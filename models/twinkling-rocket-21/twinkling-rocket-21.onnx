
pytorch2.10.0:ÔíF
ì
input
encoder.stages.0.0.weight
encoder.stages.0.0.weight_biasgetitemnode_Conv_1395"Conv*
group†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J°
	namespaceì: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÔ
pkg.torch.onnx.class_hierarchyÃ['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J–
pkg.torch.onnx.fx_nodeµ%_native_batch_norm_legit_no_training : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d, %p_encoder_stages_0_1_weight, %p_encoder_stages_0_1_bias, %b_encoder_stages_0_1_running_mean, %b_encoder_stages_0_1_running_var, 0.1, 1e-05), kwargs = {})J
pkg.torch.onnx.name_scopesa['', 'encoder', 'encoder.stages.0', 'encoder.stages.0.1', '_native_batch_norm_legit_no_training']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ê

getitemval_52node_Sigmoid_52"SigmoidJ€
	namespaceÕ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.0.2: torch.nn.modules.activation.SiLU/silu: aten.silu.defaultJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']JÑ
pkg.torch.onnx.fx_nodej%silu : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem,), kwargs = {})J_
pkg.torch.onnx.name_scopesA['', 'encoder', 'encoder.stages.0', 'encoder.stages.0.2', 'silu']J¶
pkg.torch.onnx.stack_traceáFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
‚

getitem
val_52silu	node_silu"MulJ€
	namespaceÕ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.0.2: torch.nn.modules.activation.SiLU/silu: aten.silu.defaultJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']JÑ
pkg.torch.onnx.fx_nodej%silu : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem,), kwargs = {})J_
pkg.torch.onnx.name_scopesA['', 'encoder', 'encoder.stages.0', 'encoder.stages.0.2', 'silu']J¶
pkg.torch.onnx.stack_traceáFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
Ç
silu
#encoder.stages.1.0.block.0.0.weight
(encoder.stages.1.0.block.0.0.weight_bias	getitem_3node_Conv_1397"Conv*
group(†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÍ
	namespace‹: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.0: torchvision.models.efficientnet.MBConv/encoder.stages.1.0.block: torch.nn.modules.container.Sequential/encoder.stages.1.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.1.0.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_1: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J¸
pkg.torch.onnx.fx_node·%_native_batch_norm_legit_no_training_1 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_1, %p_encoder_stages_1_0_block_0_1_weight, %p_encoder_stages_1_0_block_0_1_bias, %b_encoder_stages_1_0_block_0_1_running_mean, %b_encoder_stages_1_0_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J‹
pkg.torch.onnx.name_scopesΩ['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.0', 'encoder.stages.1.0.block', 'encoder.stages.1.0.block.0', 'encoder.stages.1.0.block.0.1', '_native_batch_norm_legit_no_training_1']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
ö
	getitem_3val_64node_Sigmoid_64"SigmoidJ§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.0: torchvision.models.efficientnet.MBConv/encoder.stages.1.0.block: torch.nn.modules.container.Sequential/encoder.stages.1.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.1.0.block.0.2: torch.nn.modules.activation.SiLU/silu_1: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jà
pkg.torch.onnx.fx_noden%silu_1 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_3,), kwargs = {})Jº
pkg.torch.onnx.name_scopesù['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.0', 'encoder.stages.1.0.block', 'encoder.stages.1.0.block.0', 'encoder.stages.1.0.block.0.2', 'silu_1']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ö
	getitem_3
val_64silu_1node_silu_1"MulJ§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.0: torchvision.models.efficientnet.MBConv/encoder.stages.1.0.block: torch.nn.modules.container.Sequential/encoder.stages.1.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.1.0.block.0.2: torch.nn.modules.activation.SiLU/silu_1: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jà
pkg.torch.onnx.fx_noden%silu_1 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_3,), kwargs = {})Jº
pkg.torch.onnx.name_scopesù['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.0', 'encoder.stages.1.0.block', 'encoder.stages.1.0.block.0', 'encoder.stages.1.0.block.0.2', 'silu_1']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
‰
silu_1
val_67mean	node_mean"
ReduceMean*
noop_with_empty_axes †*
keepdims†J´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.0: torchvision.models.efficientnet.MBConv/encoder.stages.1.0.block: torch.nn.modules.container.Sequential/encoder.stages.1.0.block.1: torchvision.ops.misc.SqueezeExcitation/encoder.stages.1.0.block.1.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jé
pkg.torch.onnx.fx_nodet%mean : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_1, [-1, -2], True), kwargs = {})J¿
pkg.torch.onnx.name_scopes°['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.0', 'encoder.stages.1.0.block', 'encoder.stages.1.0.block.1', 'encoder.stages.1.0.block.1.avgpool', 'mean']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
í
mean
%encoder.stages.1.0.block.1.fc1.weight
#encoder.stages.1.0.block.1.fc1.biasconv2d_2node_conv2d_2"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J£
	namespaceï: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.0: torchvision.models.efficientnet.MBConv/encoder.stages.1.0.block: torch.nn.modules.container.Sequential/encoder.stages.1.0.block.1: torchvision.ops.misc.SqueezeExcitation/encoder.stages.1.0.block.1.fc1: torch.nn.modules.conv.Conv2d/conv2d_2: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']JŸ
pkg.torch.onnx.fx_nodeæ%conv2d_2 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean, %p_encoder_stages_1_0_block_1_fc1_weight, %p_encoder_stages_1_0_block_1_fc1_bias), kwargs = {})J¿
pkg.torch.onnx.name_scopes°['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.0', 'encoder.stages.1.0.block', 'encoder.stages.1.0.block.1', 'encoder.stages.1.0.block.1.fc1', 'conv2d_2']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
£
conv2d_2val_68node_Sigmoid_68"SigmoidJ™
	namespaceú: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.0: torchvision.models.efficientnet.MBConv/encoder.stages.1.0.block: torch.nn.modules.container.Sequential/encoder.stages.1.0.block.1: torchvision.ops.misc.SqueezeExcitation/encoder.stages.1.0.block.1.activation: torch.nn.modules.activation.SiLU/silu_2: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Já
pkg.torch.onnx.fx_nodem%silu_2 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_2,), kwargs = {})J≈
pkg.torch.onnx.name_scopes¶['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.0', 'encoder.stages.1.0.block', 'encoder.stages.1.0.block.1', 'encoder.stages.1.0.block.1.activation', 'silu_2']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
£
conv2d_2
val_68silu_2node_silu_2"MulJ™
	namespaceú: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.0: torchvision.models.efficientnet.MBConv/encoder.stages.1.0.block: torch.nn.modules.container.Sequential/encoder.stages.1.0.block.1: torchvision.ops.misc.SqueezeExcitation/encoder.stages.1.0.block.1.activation: torch.nn.modules.activation.SiLU/silu_2: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Já
pkg.torch.onnx.fx_nodem%silu_2 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_2,), kwargs = {})J≈
pkg.torch.onnx.name_scopes¶['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.0', 'encoder.stages.1.0.block', 'encoder.stages.1.0.block.1', 'encoder.stages.1.0.block.1.activation', 'silu_2']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ñ
silu_2
%encoder.stages.1.0.block.1.fc2.weight
#encoder.stages.1.0.block.1.fc2.biasconv2d_3node_conv2d_3"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J£
	namespaceï: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.0: torchvision.models.efficientnet.MBConv/encoder.stages.1.0.block: torch.nn.modules.container.Sequential/encoder.stages.1.0.block.1: torchvision.ops.misc.SqueezeExcitation/encoder.stages.1.0.block.1.fc2: torch.nn.modules.conv.Conv2d/conv2d_3: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J€
pkg.torch.onnx.fx_node¿%conv2d_3 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_2, %p_encoder_stages_1_0_block_1_fc2_weight, %p_encoder_stages_1_0_block_1_fc2_bias), kwargs = {})J¿
pkg.torch.onnx.name_scopes°['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.0', 'encoder.stages.1.0.block', 'encoder.stages.1.0.block.1', 'encoder.stages.1.0.block.1.fc2', 'conv2d_3']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
∞
conv2d_3sigmoidnode_sigmoid"SigmoidJ∑
	namespace©: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.0: torchvision.models.efficientnet.MBConv/encoder.stages.1.0.block: torch.nn.modules.container.Sequential/encoder.stages.1.0.block.1: torchvision.ops.misc.SqueezeExcitation/encoder.stages.1.0.block.1.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jã
pkg.torch.onnx.fx_nodeq%sigmoid : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_3,), kwargs = {})JÃ
pkg.torch.onnx.name_scopes≠['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.0', 'encoder.stages.1.0.block', 'encoder.stages.1.0.block.1', 'encoder.stages.1.0.block.1.scale_activation', 'sigmoid']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
À
sigmoid
silu_1mul_178node_mul_178"MulJ·
	namespace”: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.0: torchvision.models.efficientnet.MBConv/encoder.stages.1.0.block: torch.nn.modules.container.Sequential/encoder.stages.1.0.block.1: torchvision.ops.misc.SqueezeExcitation/mul_178: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jç
pkg.torch.onnx.fx_nodes%mul_178 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid, %silu_1), kwargs = {})Jú
pkg.torch.onnx.name_scopes~['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.0', 'encoder.stages.1.0.block', 'encoder.stages.1.0.block.1', 'mul_178']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
Ö
mul_178
#encoder.stages.1.0.block.2.0.weight
(encoder.stages.1.0.block.2.0.weight_bias	getitem_6node_Conv_1399"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÍ
	namespace‹: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.0: torchvision.models.efficientnet.MBConv/encoder.stages.1.0.block: torch.nn.modules.container.Sequential/encoder.stages.1.0.block.2: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.1.0.block.2.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_2: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J¸
pkg.torch.onnx.fx_node·%_native_batch_norm_legit_no_training_2 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_4, %p_encoder_stages_1_0_block_2_1_weight, %p_encoder_stages_1_0_block_2_1_bias, %b_encoder_stages_1_0_block_2_1_running_mean, %b_encoder_stages_1_0_block_2_1_running_var, 0.1, 1e-05), kwargs = {})J‹
pkg.torch.onnx.name_scopesΩ['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.0', 'encoder.stages.1.0.block', 'encoder.stages.1.0.block.2', 'encoder.stages.1.0.block.2.1', '_native_batch_norm_legit_no_training_2']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
á
	getitem_6
#encoder.stages.1.1.block.0.0.weight
(encoder.stages.1.1.block.0.0.weight_bias	getitem_9node_Conv_1401"Conv*
group†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÍ
	namespace‹: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.1: torchvision.models.efficientnet.MBConv/encoder.stages.1.1.block: torch.nn.modules.container.Sequential/encoder.stages.1.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.1.1.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_3: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J¸
pkg.torch.onnx.fx_node·%_native_batch_norm_legit_no_training_3 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_5, %p_encoder_stages_1_1_block_0_1_weight, %p_encoder_stages_1_1_block_0_1_bias, %b_encoder_stages_1_1_block_0_1_running_mean, %b_encoder_stages_1_1_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J‹
pkg.torch.onnx.name_scopesΩ['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.1', 'encoder.stages.1.1.block', 'encoder.stages.1.1.block.0', 'encoder.stages.1.1.block.0.1', '_native_batch_norm_legit_no_training_3']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
ö
	getitem_9val_91node_Sigmoid_91"SigmoidJ§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.1: torchvision.models.efficientnet.MBConv/encoder.stages.1.1.block: torch.nn.modules.container.Sequential/encoder.stages.1.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.1.1.block.0.2: torch.nn.modules.activation.SiLU/silu_3: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jà
pkg.torch.onnx.fx_noden%silu_3 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_9,), kwargs = {})Jº
pkg.torch.onnx.name_scopesù['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.1', 'encoder.stages.1.1.block', 'encoder.stages.1.1.block.0', 'encoder.stages.1.1.block.0.2', 'silu_3']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ö
	getitem_9
val_91silu_3node_silu_3"MulJ§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.1: torchvision.models.efficientnet.MBConv/encoder.stages.1.1.block: torch.nn.modules.container.Sequential/encoder.stages.1.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.1.1.block.0.2: torch.nn.modules.activation.SiLU/silu_3: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jà
pkg.torch.onnx.fx_noden%silu_3 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_9,), kwargs = {})Jº
pkg.torch.onnx.name_scopesù['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.1', 'encoder.stages.1.1.block', 'encoder.stages.1.1.block.0', 'encoder.stages.1.1.block.0.2', 'silu_3']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
Ó
silu_3
val_67mean_1node_mean_1"
ReduceMean*
noop_with_empty_axes †*
keepdims†J≠
	namespaceü: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.1: torchvision.models.efficientnet.MBConv/encoder.stages.1.1.block: torch.nn.modules.container.Sequential/encoder.stages.1.1.block.1: torchvision.ops.misc.SqueezeExcitation/encoder.stages.1.1.block.1.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_1: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jê
pkg.torch.onnx.fx_nodev%mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_3, [-1, -2], True), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.1', 'encoder.stages.1.1.block', 'encoder.stages.1.1.block.1', 'encoder.stages.1.1.block.1.avgpool', 'mean_1']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
ñ
mean_1
%encoder.stages.1.1.block.1.fc1.weight
#encoder.stages.1.1.block.1.fc1.biasconv2d_6node_conv2d_6"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J£
	namespaceï: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.1: torchvision.models.efficientnet.MBConv/encoder.stages.1.1.block: torch.nn.modules.container.Sequential/encoder.stages.1.1.block.1: torchvision.ops.misc.SqueezeExcitation/encoder.stages.1.1.block.1.fc1: torch.nn.modules.conv.Conv2d/conv2d_6: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J€
pkg.torch.onnx.fx_node¿%conv2d_6 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_1, %p_encoder_stages_1_1_block_1_fc1_weight, %p_encoder_stages_1_1_block_1_fc1_bias), kwargs = {})J¿
pkg.torch.onnx.name_scopes°['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.1', 'encoder.stages.1.1.block', 'encoder.stages.1.1.block.1', 'encoder.stages.1.1.block.1.fc1', 'conv2d_6']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
£
conv2d_6val_94node_Sigmoid_94"SigmoidJ™
	namespaceú: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.1: torchvision.models.efficientnet.MBConv/encoder.stages.1.1.block: torch.nn.modules.container.Sequential/encoder.stages.1.1.block.1: torchvision.ops.misc.SqueezeExcitation/encoder.stages.1.1.block.1.activation: torch.nn.modules.activation.SiLU/silu_4: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Já
pkg.torch.onnx.fx_nodem%silu_4 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_6,), kwargs = {})J≈
pkg.torch.onnx.name_scopes¶['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.1', 'encoder.stages.1.1.block', 'encoder.stages.1.1.block.1', 'encoder.stages.1.1.block.1.activation', 'silu_4']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
£
conv2d_6
val_94silu_4node_silu_4"MulJ™
	namespaceú: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.1: torchvision.models.efficientnet.MBConv/encoder.stages.1.1.block: torch.nn.modules.container.Sequential/encoder.stages.1.1.block.1: torchvision.ops.misc.SqueezeExcitation/encoder.stages.1.1.block.1.activation: torch.nn.modules.activation.SiLU/silu_4: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Já
pkg.torch.onnx.fx_nodem%silu_4 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_6,), kwargs = {})J≈
pkg.torch.onnx.name_scopes¶['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.1', 'encoder.stages.1.1.block', 'encoder.stages.1.1.block.1', 'encoder.stages.1.1.block.1.activation', 'silu_4']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ñ
silu_4
%encoder.stages.1.1.block.1.fc2.weight
#encoder.stages.1.1.block.1.fc2.biasconv2d_7node_conv2d_7"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J£
	namespaceï: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.1: torchvision.models.efficientnet.MBConv/encoder.stages.1.1.block: torch.nn.modules.container.Sequential/encoder.stages.1.1.block.1: torchvision.ops.misc.SqueezeExcitation/encoder.stages.1.1.block.1.fc2: torch.nn.modules.conv.Conv2d/conv2d_7: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J€
pkg.torch.onnx.fx_node¿%conv2d_7 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_4, %p_encoder_stages_1_1_block_1_fc2_weight, %p_encoder_stages_1_1_block_1_fc2_bias), kwargs = {})J¿
pkg.torch.onnx.name_scopes°['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.1', 'encoder.stages.1.1.block', 'encoder.stages.1.1.block.1', 'encoder.stages.1.1.block.1.fc2', 'conv2d_7']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
∫
conv2d_7	sigmoid_1node_sigmoid_1"SigmoidJπ
	namespace´: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.1: torchvision.models.efficientnet.MBConv/encoder.stages.1.1.block: torch.nn.modules.container.Sequential/encoder.stages.1.1.block.1: torchvision.ops.misc.SqueezeExcitation/encoder.stages.1.1.block.1.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_1: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jç
pkg.torch.onnx.fx_nodes%sigmoid_1 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_7,), kwargs = {})JŒ
pkg.torch.onnx.name_scopesØ['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.1', 'encoder.stages.1.1.block', 'encoder.stages.1.1.block.1', 'encoder.stages.1.1.block.1.scale_activation', 'sigmoid_1']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
œ
	sigmoid_1
silu_3mul_255node_mul_255"MulJ·
	namespace”: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.1: torchvision.models.efficientnet.MBConv/encoder.stages.1.1.block: torch.nn.modules.container.Sequential/encoder.stages.1.1.block.1: torchvision.ops.misc.SqueezeExcitation/mul_255: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jè
pkg.torch.onnx.fx_nodeu%mul_255 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_1, %silu_3), kwargs = {})Jú
pkg.torch.onnx.name_scopes~['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.1', 'encoder.stages.1.1.block', 'encoder.stages.1.1.block.1', 'mul_255']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
Ü
mul_255
#encoder.stages.1.1.block.2.0.weight
(encoder.stages.1.1.block.2.0.weight_bias
getitem_12node_Conv_1403"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÍ
	namespace‹: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.1: torchvision.models.efficientnet.MBConv/encoder.stages.1.1.block: torch.nn.modules.container.Sequential/encoder.stages.1.1.block.2: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.1.1.block.2.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_4: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J¸
pkg.torch.onnx.fx_node·%_native_batch_norm_legit_no_training_4 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_8, %p_encoder_stages_1_1_block_2_1_weight, %p_encoder_stages_1_1_block_2_1_bias, %b_encoder_stages_1_1_block_2_1_running_mean, %b_encoder_stages_1_1_block_2_1_running_var, 0.1, 1e-05), kwargs = {})J‹
pkg.torch.onnx.name_scopesΩ['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.1', 'encoder.stages.1.1.block', 'encoder.stages.1.1.block.2', 'encoder.stages.1.1.block.2.1', '_native_batch_norm_legit_no_training_4']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ï


getitem_12
	getitem_6add_213node_add_213"AddJﬁ
	namespace–: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.1: torch.nn.modules.container.Sequential/encoder.stages.1.1: torchvision.models.efficientnet.MBConv/add_213: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jì
pkg.torch.onnx.fx_nodey%add_213 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_12, %getitem_6), kwargs = {})Jb
pkg.torch.onnx.name_scopesD['', 'encoder', 'encoder.stages.1', 'encoder.stages.1.1', 'add_213']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
Ü
add_213
#encoder.stages.2.0.block.0.0.weight
(encoder.stages.2.0.block.0.0.weight_bias
getitem_15node_Conv_1405"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÍ
	namespace‹: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.0: torchvision.models.efficientnet.MBConv/encoder.stages.2.0.block: torch.nn.modules.container.Sequential/encoder.stages.2.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.0.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_5: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J¸
pkg.torch.onnx.fx_node·%_native_batch_norm_legit_no_training_5 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_9, %p_encoder_stages_2_0_block_0_1_weight, %p_encoder_stages_2_0_block_0_1_bias, %b_encoder_stages_2_0_block_0_1_running_mean, %b_encoder_stages_2_0_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J‹
pkg.torch.onnx.name_scopesΩ['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.0', 'encoder.stages.2.0.block', 'encoder.stages.2.0.block.0', 'encoder.stages.2.0.block.0.1', '_native_batch_norm_legit_no_training_5']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
û

getitem_15val_117node_Sigmoid_117"SigmoidJ§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.0: torchvision.models.efficientnet.MBConv/encoder.stages.2.0.block: torch.nn.modules.container.Sequential/encoder.stages.2.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.0.block.0.2: torch.nn.modules.activation.SiLU/silu_5: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_5 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_15,), kwargs = {})Jº
pkg.torch.onnx.name_scopesù['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.0', 'encoder.stages.2.0.block', 'encoder.stages.2.0.block.0', 'encoder.stages.2.0.block.0.2', 'silu_5']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù

getitem_15
val_117silu_5node_silu_5"MulJ§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.0: torchvision.models.efficientnet.MBConv/encoder.stages.2.0.block: torch.nn.modules.container.Sequential/encoder.stages.2.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.0.block.0.2: torch.nn.modules.activation.SiLU/silu_5: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_5 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_15,), kwargs = {})Jº
pkg.torch.onnx.name_scopesù['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.0', 'encoder.stages.2.0.block', 'encoder.stages.2.0.block.0', 'encoder.stages.2.0.block.0.2', 'silu_5']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
á
silu_5
#encoder.stages.2.0.block.1.0.weight
(encoder.stages.2.0.block.1.0.weight_bias
getitem_18node_Conv_1407"Conv*
groupê†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÍ
	namespace‹: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.0: torchvision.models.efficientnet.MBConv/encoder.stages.2.0.block: torch.nn.modules.container.Sequential/encoder.stages.2.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.0.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_6: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˝
pkg.torch.onnx.fx_node‚%_native_batch_norm_legit_no_training_6 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_10, %p_encoder_stages_2_0_block_1_1_weight, %p_encoder_stages_2_0_block_1_1_bias, %b_encoder_stages_2_0_block_1_1_running_mean, %b_encoder_stages_2_0_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J‹
pkg.torch.onnx.name_scopesΩ['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.0', 'encoder.stages.2.0.block', 'encoder.stages.2.0.block.1', 'encoder.stages.2.0.block.1.1', '_native_batch_norm_legit_no_training_6']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
û

getitem_18val_129node_Sigmoid_129"SigmoidJ§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.0: torchvision.models.efficientnet.MBConv/encoder.stages.2.0.block: torch.nn.modules.container.Sequential/encoder.stages.2.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.0.block.1.2: torch.nn.modules.activation.SiLU/silu_6: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_6 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_18,), kwargs = {})Jº
pkg.torch.onnx.name_scopesù['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.0', 'encoder.stages.2.0.block', 'encoder.stages.2.0.block.1', 'encoder.stages.2.0.block.1.2', 'silu_6']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù

getitem_18
val_129silu_6node_silu_6"MulJ§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.0: torchvision.models.efficientnet.MBConv/encoder.stages.2.0.block: torch.nn.modules.container.Sequential/encoder.stages.2.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.0.block.1.2: torch.nn.modules.activation.SiLU/silu_6: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_6 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_18,), kwargs = {})Jº
pkg.torch.onnx.name_scopesù['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.0', 'encoder.stages.2.0.block', 'encoder.stages.2.0.block.1', 'encoder.stages.2.0.block.1.2', 'silu_6']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
Ó
silu_6
val_67mean_2node_mean_2"
ReduceMean*
noop_with_empty_axes †*
keepdims†J≠
	namespaceü: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.0: torchvision.models.efficientnet.MBConv/encoder.stages.2.0.block: torch.nn.modules.container.Sequential/encoder.stages.2.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.0.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_2: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jê
pkg.torch.onnx.fx_nodev%mean_2 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_6, [-1, -2], True), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.0', 'encoder.stages.2.0.block', 'encoder.stages.2.0.block.2', 'encoder.stages.2.0.block.2.avgpool', 'mean_2']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
õ
mean_2
%encoder.stages.2.0.block.2.fc1.weight
#encoder.stages.2.0.block.2.fc1.bias	conv2d_11node_conv2d_11"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.0: torchvision.models.efficientnet.MBConv/encoder.stages.2.0.block: torch.nn.modules.container.Sequential/encoder.stages.2.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.0.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_11: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J‹
pkg.torch.onnx.fx_node¡%conv2d_11 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_2, %p_encoder_stages_2_0_block_2_fc1_weight, %p_encoder_stages_2_0_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.0', 'encoder.stages.2.0.block', 'encoder.stages.2.0.block.2', 'encoder.stages.2.0.block.2.fc1', 'conv2d_11']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
ß
	conv2d_11val_132node_Sigmoid_132"SigmoidJ™
	namespaceú: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.0: torchvision.models.efficientnet.MBConv/encoder.stages.2.0.block: torch.nn.modules.container.Sequential/encoder.stages.2.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.0.block.2.activation: torch.nn.modules.activation.SiLU/silu_7: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jà
pkg.torch.onnx.fx_noden%silu_7 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_11,), kwargs = {})J≈
pkg.torch.onnx.name_scopes¶['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.0', 'encoder.stages.2.0.block', 'encoder.stages.2.0.block.2', 'encoder.stages.2.0.block.2.activation', 'silu_7']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¶
	conv2d_11
val_132silu_7node_silu_7"MulJ™
	namespaceú: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.0: torchvision.models.efficientnet.MBConv/encoder.stages.2.0.block: torch.nn.modules.container.Sequential/encoder.stages.2.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.0.block.2.activation: torch.nn.modules.activation.SiLU/silu_7: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jà
pkg.torch.onnx.fx_noden%silu_7 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_11,), kwargs = {})J≈
pkg.torch.onnx.name_scopes¶['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.0', 'encoder.stages.2.0.block', 'encoder.stages.2.0.block.2', 'encoder.stages.2.0.block.2.activation', 'silu_7']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
õ
silu_7
%encoder.stages.2.0.block.2.fc2.weight
#encoder.stages.2.0.block.2.fc2.bias	conv2d_12node_conv2d_12"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.0: torchvision.models.efficientnet.MBConv/encoder.stages.2.0.block: torch.nn.modules.container.Sequential/encoder.stages.2.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.0.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_12: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J‹
pkg.torch.onnx.fx_node¡%conv2d_12 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_7, %p_encoder_stages_2_0_block_2_fc2_weight, %p_encoder_stages_2_0_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.0', 'encoder.stages.2.0.block', 'encoder.stages.2.0.block.2', 'encoder.stages.2.0.block.2.fc2', 'conv2d_12']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
º
	conv2d_12	sigmoid_2node_sigmoid_2"SigmoidJπ
	namespace´: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.0: torchvision.models.efficientnet.MBConv/encoder.stages.2.0.block: torch.nn.modules.container.Sequential/encoder.stages.2.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.0.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_2: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jé
pkg.torch.onnx.fx_nodet%sigmoid_2 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_12,), kwargs = {})JŒ
pkg.torch.onnx.name_scopesØ['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.0', 'encoder.stages.2.0.block', 'encoder.stages.2.0.block.2', 'encoder.stages.2.0.block.2.scale_activation', 'sigmoid_2']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
œ
	sigmoid_2
silu_6mul_384node_mul_384"MulJ·
	namespace”: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.0: torchvision.models.efficientnet.MBConv/encoder.stages.2.0.block: torch.nn.modules.container.Sequential/encoder.stages.2.0.block.2: torchvision.ops.misc.SqueezeExcitation/mul_384: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jè
pkg.torch.onnx.fx_nodeu%mul_384 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_2, %silu_6), kwargs = {})Jú
pkg.torch.onnx.name_scopes~['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.0', 'encoder.stages.2.0.block', 'encoder.stages.2.0.block.2', 'mul_384']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
á
mul_384
#encoder.stages.2.0.block.3.0.weight
(encoder.stages.2.0.block.3.0.weight_bias
getitem_21node_Conv_1409"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÍ
	namespace‹: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.0: torchvision.models.efficientnet.MBConv/encoder.stages.2.0.block: torch.nn.modules.container.Sequential/encoder.stages.2.0.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.0.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_7: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˝
pkg.torch.onnx.fx_node‚%_native_batch_norm_legit_no_training_7 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_13, %p_encoder_stages_2_0_block_3_1_weight, %p_encoder_stages_2_0_block_3_1_bias, %b_encoder_stages_2_0_block_3_1_running_mean, %b_encoder_stages_2_0_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J‹
pkg.torch.onnx.name_scopesΩ['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.0', 'encoder.stages.2.0.block', 'encoder.stages.2.0.block.3', 'encoder.stages.2.0.block.3.1', '_native_batch_norm_legit_no_training_7']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
ä

getitem_21
#encoder.stages.2.1.block.0.0.weight
(encoder.stages.2.1.block.0.0.weight_bias
getitem_24node_Conv_1411"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÍ
	namespace‹: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.1: torchvision.models.efficientnet.MBConv/encoder.stages.2.1.block: torch.nn.modules.container.Sequential/encoder.stages.2.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.1.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_8: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˝
pkg.torch.onnx.fx_node‚%_native_batch_norm_legit_no_training_8 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_14, %p_encoder_stages_2_1_block_0_1_weight, %p_encoder_stages_2_1_block_0_1_bias, %b_encoder_stages_2_1_block_0_1_running_mean, %b_encoder_stages_2_1_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J‹
pkg.torch.onnx.name_scopesΩ['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.1', 'encoder.stages.2.1.block', 'encoder.stages.2.1.block.0', 'encoder.stages.2.1.block.0.1', '_native_batch_norm_legit_no_training_8']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
û

getitem_24val_155node_Sigmoid_155"SigmoidJ§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.1: torchvision.models.efficientnet.MBConv/encoder.stages.2.1.block: torch.nn.modules.container.Sequential/encoder.stages.2.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.1.block.0.2: torch.nn.modules.activation.SiLU/silu_8: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_8 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_24,), kwargs = {})Jº
pkg.torch.onnx.name_scopesù['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.1', 'encoder.stages.2.1.block', 'encoder.stages.2.1.block.0', 'encoder.stages.2.1.block.0.2', 'silu_8']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù

getitem_24
val_155silu_8node_silu_8"MulJ§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.1: torchvision.models.efficientnet.MBConv/encoder.stages.2.1.block: torch.nn.modules.container.Sequential/encoder.stages.2.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.1.block.0.2: torch.nn.modules.activation.SiLU/silu_8: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_8 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_24,), kwargs = {})Jº
pkg.torch.onnx.name_scopesù['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.1', 'encoder.stages.2.1.block', 'encoder.stages.2.1.block.0', 'encoder.stages.2.1.block.0.2', 'silu_8']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
á
silu_8
#encoder.stages.2.1.block.1.0.weight
(encoder.stages.2.1.block.1.0.weight_bias
getitem_27node_Conv_1413"Conv*
group¿†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÍ
	namespace‹: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.1: torchvision.models.efficientnet.MBConv/encoder.stages.2.1.block: torch.nn.modules.container.Sequential/encoder.stages.2.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.1.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_9: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˝
pkg.torch.onnx.fx_node‚%_native_batch_norm_legit_no_training_9 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_15, %p_encoder_stages_2_1_block_1_1_weight, %p_encoder_stages_2_1_block_1_1_bias, %b_encoder_stages_2_1_block_1_1_running_mean, %b_encoder_stages_2_1_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J‹
pkg.torch.onnx.name_scopesΩ['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.1', 'encoder.stages.2.1.block', 'encoder.stages.2.1.block.1', 'encoder.stages.2.1.block.1.1', '_native_batch_norm_legit_no_training_9']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
û

getitem_27val_167node_Sigmoid_167"SigmoidJ§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.1: torchvision.models.efficientnet.MBConv/encoder.stages.2.1.block: torch.nn.modules.container.Sequential/encoder.stages.2.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.1.block.1.2: torch.nn.modules.activation.SiLU/silu_9: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_9 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_27,), kwargs = {})Jº
pkg.torch.onnx.name_scopesù['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.1', 'encoder.stages.2.1.block', 'encoder.stages.2.1.block.1', 'encoder.stages.2.1.block.1.2', 'silu_9']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù

getitem_27
val_167silu_9node_silu_9"MulJ§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.1: torchvision.models.efficientnet.MBConv/encoder.stages.2.1.block: torch.nn.modules.container.Sequential/encoder.stages.2.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.1.block.1.2: torch.nn.modules.activation.SiLU/silu_9: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_9 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_27,), kwargs = {})Jº
pkg.torch.onnx.name_scopesù['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.1', 'encoder.stages.2.1.block', 'encoder.stages.2.1.block.1', 'encoder.stages.2.1.block.1.2', 'silu_9']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
Ó
silu_9
val_67mean_3node_mean_3"
ReduceMean*
noop_with_empty_axes †*
keepdims†J≠
	namespaceü: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.1: torchvision.models.efficientnet.MBConv/encoder.stages.2.1.block: torch.nn.modules.container.Sequential/encoder.stages.2.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.1.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_3: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jê
pkg.torch.onnx.fx_nodev%mean_3 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_9, [-1, -2], True), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.1', 'encoder.stages.2.1.block', 'encoder.stages.2.1.block.2', 'encoder.stages.2.1.block.2.avgpool', 'mean_3']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
õ
mean_3
%encoder.stages.2.1.block.2.fc1.weight
#encoder.stages.2.1.block.2.fc1.bias	conv2d_16node_conv2d_16"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.1: torchvision.models.efficientnet.MBConv/encoder.stages.2.1.block: torch.nn.modules.container.Sequential/encoder.stages.2.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.1.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_16: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J‹
pkg.torch.onnx.fx_node¡%conv2d_16 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_3, %p_encoder_stages_2_1_block_2_fc1_weight, %p_encoder_stages_2_1_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.1', 'encoder.stages.2.1.block', 'encoder.stages.2.1.block.2', 'encoder.stages.2.1.block.2.fc1', 'conv2d_16']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_16val_170node_Sigmoid_170"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.1: torchvision.models.efficientnet.MBConv/encoder.stages.2.1.block: torch.nn.modules.container.Sequential/encoder.stages.2.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.1.block.2.activation: torch.nn.modules.activation.SiLU/silu_10: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_10 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_16,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.1', 'encoder.stages.2.1.block', 'encoder.stages.2.1.block.2', 'encoder.stages.2.1.block.2.activation', 'silu_10']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_16
val_170silu_10node_silu_10"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.1: torchvision.models.efficientnet.MBConv/encoder.stages.2.1.block: torch.nn.modules.container.Sequential/encoder.stages.2.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.1.block.2.activation: torch.nn.modules.activation.SiLU/silu_10: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_10 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_16,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.1', 'encoder.stages.2.1.block', 'encoder.stages.2.1.block.2', 'encoder.stages.2.1.block.2.activation', 'silu_10']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_10
%encoder.stages.2.1.block.2.fc2.weight
#encoder.stages.2.1.block.2.fc2.bias	conv2d_17node_conv2d_17"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.1: torchvision.models.efficientnet.MBConv/encoder.stages.2.1.block: torch.nn.modules.container.Sequential/encoder.stages.2.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.1.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_17: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_17 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_10, %p_encoder_stages_2_1_block_2_fc2_weight, %p_encoder_stages_2_1_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.1', 'encoder.stages.2.1.block', 'encoder.stages.2.1.block.2', 'encoder.stages.2.1.block.2.fc2', 'conv2d_17']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
º
	conv2d_17	sigmoid_3node_sigmoid_3"SigmoidJπ
	namespace´: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.1: torchvision.models.efficientnet.MBConv/encoder.stages.2.1.block: torch.nn.modules.container.Sequential/encoder.stages.2.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.1.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_3: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jé
pkg.torch.onnx.fx_nodet%sigmoid_3 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_17,), kwargs = {})JŒ
pkg.torch.onnx.name_scopesØ['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.1', 'encoder.stages.2.1.block', 'encoder.stages.2.1.block.2', 'encoder.stages.2.1.block.2.scale_activation', 'sigmoid_3']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
œ
	sigmoid_3
silu_9mul_501node_mul_501"MulJ·
	namespace”: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.1: torchvision.models.efficientnet.MBConv/encoder.stages.2.1.block: torch.nn.modules.container.Sequential/encoder.stages.2.1.block.2: torchvision.ops.misc.SqueezeExcitation/mul_501: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jè
pkg.torch.onnx.fx_nodeu%mul_501 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_3, %silu_9), kwargs = {})Jú
pkg.torch.onnx.name_scopes~['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.1', 'encoder.stages.2.1.block', 'encoder.stages.2.1.block.2', 'mul_501']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
ä
mul_501
#encoder.stages.2.1.block.3.0.weight
(encoder.stages.2.1.block.3.0.weight_bias
getitem_30node_Conv_1415"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.1: torchvision.models.efficientnet.MBConv/encoder.stages.2.1.block: torch.nn.modules.container.Sequential/encoder.stages.2.1.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.1.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_10: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_10 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_18, %p_encoder_stages_2_1_block_3_1_weight, %p_encoder_stages_2_1_block_3_1_bias, %b_encoder_stages_2_1_block_3_1_running_mean, %b_encoder_stages_2_1_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.1', 'encoder.stages.2.1.block', 'encoder.stages.2.1.block.3', 'encoder.stages.2.1.block.3.1', '_native_batch_norm_legit_no_training_10']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ó


getitem_30

getitem_21add_405node_add_405"AddJﬁ
	namespace–: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.1: torchvision.models.efficientnet.MBConv/add_405: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_405 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_30, %getitem_21), kwargs = {})Jb
pkg.torch.onnx.name_scopesD['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.1', 'add_405']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
ä
add_405
#encoder.stages.2.2.block.0.0.weight
(encoder.stages.2.2.block.0.0.weight_bias
getitem_33node_Conv_1417"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.2: torchvision.models.efficientnet.MBConv/encoder.stages.2.2.block: torch.nn.modules.container.Sequential/encoder.stages.2.2.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.2.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_11: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_11 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_19, %p_encoder_stages_2_2_block_0_1_weight, %p_encoder_stages_2_2_block_0_1_bias, %b_encoder_stages_2_2_block_0_1_running_mean, %b_encoder_stages_2_2_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.2', 'encoder.stages.2.2.block', 'encoder.stages.2.2.block.0', 'encoder.stages.2.2.block.0.1', '_native_batch_norm_legit_no_training_11']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
°

getitem_33val_193node_Sigmoid_193"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.2: torchvision.models.efficientnet.MBConv/encoder.stages.2.2.block: torch.nn.modules.container.Sequential/encoder.stages.2.2.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.2.block.0.2: torch.nn.modules.activation.SiLU/silu_11: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_11 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_33,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.2', 'encoder.stages.2.2.block', 'encoder.stages.2.2.block.0', 'encoder.stages.2.2.block.0.2', 'silu_11']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢

getitem_33
val_193silu_11node_silu_11"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.2: torchvision.models.efficientnet.MBConv/encoder.stages.2.2.block: torch.nn.modules.container.Sequential/encoder.stages.2.2.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.2.block.0.2: torch.nn.modules.activation.SiLU/silu_11: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_11 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_33,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.2', 'encoder.stages.2.2.block', 'encoder.stages.2.2.block.0', 'encoder.stages.2.2.block.0.2', 'silu_11']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ã
silu_11
#encoder.stages.2.2.block.1.0.weight
(encoder.stages.2.2.block.1.0.weight_bias
getitem_36node_Conv_1419"Conv*
group¿†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.2: torchvision.models.efficientnet.MBConv/encoder.stages.2.2.block: torch.nn.modules.container.Sequential/encoder.stages.2.2.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.2.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_12: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_12 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_20, %p_encoder_stages_2_2_block_1_1_weight, %p_encoder_stages_2_2_block_1_1_bias, %b_encoder_stages_2_2_block_1_1_running_mean, %b_encoder_stages_2_2_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.2', 'encoder.stages.2.2.block', 'encoder.stages.2.2.block.1', 'encoder.stages.2.2.block.1.1', '_native_batch_norm_legit_no_training_12']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
°

getitem_36val_205node_Sigmoid_205"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.2: torchvision.models.efficientnet.MBConv/encoder.stages.2.2.block: torch.nn.modules.container.Sequential/encoder.stages.2.2.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.2.block.1.2: torch.nn.modules.activation.SiLU/silu_12: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_12 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_36,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.2', 'encoder.stages.2.2.block', 'encoder.stages.2.2.block.1', 'encoder.stages.2.2.block.1.2', 'silu_12']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢

getitem_36
val_205silu_12node_silu_12"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.2: torchvision.models.efficientnet.MBConv/encoder.stages.2.2.block: torch.nn.modules.container.Sequential/encoder.stages.2.2.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.2.block.1.2: torch.nn.modules.activation.SiLU/silu_12: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_12 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_36,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.2', 'encoder.stages.2.2.block', 'encoder.stages.2.2.block.1', 'encoder.stages.2.2.block.1.2', 'silu_12']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)

silu_12
val_67mean_4node_mean_4"
ReduceMean*
noop_with_empty_axes †*
keepdims†J≠
	namespaceü: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.2: torchvision.models.efficientnet.MBConv/encoder.stages.2.2.block: torch.nn.modules.container.Sequential/encoder.stages.2.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.2.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_4: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jë
pkg.torch.onnx.fx_nodew%mean_4 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_12, [-1, -2], True), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.2', 'encoder.stages.2.2.block', 'encoder.stages.2.2.block.2', 'encoder.stages.2.2.block.2.avgpool', 'mean_4']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
õ
mean_4
%encoder.stages.2.2.block.2.fc1.weight
#encoder.stages.2.2.block.2.fc1.bias	conv2d_21node_conv2d_21"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.2: torchvision.models.efficientnet.MBConv/encoder.stages.2.2.block: torch.nn.modules.container.Sequential/encoder.stages.2.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.2.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_21: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J‹
pkg.torch.onnx.fx_node¡%conv2d_21 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_4, %p_encoder_stages_2_2_block_2_fc1_weight, %p_encoder_stages_2_2_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.2', 'encoder.stages.2.2.block', 'encoder.stages.2.2.block.2', 'encoder.stages.2.2.block.2.fc1', 'conv2d_21']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_21val_208node_Sigmoid_208"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.2: torchvision.models.efficientnet.MBConv/encoder.stages.2.2.block: torch.nn.modules.container.Sequential/encoder.stages.2.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.2.block.2.activation: torch.nn.modules.activation.SiLU/silu_13: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_13 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_21,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.2', 'encoder.stages.2.2.block', 'encoder.stages.2.2.block.2', 'encoder.stages.2.2.block.2.activation', 'silu_13']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_21
val_208silu_13node_silu_13"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.2: torchvision.models.efficientnet.MBConv/encoder.stages.2.2.block: torch.nn.modules.container.Sequential/encoder.stages.2.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.2.block.2.activation: torch.nn.modules.activation.SiLU/silu_13: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_13 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_21,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.2', 'encoder.stages.2.2.block', 'encoder.stages.2.2.block.2', 'encoder.stages.2.2.block.2.activation', 'silu_13']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_13
%encoder.stages.2.2.block.2.fc2.weight
#encoder.stages.2.2.block.2.fc2.bias	conv2d_22node_conv2d_22"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.2: torchvision.models.efficientnet.MBConv/encoder.stages.2.2.block: torch.nn.modules.container.Sequential/encoder.stages.2.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.2.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_22: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_22 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_13, %p_encoder_stages_2_2_block_2_fc2_weight, %p_encoder_stages_2_2_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.2', 'encoder.stages.2.2.block', 'encoder.stages.2.2.block.2', 'encoder.stages.2.2.block.2.fc2', 'conv2d_22']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
º
	conv2d_22	sigmoid_4node_sigmoid_4"SigmoidJπ
	namespace´: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.2: torchvision.models.efficientnet.MBConv/encoder.stages.2.2.block: torch.nn.modules.container.Sequential/encoder.stages.2.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.2.2.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_4: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jé
pkg.torch.onnx.fx_nodet%sigmoid_4 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_22,), kwargs = {})JŒ
pkg.torch.onnx.name_scopesØ['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.2', 'encoder.stages.2.2.block', 'encoder.stages.2.2.block.2', 'encoder.stages.2.2.block.2.scale_activation', 'sigmoid_4']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
—
	sigmoid_4
silu_12mul_630node_mul_630"MulJ·
	namespace”: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.2: torchvision.models.efficientnet.MBConv/encoder.stages.2.2.block: torch.nn.modules.container.Sequential/encoder.stages.2.2.block.2: torchvision.ops.misc.SqueezeExcitation/mul_630: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jê
pkg.torch.onnx.fx_nodev%mul_630 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_4, %silu_12), kwargs = {})Jú
pkg.torch.onnx.name_scopes~['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.2', 'encoder.stages.2.2.block', 'encoder.stages.2.2.block.2', 'mul_630']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
ä
mul_630
#encoder.stages.2.2.block.3.0.weight
(encoder.stages.2.2.block.3.0.weight_bias
getitem_39node_Conv_1421"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.2: torchvision.models.efficientnet.MBConv/encoder.stages.2.2.block: torch.nn.modules.container.Sequential/encoder.stages.2.2.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.2.2.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_13: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_13 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_23, %p_encoder_stages_2_2_block_3_1_weight, %p_encoder_stages_2_2_block_3_1_bias, %b_encoder_stages_2_2_block_3_1_running_mean, %b_encoder_stages_2_2_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.2', 'encoder.stages.2.2.block', 'encoder.stages.2.2.block.3', 'encoder.stages.2.2.block.3.1', '_native_batch_norm_legit_no_training_13']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ë


getitem_39
add_405add_509node_add_509"AddJﬁ
	namespace–: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.2: torch.nn.modules.container.Sequential/encoder.stages.2.2: torchvision.models.efficientnet.MBConv/add_509: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jë
pkg.torch.onnx.fx_nodew%add_509 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_39, %add_405), kwargs = {})Jb
pkg.torch.onnx.name_scopesD['', 'encoder', 'encoder.stages.2', 'encoder.stages.2.2', 'add_509']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
ä
add_509
#encoder.stages.3.0.block.0.0.weight
(encoder.stages.3.0.block.0.0.weight_bias
getitem_42node_Conv_1423"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.0: torchvision.models.efficientnet.MBConv/encoder.stages.3.0.block: torch.nn.modules.container.Sequential/encoder.stages.3.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.0.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_14: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_14 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_24, %p_encoder_stages_3_0_block_0_1_weight, %p_encoder_stages_3_0_block_0_1_bias, %b_encoder_stages_3_0_block_0_1_running_mean, %b_encoder_stages_3_0_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.0', 'encoder.stages.3.0.block', 'encoder.stages.3.0.block.0', 'encoder.stages.3.0.block.0.1', '_native_batch_norm_legit_no_training_14']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
°

getitem_42val_231node_Sigmoid_231"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.0: torchvision.models.efficientnet.MBConv/encoder.stages.3.0.block: torch.nn.modules.container.Sequential/encoder.stages.3.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.0.block.0.2: torch.nn.modules.activation.SiLU/silu_14: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_14 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_42,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.0', 'encoder.stages.3.0.block', 'encoder.stages.3.0.block.0', 'encoder.stages.3.0.block.0.2', 'silu_14']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢

getitem_42
val_231silu_14node_silu_14"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.0: torchvision.models.efficientnet.MBConv/encoder.stages.3.0.block: torch.nn.modules.container.Sequential/encoder.stages.3.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.0.block.0.2: torch.nn.modules.activation.SiLU/silu_14: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_14 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_42,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.0', 'encoder.stages.3.0.block', 'encoder.stages.3.0.block.0', 'encoder.stages.3.0.block.0.2', 'silu_14']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ã
silu_14
#encoder.stages.3.0.block.1.0.weight
(encoder.stages.3.0.block.1.0.weight_bias
getitem_45node_Conv_1425"Conv*
group¿†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.0: torchvision.models.efficientnet.MBConv/encoder.stages.3.0.block: torch.nn.modules.container.Sequential/encoder.stages.3.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.0.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_15: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_15 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_25, %p_encoder_stages_3_0_block_1_1_weight, %p_encoder_stages_3_0_block_1_1_bias, %b_encoder_stages_3_0_block_1_1_running_mean, %b_encoder_stages_3_0_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.0', 'encoder.stages.3.0.block', 'encoder.stages.3.0.block.1', 'encoder.stages.3.0.block.1.1', '_native_batch_norm_legit_no_training_15']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
°

getitem_45val_243node_Sigmoid_243"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.0: torchvision.models.efficientnet.MBConv/encoder.stages.3.0.block: torch.nn.modules.container.Sequential/encoder.stages.3.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.0.block.1.2: torch.nn.modules.activation.SiLU/silu_15: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_15 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_45,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.0', 'encoder.stages.3.0.block', 'encoder.stages.3.0.block.1', 'encoder.stages.3.0.block.1.2', 'silu_15']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢

getitem_45
val_243silu_15node_silu_15"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.0: torchvision.models.efficientnet.MBConv/encoder.stages.3.0.block: torch.nn.modules.container.Sequential/encoder.stages.3.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.0.block.1.2: torch.nn.modules.activation.SiLU/silu_15: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_15 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_45,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.0', 'encoder.stages.3.0.block', 'encoder.stages.3.0.block.1', 'encoder.stages.3.0.block.1.2', 'silu_15']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)

silu_15
val_67mean_5node_mean_5"
ReduceMean*
noop_with_empty_axes †*
keepdims†J≠
	namespaceü: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.0: torchvision.models.efficientnet.MBConv/encoder.stages.3.0.block: torch.nn.modules.container.Sequential/encoder.stages.3.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.0.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_5: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jë
pkg.torch.onnx.fx_nodew%mean_5 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_15, [-1, -2], True), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.0', 'encoder.stages.3.0.block', 'encoder.stages.3.0.block.2', 'encoder.stages.3.0.block.2.avgpool', 'mean_5']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
õ
mean_5
%encoder.stages.3.0.block.2.fc1.weight
#encoder.stages.3.0.block.2.fc1.bias	conv2d_26node_conv2d_26"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.0: torchvision.models.efficientnet.MBConv/encoder.stages.3.0.block: torch.nn.modules.container.Sequential/encoder.stages.3.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.0.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_26: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J‹
pkg.torch.onnx.fx_node¡%conv2d_26 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_5, %p_encoder_stages_3_0_block_2_fc1_weight, %p_encoder_stages_3_0_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.0', 'encoder.stages.3.0.block', 'encoder.stages.3.0.block.2', 'encoder.stages.3.0.block.2.fc1', 'conv2d_26']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_26val_246node_Sigmoid_246"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.0: torchvision.models.efficientnet.MBConv/encoder.stages.3.0.block: torch.nn.modules.container.Sequential/encoder.stages.3.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.0.block.2.activation: torch.nn.modules.activation.SiLU/silu_16: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_16 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_26,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.0', 'encoder.stages.3.0.block', 'encoder.stages.3.0.block.2', 'encoder.stages.3.0.block.2.activation', 'silu_16']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_26
val_246silu_16node_silu_16"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.0: torchvision.models.efficientnet.MBConv/encoder.stages.3.0.block: torch.nn.modules.container.Sequential/encoder.stages.3.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.0.block.2.activation: torch.nn.modules.activation.SiLU/silu_16: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_16 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_26,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.0', 'encoder.stages.3.0.block', 'encoder.stages.3.0.block.2', 'encoder.stages.3.0.block.2.activation', 'silu_16']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_16
%encoder.stages.3.0.block.2.fc2.weight
#encoder.stages.3.0.block.2.fc2.bias	conv2d_27node_conv2d_27"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.0: torchvision.models.efficientnet.MBConv/encoder.stages.3.0.block: torch.nn.modules.container.Sequential/encoder.stages.3.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.0.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_27: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_27 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_16, %p_encoder_stages_3_0_block_2_fc2_weight, %p_encoder_stages_3_0_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.0', 'encoder.stages.3.0.block', 'encoder.stages.3.0.block.2', 'encoder.stages.3.0.block.2.fc2', 'conv2d_27']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
º
	conv2d_27	sigmoid_5node_sigmoid_5"SigmoidJπ
	namespace´: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.0: torchvision.models.efficientnet.MBConv/encoder.stages.3.0.block: torch.nn.modules.container.Sequential/encoder.stages.3.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.0.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_5: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jé
pkg.torch.onnx.fx_nodet%sigmoid_5 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_27,), kwargs = {})JŒ
pkg.torch.onnx.name_scopesØ['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.0', 'encoder.stages.3.0.block', 'encoder.stages.3.0.block.2', 'encoder.stages.3.0.block.2.scale_activation', 'sigmoid_5']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
—
	sigmoid_5
silu_15mul_759node_mul_759"MulJ·
	namespace”: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.0: torchvision.models.efficientnet.MBConv/encoder.stages.3.0.block: torch.nn.modules.container.Sequential/encoder.stages.3.0.block.2: torchvision.ops.misc.SqueezeExcitation/mul_759: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jê
pkg.torch.onnx.fx_nodev%mul_759 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_5, %silu_15), kwargs = {})Jú
pkg.torch.onnx.name_scopes~['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.0', 'encoder.stages.3.0.block', 'encoder.stages.3.0.block.2', 'mul_759']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
ä
mul_759
#encoder.stages.3.0.block.3.0.weight
(encoder.stages.3.0.block.3.0.weight_bias
getitem_48node_Conv_1427"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.0: torchvision.models.efficientnet.MBConv/encoder.stages.3.0.block: torch.nn.modules.container.Sequential/encoder.stages.3.0.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.0.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_16: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_16 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_28, %p_encoder_stages_3_0_block_3_1_weight, %p_encoder_stages_3_0_block_3_1_bias, %b_encoder_stages_3_0_block_3_1_running_mean, %b_encoder_stages_3_0_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.0', 'encoder.stages.3.0.block', 'encoder.stages.3.0.block.3', 'encoder.stages.3.0.block.3.1', '_native_batch_norm_legit_no_training_16']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
ç

getitem_48
#encoder.stages.3.1.block.0.0.weight
(encoder.stages.3.1.block.0.0.weight_bias
getitem_51node_Conv_1429"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.1: torchvision.models.efficientnet.MBConv/encoder.stages.3.1.block: torch.nn.modules.container.Sequential/encoder.stages.3.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.1.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_17: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_17 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_29, %p_encoder_stages_3_1_block_0_1_weight, %p_encoder_stages_3_1_block_0_1_bias, %b_encoder_stages_3_1_block_0_1_running_mean, %b_encoder_stages_3_1_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.1', 'encoder.stages.3.1.block', 'encoder.stages.3.1.block.0', 'encoder.stages.3.1.block.0.1', '_native_batch_norm_legit_no_training_17']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
°

getitem_51val_269node_Sigmoid_269"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.1: torchvision.models.efficientnet.MBConv/encoder.stages.3.1.block: torch.nn.modules.container.Sequential/encoder.stages.3.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.1.block.0.2: torch.nn.modules.activation.SiLU/silu_17: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_17 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_51,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.1', 'encoder.stages.3.1.block', 'encoder.stages.3.1.block.0', 'encoder.stages.3.1.block.0.2', 'silu_17']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢

getitem_51
val_269silu_17node_silu_17"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.1: torchvision.models.efficientnet.MBConv/encoder.stages.3.1.block: torch.nn.modules.container.Sequential/encoder.stages.3.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.1.block.0.2: torch.nn.modules.activation.SiLU/silu_17: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_17 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_51,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.1', 'encoder.stages.3.1.block', 'encoder.stages.3.1.block.0', 'encoder.stages.3.1.block.0.2', 'silu_17']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ã
silu_17
#encoder.stages.3.1.block.1.0.weight
(encoder.stages.3.1.block.1.0.weight_bias
getitem_54node_Conv_1431"Conv*
group††*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.1: torchvision.models.efficientnet.MBConv/encoder.stages.3.1.block: torch.nn.modules.container.Sequential/encoder.stages.3.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.1.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_18: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_18 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_30, %p_encoder_stages_3_1_block_1_1_weight, %p_encoder_stages_3_1_block_1_1_bias, %b_encoder_stages_3_1_block_1_1_running_mean, %b_encoder_stages_3_1_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.1', 'encoder.stages.3.1.block', 'encoder.stages.3.1.block.1', 'encoder.stages.3.1.block.1.1', '_native_batch_norm_legit_no_training_18']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
°

getitem_54val_281node_Sigmoid_281"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.1: torchvision.models.efficientnet.MBConv/encoder.stages.3.1.block: torch.nn.modules.container.Sequential/encoder.stages.3.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.1.block.1.2: torch.nn.modules.activation.SiLU/silu_18: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_18 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_54,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.1', 'encoder.stages.3.1.block', 'encoder.stages.3.1.block.1', 'encoder.stages.3.1.block.1.2', 'silu_18']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢

getitem_54
val_281silu_18node_silu_18"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.1: torchvision.models.efficientnet.MBConv/encoder.stages.3.1.block: torch.nn.modules.container.Sequential/encoder.stages.3.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.1.block.1.2: torch.nn.modules.activation.SiLU/silu_18: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_18 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_54,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.1', 'encoder.stages.3.1.block', 'encoder.stages.3.1.block.1', 'encoder.stages.3.1.block.1.2', 'silu_18']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)

silu_18
val_67mean_6node_mean_6"
ReduceMean*
noop_with_empty_axes †*
keepdims†J≠
	namespaceü: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.1: torchvision.models.efficientnet.MBConv/encoder.stages.3.1.block: torch.nn.modules.container.Sequential/encoder.stages.3.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.1.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_6: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jë
pkg.torch.onnx.fx_nodew%mean_6 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_18, [-1, -2], True), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.1', 'encoder.stages.3.1.block', 'encoder.stages.3.1.block.2', 'encoder.stages.3.1.block.2.avgpool', 'mean_6']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
õ
mean_6
%encoder.stages.3.1.block.2.fc1.weight
#encoder.stages.3.1.block.2.fc1.bias	conv2d_31node_conv2d_31"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.1: torchvision.models.efficientnet.MBConv/encoder.stages.3.1.block: torch.nn.modules.container.Sequential/encoder.stages.3.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.1.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_31: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J‹
pkg.torch.onnx.fx_node¡%conv2d_31 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_6, %p_encoder_stages_3_1_block_2_fc1_weight, %p_encoder_stages_3_1_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.1', 'encoder.stages.3.1.block', 'encoder.stages.3.1.block.2', 'encoder.stages.3.1.block.2.fc1', 'conv2d_31']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_31val_284node_Sigmoid_284"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.1: torchvision.models.efficientnet.MBConv/encoder.stages.3.1.block: torch.nn.modules.container.Sequential/encoder.stages.3.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.1.block.2.activation: torch.nn.modules.activation.SiLU/silu_19: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_19 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_31,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.1', 'encoder.stages.3.1.block', 'encoder.stages.3.1.block.2', 'encoder.stages.3.1.block.2.activation', 'silu_19']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_31
val_284silu_19node_silu_19"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.1: torchvision.models.efficientnet.MBConv/encoder.stages.3.1.block: torch.nn.modules.container.Sequential/encoder.stages.3.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.1.block.2.activation: torch.nn.modules.activation.SiLU/silu_19: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_19 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_31,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.1', 'encoder.stages.3.1.block', 'encoder.stages.3.1.block.2', 'encoder.stages.3.1.block.2.activation', 'silu_19']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_19
%encoder.stages.3.1.block.2.fc2.weight
#encoder.stages.3.1.block.2.fc2.bias	conv2d_32node_conv2d_32"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.1: torchvision.models.efficientnet.MBConv/encoder.stages.3.1.block: torch.nn.modules.container.Sequential/encoder.stages.3.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.1.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_32: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_32 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_19, %p_encoder_stages_3_1_block_2_fc2_weight, %p_encoder_stages_3_1_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.1', 'encoder.stages.3.1.block', 'encoder.stages.3.1.block.2', 'encoder.stages.3.1.block.2.fc2', 'conv2d_32']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
º
	conv2d_32	sigmoid_6node_sigmoid_6"SigmoidJπ
	namespace´: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.1: torchvision.models.efficientnet.MBConv/encoder.stages.3.1.block: torch.nn.modules.container.Sequential/encoder.stages.3.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.1.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_6: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jé
pkg.torch.onnx.fx_nodet%sigmoid_6 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_32,), kwargs = {})JŒ
pkg.torch.onnx.name_scopesØ['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.1', 'encoder.stages.3.1.block', 'encoder.stages.3.1.block.2', 'encoder.stages.3.1.block.2.scale_activation', 'sigmoid_6']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
—
	sigmoid_6
silu_18mul_876node_mul_876"MulJ·
	namespace”: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.1: torchvision.models.efficientnet.MBConv/encoder.stages.3.1.block: torch.nn.modules.container.Sequential/encoder.stages.3.1.block.2: torchvision.ops.misc.SqueezeExcitation/mul_876: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jê
pkg.torch.onnx.fx_nodev%mul_876 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_6, %silu_18), kwargs = {})Jú
pkg.torch.onnx.name_scopes~['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.1', 'encoder.stages.3.1.block', 'encoder.stages.3.1.block.2', 'mul_876']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
ä
mul_876
#encoder.stages.3.1.block.3.0.weight
(encoder.stages.3.1.block.3.0.weight_bias
getitem_57node_Conv_1433"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.1: torchvision.models.efficientnet.MBConv/encoder.stages.3.1.block: torch.nn.modules.container.Sequential/encoder.stages.3.1.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.1.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_19: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_19 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_33, %p_encoder_stages_3_1_block_3_1_weight, %p_encoder_stages_3_1_block_3_1_bias, %b_encoder_stages_3_1_block_3_1_running_mean, %b_encoder_stages_3_1_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.1', 'encoder.stages.3.1.block', 'encoder.stages.3.1.block.3', 'encoder.stages.3.1.block.3.1', '_native_batch_norm_legit_no_training_19']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ó


getitem_57

getitem_48add_701node_add_701"AddJﬁ
	namespace–: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.1: torchvision.models.efficientnet.MBConv/add_701: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_701 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_57, %getitem_48), kwargs = {})Jb
pkg.torch.onnx.name_scopesD['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.1', 'add_701']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
ä
add_701
#encoder.stages.3.2.block.0.0.weight
(encoder.stages.3.2.block.0.0.weight_bias
getitem_60node_Conv_1435"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.2: torchvision.models.efficientnet.MBConv/encoder.stages.3.2.block: torch.nn.modules.container.Sequential/encoder.stages.3.2.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.2.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_20: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_20 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_34, %p_encoder_stages_3_2_block_0_1_weight, %p_encoder_stages_3_2_block_0_1_bias, %b_encoder_stages_3_2_block_0_1_running_mean, %b_encoder_stages_3_2_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.2', 'encoder.stages.3.2.block', 'encoder.stages.3.2.block.0', 'encoder.stages.3.2.block.0.1', '_native_batch_norm_legit_no_training_20']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
°

getitem_60val_307node_Sigmoid_307"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.2: torchvision.models.efficientnet.MBConv/encoder.stages.3.2.block: torch.nn.modules.container.Sequential/encoder.stages.3.2.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.2.block.0.2: torch.nn.modules.activation.SiLU/silu_20: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_20 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_60,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.2', 'encoder.stages.3.2.block', 'encoder.stages.3.2.block.0', 'encoder.stages.3.2.block.0.2', 'silu_20']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢

getitem_60
val_307silu_20node_silu_20"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.2: torchvision.models.efficientnet.MBConv/encoder.stages.3.2.block: torch.nn.modules.container.Sequential/encoder.stages.3.2.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.2.block.0.2: torch.nn.modules.activation.SiLU/silu_20: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_20 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_60,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.2', 'encoder.stages.3.2.block', 'encoder.stages.3.2.block.0', 'encoder.stages.3.2.block.0.2', 'silu_20']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ã
silu_20
#encoder.stages.3.2.block.1.0.weight
(encoder.stages.3.2.block.1.0.weight_bias
getitem_63node_Conv_1437"Conv*
group††*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.2: torchvision.models.efficientnet.MBConv/encoder.stages.3.2.block: torch.nn.modules.container.Sequential/encoder.stages.3.2.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.2.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_21: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_21 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_35, %p_encoder_stages_3_2_block_1_1_weight, %p_encoder_stages_3_2_block_1_1_bias, %b_encoder_stages_3_2_block_1_1_running_mean, %b_encoder_stages_3_2_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.2', 'encoder.stages.3.2.block', 'encoder.stages.3.2.block.1', 'encoder.stages.3.2.block.1.1', '_native_batch_norm_legit_no_training_21']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
°

getitem_63val_319node_Sigmoid_319"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.2: torchvision.models.efficientnet.MBConv/encoder.stages.3.2.block: torch.nn.modules.container.Sequential/encoder.stages.3.2.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.2.block.1.2: torch.nn.modules.activation.SiLU/silu_21: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_21 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_63,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.2', 'encoder.stages.3.2.block', 'encoder.stages.3.2.block.1', 'encoder.stages.3.2.block.1.2', 'silu_21']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢

getitem_63
val_319silu_21node_silu_21"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.2: torchvision.models.efficientnet.MBConv/encoder.stages.3.2.block: torch.nn.modules.container.Sequential/encoder.stages.3.2.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.2.block.1.2: torch.nn.modules.activation.SiLU/silu_21: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_21 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_63,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.2', 'encoder.stages.3.2.block', 'encoder.stages.3.2.block.1', 'encoder.stages.3.2.block.1.2', 'silu_21']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)

silu_21
val_67mean_7node_mean_7"
ReduceMean*
noop_with_empty_axes †*
keepdims†J≠
	namespaceü: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.2: torchvision.models.efficientnet.MBConv/encoder.stages.3.2.block: torch.nn.modules.container.Sequential/encoder.stages.3.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.2.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_7: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jë
pkg.torch.onnx.fx_nodew%mean_7 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_21, [-1, -2], True), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.2', 'encoder.stages.3.2.block', 'encoder.stages.3.2.block.2', 'encoder.stages.3.2.block.2.avgpool', 'mean_7']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
õ
mean_7
%encoder.stages.3.2.block.2.fc1.weight
#encoder.stages.3.2.block.2.fc1.bias	conv2d_36node_conv2d_36"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.2: torchvision.models.efficientnet.MBConv/encoder.stages.3.2.block: torch.nn.modules.container.Sequential/encoder.stages.3.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.2.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_36: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J‹
pkg.torch.onnx.fx_node¡%conv2d_36 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_7, %p_encoder_stages_3_2_block_2_fc1_weight, %p_encoder_stages_3_2_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.2', 'encoder.stages.3.2.block', 'encoder.stages.3.2.block.2', 'encoder.stages.3.2.block.2.fc1', 'conv2d_36']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_36val_322node_Sigmoid_322"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.2: torchvision.models.efficientnet.MBConv/encoder.stages.3.2.block: torch.nn.modules.container.Sequential/encoder.stages.3.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.2.block.2.activation: torch.nn.modules.activation.SiLU/silu_22: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_22 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_36,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.2', 'encoder.stages.3.2.block', 'encoder.stages.3.2.block.2', 'encoder.stages.3.2.block.2.activation', 'silu_22']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_36
val_322silu_22node_silu_22"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.2: torchvision.models.efficientnet.MBConv/encoder.stages.3.2.block: torch.nn.modules.container.Sequential/encoder.stages.3.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.2.block.2.activation: torch.nn.modules.activation.SiLU/silu_22: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_22 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_36,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.2', 'encoder.stages.3.2.block', 'encoder.stages.3.2.block.2', 'encoder.stages.3.2.block.2.activation', 'silu_22']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_22
%encoder.stages.3.2.block.2.fc2.weight
#encoder.stages.3.2.block.2.fc2.bias	conv2d_37node_conv2d_37"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.2: torchvision.models.efficientnet.MBConv/encoder.stages.3.2.block: torch.nn.modules.container.Sequential/encoder.stages.3.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.2.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_37: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_37 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_22, %p_encoder_stages_3_2_block_2_fc2_weight, %p_encoder_stages_3_2_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.2', 'encoder.stages.3.2.block', 'encoder.stages.3.2.block.2', 'encoder.stages.3.2.block.2.fc2', 'conv2d_37']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
º
	conv2d_37	sigmoid_7node_sigmoid_7"SigmoidJπ
	namespace´: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.2: torchvision.models.efficientnet.MBConv/encoder.stages.3.2.block: torch.nn.modules.container.Sequential/encoder.stages.3.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.3.2.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_7: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jé
pkg.torch.onnx.fx_nodet%sigmoid_7 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_37,), kwargs = {})JŒ
pkg.torch.onnx.name_scopesØ['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.2', 'encoder.stages.3.2.block', 'encoder.stages.3.2.block.2', 'encoder.stages.3.2.block.2.scale_activation', 'sigmoid_7']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
÷
	sigmoid_7
silu_21mul_1005node_mul_1005"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.2: torchvision.models.efficientnet.MBConv/encoder.stages.3.2.block: torch.nn.modules.container.Sequential/encoder.stages.3.2.block.2: torchvision.ops.misc.SqueezeExcitation/mul_1005: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jë
pkg.torch.onnx.fx_nodew%mul_1005 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_7, %silu_21), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.2', 'encoder.stages.3.2.block', 'encoder.stages.3.2.block.2', 'mul_1005']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
ã
mul_1005
#encoder.stages.3.2.block.3.0.weight
(encoder.stages.3.2.block.3.0.weight_bias
getitem_66node_Conv_1439"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.2: torchvision.models.efficientnet.MBConv/encoder.stages.3.2.block: torch.nn.modules.container.Sequential/encoder.stages.3.2.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.3.2.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_22: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_22 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_38, %p_encoder_stages_3_2_block_3_1_weight, %p_encoder_stages_3_2_block_3_1_bias, %b_encoder_stages_3_2_block_3_1_running_mean, %b_encoder_stages_3_2_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.2', 'encoder.stages.3.2.block', 'encoder.stages.3.2.block.3', 'encoder.stages.3.2.block.3.1', '_native_batch_norm_legit_no_training_22']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ë


getitem_66
add_701add_805node_add_805"AddJﬁ
	namespace–: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.3: torch.nn.modules.container.Sequential/encoder.stages.3.2: torchvision.models.efficientnet.MBConv/add_805: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jë
pkg.torch.onnx.fx_nodew%add_805 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_66, %add_701), kwargs = {})Jb
pkg.torch.onnx.name_scopesD['', 'encoder', 'encoder.stages.3', 'encoder.stages.3.2', 'add_805']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
ä
add_805
#encoder.stages.4.0.block.0.0.weight
(encoder.stages.4.0.block.0.0.weight_bias
getitem_69node_Conv_1441"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.0: torchvision.models.efficientnet.MBConv/encoder.stages.4.0.block: torch.nn.modules.container.Sequential/encoder.stages.4.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.0.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_23: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_23 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_39, %p_encoder_stages_4_0_block_0_1_weight, %p_encoder_stages_4_0_block_0_1_bias, %b_encoder_stages_4_0_block_0_1_running_mean, %b_encoder_stages_4_0_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.0', 'encoder.stages.4.0.block', 'encoder.stages.4.0.block.0', 'encoder.stages.4.0.block.0.1', '_native_batch_norm_legit_no_training_23']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
°

getitem_69val_345node_Sigmoid_345"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.0: torchvision.models.efficientnet.MBConv/encoder.stages.4.0.block: torch.nn.modules.container.Sequential/encoder.stages.4.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.0.block.0.2: torch.nn.modules.activation.SiLU/silu_23: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_23 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_69,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.0', 'encoder.stages.4.0.block', 'encoder.stages.4.0.block.0', 'encoder.stages.4.0.block.0.2', 'silu_23']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢

getitem_69
val_345silu_23node_silu_23"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.0: torchvision.models.efficientnet.MBConv/encoder.stages.4.0.block: torch.nn.modules.container.Sequential/encoder.stages.4.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.0.block.0.2: torch.nn.modules.activation.SiLU/silu_23: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_23 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_69,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.0', 'encoder.stages.4.0.block', 'encoder.stages.4.0.block.0', 'encoder.stages.4.0.block.0.2', 'silu_23']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ã
silu_23
#encoder.stages.4.0.block.1.0.weight
(encoder.stages.4.0.block.1.0.weight_bias
getitem_72node_Conv_1443"Conv*
group††*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.0: torchvision.models.efficientnet.MBConv/encoder.stages.4.0.block: torch.nn.modules.container.Sequential/encoder.stages.4.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.0.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_24: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_24 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_40, %p_encoder_stages_4_0_block_1_1_weight, %p_encoder_stages_4_0_block_1_1_bias, %b_encoder_stages_4_0_block_1_1_running_mean, %b_encoder_stages_4_0_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.0', 'encoder.stages.4.0.block', 'encoder.stages.4.0.block.1', 'encoder.stages.4.0.block.1.1', '_native_batch_norm_legit_no_training_24']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
°

getitem_72val_357node_Sigmoid_357"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.0: torchvision.models.efficientnet.MBConv/encoder.stages.4.0.block: torch.nn.modules.container.Sequential/encoder.stages.4.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.0.block.1.2: torch.nn.modules.activation.SiLU/silu_24: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_24 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_72,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.0', 'encoder.stages.4.0.block', 'encoder.stages.4.0.block.1', 'encoder.stages.4.0.block.1.2', 'silu_24']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢

getitem_72
val_357silu_24node_silu_24"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.0: torchvision.models.efficientnet.MBConv/encoder.stages.4.0.block: torch.nn.modules.container.Sequential/encoder.stages.4.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.0.block.1.2: torch.nn.modules.activation.SiLU/silu_24: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_24 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_72,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.0', 'encoder.stages.4.0.block', 'encoder.stages.4.0.block.1', 'encoder.stages.4.0.block.1.2', 'silu_24']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)

silu_24
val_67mean_8node_mean_8"
ReduceMean*
noop_with_empty_axes †*
keepdims†J≠
	namespaceü: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.0: torchvision.models.efficientnet.MBConv/encoder.stages.4.0.block: torch.nn.modules.container.Sequential/encoder.stages.4.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.0.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_8: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jë
pkg.torch.onnx.fx_nodew%mean_8 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_24, [-1, -2], True), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.0', 'encoder.stages.4.0.block', 'encoder.stages.4.0.block.2', 'encoder.stages.4.0.block.2.avgpool', 'mean_8']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
õ
mean_8
%encoder.stages.4.0.block.2.fc1.weight
#encoder.stages.4.0.block.2.fc1.bias	conv2d_41node_conv2d_41"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.0: torchvision.models.efficientnet.MBConv/encoder.stages.4.0.block: torch.nn.modules.container.Sequential/encoder.stages.4.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.0.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_41: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J‹
pkg.torch.onnx.fx_node¡%conv2d_41 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_8, %p_encoder_stages_4_0_block_2_fc1_weight, %p_encoder_stages_4_0_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.0', 'encoder.stages.4.0.block', 'encoder.stages.4.0.block.2', 'encoder.stages.4.0.block.2.fc1', 'conv2d_41']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_41val_360node_Sigmoid_360"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.0: torchvision.models.efficientnet.MBConv/encoder.stages.4.0.block: torch.nn.modules.container.Sequential/encoder.stages.4.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.0.block.2.activation: torch.nn.modules.activation.SiLU/silu_25: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_25 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_41,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.0', 'encoder.stages.4.0.block', 'encoder.stages.4.0.block.2', 'encoder.stages.4.0.block.2.activation', 'silu_25']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_41
val_360silu_25node_silu_25"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.0: torchvision.models.efficientnet.MBConv/encoder.stages.4.0.block: torch.nn.modules.container.Sequential/encoder.stages.4.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.0.block.2.activation: torch.nn.modules.activation.SiLU/silu_25: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_25 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_41,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.0', 'encoder.stages.4.0.block', 'encoder.stages.4.0.block.2', 'encoder.stages.4.0.block.2.activation', 'silu_25']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_25
%encoder.stages.4.0.block.2.fc2.weight
#encoder.stages.4.0.block.2.fc2.bias	conv2d_42node_conv2d_42"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.0: torchvision.models.efficientnet.MBConv/encoder.stages.4.0.block: torch.nn.modules.container.Sequential/encoder.stages.4.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.0.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_42: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_42 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_25, %p_encoder_stages_4_0_block_2_fc2_weight, %p_encoder_stages_4_0_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.0', 'encoder.stages.4.0.block', 'encoder.stages.4.0.block.2', 'encoder.stages.4.0.block.2.fc2', 'conv2d_42']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
º
	conv2d_42	sigmoid_8node_sigmoid_8"SigmoidJπ
	namespace´: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.0: torchvision.models.efficientnet.MBConv/encoder.stages.4.0.block: torch.nn.modules.container.Sequential/encoder.stages.4.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.0.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_8: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jé
pkg.torch.onnx.fx_nodet%sigmoid_8 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_42,), kwargs = {})JŒ
pkg.torch.onnx.name_scopesØ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.0', 'encoder.stages.4.0.block', 'encoder.stages.4.0.block.2', 'encoder.stages.4.0.block.2.scale_activation', 'sigmoid_8']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
÷
	sigmoid_8
silu_24mul_1134node_mul_1134"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.0: torchvision.models.efficientnet.MBConv/encoder.stages.4.0.block: torch.nn.modules.container.Sequential/encoder.stages.4.0.block.2: torchvision.ops.misc.SqueezeExcitation/mul_1134: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jë
pkg.torch.onnx.fx_nodew%mul_1134 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_8, %silu_24), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.0', 'encoder.stages.4.0.block', 'encoder.stages.4.0.block.2', 'mul_1134']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
ã
mul_1134
#encoder.stages.4.0.block.3.0.weight
(encoder.stages.4.0.block.3.0.weight_bias
getitem_75node_Conv_1445"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.0: torchvision.models.efficientnet.MBConv/encoder.stages.4.0.block: torch.nn.modules.container.Sequential/encoder.stages.4.0.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.0.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_25: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_25 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_43, %p_encoder_stages_4_0_block_3_1_weight, %p_encoder_stages_4_0_block_3_1_bias, %b_encoder_stages_4_0_block_3_1_running_mean, %b_encoder_stages_4_0_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.0', 'encoder.stages.4.0.block', 'encoder.stages.4.0.block.3', 'encoder.stages.4.0.block.3.1', '_native_batch_norm_legit_no_training_25']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
ç

getitem_75
#encoder.stages.4.1.block.0.0.weight
(encoder.stages.4.1.block.0.0.weight_bias
getitem_78node_Conv_1447"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.1: torchvision.models.efficientnet.MBConv/encoder.stages.4.1.block: torch.nn.modules.container.Sequential/encoder.stages.4.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.1.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_26: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_26 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_44, %p_encoder_stages_4_1_block_0_1_weight, %p_encoder_stages_4_1_block_0_1_bias, %b_encoder_stages_4_1_block_0_1_running_mean, %b_encoder_stages_4_1_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.1', 'encoder.stages.4.1.block', 'encoder.stages.4.1.block.0', 'encoder.stages.4.1.block.0.1', '_native_batch_norm_legit_no_training_26']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
°

getitem_78val_383node_Sigmoid_383"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.1: torchvision.models.efficientnet.MBConv/encoder.stages.4.1.block: torch.nn.modules.container.Sequential/encoder.stages.4.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.1.block.0.2: torch.nn.modules.activation.SiLU/silu_26: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_26 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_78,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.1', 'encoder.stages.4.1.block', 'encoder.stages.4.1.block.0', 'encoder.stages.4.1.block.0.2', 'silu_26']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢

getitem_78
val_383silu_26node_silu_26"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.1: torchvision.models.efficientnet.MBConv/encoder.stages.4.1.block: torch.nn.modules.container.Sequential/encoder.stages.4.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.1.block.0.2: torch.nn.modules.activation.SiLU/silu_26: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_26 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_78,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.1', 'encoder.stages.4.1.block', 'encoder.stages.4.1.block.0', 'encoder.stages.4.1.block.0.2', 'silu_26']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ã
silu_26
#encoder.stages.4.1.block.1.0.weight
(encoder.stages.4.1.block.1.0.weight_bias
getitem_81node_Conv_1449"Conv*
group¿†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.1: torchvision.models.efficientnet.MBConv/encoder.stages.4.1.block: torch.nn.modules.container.Sequential/encoder.stages.4.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.1.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_27: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_27 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_45, %p_encoder_stages_4_1_block_1_1_weight, %p_encoder_stages_4_1_block_1_1_bias, %b_encoder_stages_4_1_block_1_1_running_mean, %b_encoder_stages_4_1_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.1', 'encoder.stages.4.1.block', 'encoder.stages.4.1.block.1', 'encoder.stages.4.1.block.1.1', '_native_batch_norm_legit_no_training_27']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
°

getitem_81val_395node_Sigmoid_395"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.1: torchvision.models.efficientnet.MBConv/encoder.stages.4.1.block: torch.nn.modules.container.Sequential/encoder.stages.4.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.1.block.1.2: torch.nn.modules.activation.SiLU/silu_27: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_27 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_81,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.1', 'encoder.stages.4.1.block', 'encoder.stages.4.1.block.1', 'encoder.stages.4.1.block.1.2', 'silu_27']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢

getitem_81
val_395silu_27node_silu_27"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.1: torchvision.models.efficientnet.MBConv/encoder.stages.4.1.block: torch.nn.modules.container.Sequential/encoder.stages.4.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.1.block.1.2: torch.nn.modules.activation.SiLU/silu_27: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_27 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_81,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.1', 'encoder.stages.4.1.block', 'encoder.stages.4.1.block.1', 'encoder.stages.4.1.block.1.2', 'silu_27']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)

silu_27
val_67mean_9node_mean_9"
ReduceMean*
noop_with_empty_axes †*
keepdims†J≠
	namespaceü: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.1: torchvision.models.efficientnet.MBConv/encoder.stages.4.1.block: torch.nn.modules.container.Sequential/encoder.stages.4.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.1.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_9: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jë
pkg.torch.onnx.fx_nodew%mean_9 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_27, [-1, -2], True), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.1', 'encoder.stages.4.1.block', 'encoder.stages.4.1.block.2', 'encoder.stages.4.1.block.2.avgpool', 'mean_9']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
õ
mean_9
%encoder.stages.4.1.block.2.fc1.weight
#encoder.stages.4.1.block.2.fc1.bias	conv2d_46node_conv2d_46"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.1: torchvision.models.efficientnet.MBConv/encoder.stages.4.1.block: torch.nn.modules.container.Sequential/encoder.stages.4.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.1.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_46: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J‹
pkg.torch.onnx.fx_node¡%conv2d_46 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_9, %p_encoder_stages_4_1_block_2_fc1_weight, %p_encoder_stages_4_1_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.1', 'encoder.stages.4.1.block', 'encoder.stages.4.1.block.2', 'encoder.stages.4.1.block.2.fc1', 'conv2d_46']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_46val_398node_Sigmoid_398"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.1: torchvision.models.efficientnet.MBConv/encoder.stages.4.1.block: torch.nn.modules.container.Sequential/encoder.stages.4.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.1.block.2.activation: torch.nn.modules.activation.SiLU/silu_28: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_28 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_46,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.1', 'encoder.stages.4.1.block', 'encoder.stages.4.1.block.2', 'encoder.stages.4.1.block.2.activation', 'silu_28']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_46
val_398silu_28node_silu_28"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.1: torchvision.models.efficientnet.MBConv/encoder.stages.4.1.block: torch.nn.modules.container.Sequential/encoder.stages.4.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.1.block.2.activation: torch.nn.modules.activation.SiLU/silu_28: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_28 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_46,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.1', 'encoder.stages.4.1.block', 'encoder.stages.4.1.block.2', 'encoder.stages.4.1.block.2.activation', 'silu_28']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_28
%encoder.stages.4.1.block.2.fc2.weight
#encoder.stages.4.1.block.2.fc2.bias	conv2d_47node_conv2d_47"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.1: torchvision.models.efficientnet.MBConv/encoder.stages.4.1.block: torch.nn.modules.container.Sequential/encoder.stages.4.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.1.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_47: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_47 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_28, %p_encoder_stages_4_1_block_2_fc2_weight, %p_encoder_stages_4_1_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.1', 'encoder.stages.4.1.block', 'encoder.stages.4.1.block.2', 'encoder.stages.4.1.block.2.fc2', 'conv2d_47']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
º
	conv2d_47	sigmoid_9node_sigmoid_9"SigmoidJπ
	namespace´: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.1: torchvision.models.efficientnet.MBConv/encoder.stages.4.1.block: torch.nn.modules.container.Sequential/encoder.stages.4.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.1.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_9: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jé
pkg.torch.onnx.fx_nodet%sigmoid_9 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_47,), kwargs = {})JŒ
pkg.torch.onnx.name_scopesØ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.1', 'encoder.stages.4.1.block', 'encoder.stages.4.1.block.2', 'encoder.stages.4.1.block.2.scale_activation', 'sigmoid_9']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
÷
	sigmoid_9
silu_27mul_1251node_mul_1251"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.1: torchvision.models.efficientnet.MBConv/encoder.stages.4.1.block: torch.nn.modules.container.Sequential/encoder.stages.4.1.block.2: torchvision.ops.misc.SqueezeExcitation/mul_1251: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jë
pkg.torch.onnx.fx_nodew%mul_1251 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_9, %silu_27), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.1', 'encoder.stages.4.1.block', 'encoder.stages.4.1.block.2', 'mul_1251']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
ã
mul_1251
#encoder.stages.4.1.block.3.0.weight
(encoder.stages.4.1.block.3.0.weight_bias
getitem_84node_Conv_1451"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.1: torchvision.models.efficientnet.MBConv/encoder.stages.4.1.block: torch.nn.modules.container.Sequential/encoder.stages.4.1.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.1.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_28: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_28 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_48, %p_encoder_stages_4_1_block_3_1_weight, %p_encoder_stages_4_1_block_3_1_bias, %b_encoder_stages_4_1_block_3_1_running_mean, %b_encoder_stages_4_1_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.1', 'encoder.stages.4.1.block', 'encoder.stages.4.1.block.3', 'encoder.stages.4.1.block.3.1', '_native_batch_norm_legit_no_training_28']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ó


getitem_84

getitem_75add_997node_add_997"AddJﬁ
	namespace–: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.1: torchvision.models.efficientnet.MBConv/add_997: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_997 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_84, %getitem_75), kwargs = {})Jb
pkg.torch.onnx.name_scopesD['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.1', 'add_997']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
ä
add_997
#encoder.stages.4.2.block.0.0.weight
(encoder.stages.4.2.block.0.0.weight_bias
getitem_87node_Conv_1453"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.2: torchvision.models.efficientnet.MBConv/encoder.stages.4.2.block: torch.nn.modules.container.Sequential/encoder.stages.4.2.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.2.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_29: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_29 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_49, %p_encoder_stages_4_2_block_0_1_weight, %p_encoder_stages_4_2_block_0_1_bias, %b_encoder_stages_4_2_block_0_1_running_mean, %b_encoder_stages_4_2_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.2', 'encoder.stages.4.2.block', 'encoder.stages.4.2.block.0', 'encoder.stages.4.2.block.0.1', '_native_batch_norm_legit_no_training_29']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
°

getitem_87val_421node_Sigmoid_421"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.2: torchvision.models.efficientnet.MBConv/encoder.stages.4.2.block: torch.nn.modules.container.Sequential/encoder.stages.4.2.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.2.block.0.2: torch.nn.modules.activation.SiLU/silu_29: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_29 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_87,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.2', 'encoder.stages.4.2.block', 'encoder.stages.4.2.block.0', 'encoder.stages.4.2.block.0.2', 'silu_29']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢

getitem_87
val_421silu_29node_silu_29"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.2: torchvision.models.efficientnet.MBConv/encoder.stages.4.2.block: torch.nn.modules.container.Sequential/encoder.stages.4.2.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.2.block.0.2: torch.nn.modules.activation.SiLU/silu_29: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_29 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_87,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.2', 'encoder.stages.4.2.block', 'encoder.stages.4.2.block.0', 'encoder.stages.4.2.block.0.2', 'silu_29']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ã
silu_29
#encoder.stages.4.2.block.1.0.weight
(encoder.stages.4.2.block.1.0.weight_bias
getitem_90node_Conv_1455"Conv*
group¿†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.2: torchvision.models.efficientnet.MBConv/encoder.stages.4.2.block: torch.nn.modules.container.Sequential/encoder.stages.4.2.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.2.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_30: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_30 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_50, %p_encoder_stages_4_2_block_1_1_weight, %p_encoder_stages_4_2_block_1_1_bias, %b_encoder_stages_4_2_block_1_1_running_mean, %b_encoder_stages_4_2_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.2', 'encoder.stages.4.2.block', 'encoder.stages.4.2.block.1', 'encoder.stages.4.2.block.1.1', '_native_batch_norm_legit_no_training_30']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
°

getitem_90val_433node_Sigmoid_433"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.2: torchvision.models.efficientnet.MBConv/encoder.stages.4.2.block: torch.nn.modules.container.Sequential/encoder.stages.4.2.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.2.block.1.2: torch.nn.modules.activation.SiLU/silu_30: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_30 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_90,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.2', 'encoder.stages.4.2.block', 'encoder.stages.4.2.block.1', 'encoder.stages.4.2.block.1.2', 'silu_30']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢

getitem_90
val_433silu_30node_silu_30"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.2: torchvision.models.efficientnet.MBConv/encoder.stages.4.2.block: torch.nn.modules.container.Sequential/encoder.stages.4.2.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.2.block.1.2: torch.nn.modules.activation.SiLU/silu_30: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_30 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_90,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.2', 'encoder.stages.4.2.block', 'encoder.stages.4.2.block.1', 'encoder.stages.4.2.block.1.2', 'silu_30']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ı
silu_30
val_67mean_10node_mean_10"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÆ
	namespace†: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.2: torchvision.models.efficientnet.MBConv/encoder.stages.4.2.block: torch.nn.modules.container.Sequential/encoder.stages.4.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.2.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_10: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jí
pkg.torch.onnx.fx_nodex%mean_10 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_30, [-1, -2], True), kwargs = {})J√
pkg.torch.onnx.name_scopes§['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.2', 'encoder.stages.4.2.block', 'encoder.stages.4.2.block.2', 'encoder.stages.4.2.block.2.avgpool', 'mean_10']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
ù
mean_10
%encoder.stages.4.2.block.2.fc1.weight
#encoder.stages.4.2.block.2.fc1.bias	conv2d_51node_conv2d_51"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.2: torchvision.models.efficientnet.MBConv/encoder.stages.4.2.block: torch.nn.modules.container.Sequential/encoder.stages.4.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.2.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_51: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_51 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_10, %p_encoder_stages_4_2_block_2_fc1_weight, %p_encoder_stages_4_2_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.2', 'encoder.stages.4.2.block', 'encoder.stages.4.2.block.2', 'encoder.stages.4.2.block.2.fc1', 'conv2d_51']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_51val_436node_Sigmoid_436"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.2: torchvision.models.efficientnet.MBConv/encoder.stages.4.2.block: torch.nn.modules.container.Sequential/encoder.stages.4.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.2.block.2.activation: torch.nn.modules.activation.SiLU/silu_31: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_31 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_51,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.2', 'encoder.stages.4.2.block', 'encoder.stages.4.2.block.2', 'encoder.stages.4.2.block.2.activation', 'silu_31']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_51
val_436silu_31node_silu_31"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.2: torchvision.models.efficientnet.MBConv/encoder.stages.4.2.block: torch.nn.modules.container.Sequential/encoder.stages.4.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.2.block.2.activation: torch.nn.modules.activation.SiLU/silu_31: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_31 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_51,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.2', 'encoder.stages.4.2.block', 'encoder.stages.4.2.block.2', 'encoder.stages.4.2.block.2.activation', 'silu_31']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_31
%encoder.stages.4.2.block.2.fc2.weight
#encoder.stages.4.2.block.2.fc2.bias	conv2d_52node_conv2d_52"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.2: torchvision.models.efficientnet.MBConv/encoder.stages.4.2.block: torch.nn.modules.container.Sequential/encoder.stages.4.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.2.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_52: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_52 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_31, %p_encoder_stages_4_2_block_2_fc2_weight, %p_encoder_stages_4_2_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.2', 'encoder.stages.4.2.block', 'encoder.stages.4.2.block.2', 'encoder.stages.4.2.block.2.fc2', 'conv2d_52']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
¡
	conv2d_52
sigmoid_10node_sigmoid_10"SigmoidJ∫
	namespace¨: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.2: torchvision.models.efficientnet.MBConv/encoder.stages.4.2.block: torch.nn.modules.container.Sequential/encoder.stages.4.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.2.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_10: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jè
pkg.torch.onnx.fx_nodeu%sigmoid_10 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_52,), kwargs = {})Jœ
pkg.torch.onnx.name_scopes∞['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.2', 'encoder.stages.4.2.block', 'encoder.stages.4.2.block.2', 'encoder.stages.4.2.block.2.scale_activation', 'sigmoid_10']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ÿ

sigmoid_10
silu_30mul_1380node_mul_1380"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.2: torchvision.models.efficientnet.MBConv/encoder.stages.4.2.block: torch.nn.modules.container.Sequential/encoder.stages.4.2.block.2: torchvision.ops.misc.SqueezeExcitation/mul_1380: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_1380 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_10, %silu_30), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.2', 'encoder.stages.4.2.block', 'encoder.stages.4.2.block.2', 'mul_1380']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
ã
mul_1380
#encoder.stages.4.2.block.3.0.weight
(encoder.stages.4.2.block.3.0.weight_bias
getitem_93node_Conv_1457"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.2: torchvision.models.efficientnet.MBConv/encoder.stages.4.2.block: torch.nn.modules.container.Sequential/encoder.stages.4.2.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.2.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_31: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_31 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_53, %p_encoder_stages_4_2_block_3_1_weight, %p_encoder_stages_4_2_block_3_1_bias, %b_encoder_stages_4_2_block_3_1_running_mean, %b_encoder_stages_4_2_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.2', 'encoder.stages.4.2.block', 'encoder.stages.4.2.block.3', 'encoder.stages.4.2.block.3.1', '_native_batch_norm_legit_no_training_31']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ì


getitem_93
add_997add_1101node_add_1101"AddJﬂ
	namespace—: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.2: torchvision.models.efficientnet.MBConv/add_1101: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jí
pkg.torch.onnx.fx_nodex%add_1101 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_93, %add_997), kwargs = {})Jc
pkg.torch.onnx.name_scopesE['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.2', 'add_1101']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
ã
add_1101
#encoder.stages.4.3.block.0.0.weight
(encoder.stages.4.3.block.0.0.weight_bias
getitem_96node_Conv_1459"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.3: torchvision.models.efficientnet.MBConv/encoder.stages.4.3.block: torch.nn.modules.container.Sequential/encoder.stages.4.3.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.3.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_32: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_32 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_54, %p_encoder_stages_4_3_block_0_1_weight, %p_encoder_stages_4_3_block_0_1_bias, %b_encoder_stages_4_3_block_0_1_running_mean, %b_encoder_stages_4_3_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.3', 'encoder.stages.4.3.block', 'encoder.stages.4.3.block.0', 'encoder.stages.4.3.block.0.1', '_native_batch_norm_legit_no_training_32']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
°

getitem_96val_459node_Sigmoid_459"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.3: torchvision.models.efficientnet.MBConv/encoder.stages.4.3.block: torch.nn.modules.container.Sequential/encoder.stages.4.3.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.3.block.0.2: torch.nn.modules.activation.SiLU/silu_32: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_32 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_96,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.3', 'encoder.stages.4.3.block', 'encoder.stages.4.3.block.0', 'encoder.stages.4.3.block.0.2', 'silu_32']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢

getitem_96
val_459silu_32node_silu_32"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.3: torchvision.models.efficientnet.MBConv/encoder.stages.4.3.block: torch.nn.modules.container.Sequential/encoder.stages.4.3.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.3.block.0.2: torch.nn.modules.activation.SiLU/silu_32: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_32 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_96,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.3', 'encoder.stages.4.3.block', 'encoder.stages.4.3.block.0', 'encoder.stages.4.3.block.0.2', 'silu_32']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ã
silu_32
#encoder.stages.4.3.block.1.0.weight
(encoder.stages.4.3.block.1.0.weight_bias
getitem_99node_Conv_1461"Conv*
group¿†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.3: torchvision.models.efficientnet.MBConv/encoder.stages.4.3.block: torch.nn.modules.container.Sequential/encoder.stages.4.3.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.3.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_33: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_33 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_55, %p_encoder_stages_4_3_block_1_1_weight, %p_encoder_stages_4_3_block_1_1_bias, %b_encoder_stages_4_3_block_1_1_running_mean, %b_encoder_stages_4_3_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.3', 'encoder.stages.4.3.block', 'encoder.stages.4.3.block.1', 'encoder.stages.4.3.block.1.1', '_native_batch_norm_legit_no_training_33']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
°

getitem_99val_471node_Sigmoid_471"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.3: torchvision.models.efficientnet.MBConv/encoder.stages.4.3.block: torch.nn.modules.container.Sequential/encoder.stages.4.3.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.3.block.1.2: torch.nn.modules.activation.SiLU/silu_33: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_33 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_99,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.3', 'encoder.stages.4.3.block', 'encoder.stages.4.3.block.1', 'encoder.stages.4.3.block.1.2', 'silu_33']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢

getitem_99
val_471silu_33node_silu_33"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.3: torchvision.models.efficientnet.MBConv/encoder.stages.4.3.block: torch.nn.modules.container.Sequential/encoder.stages.4.3.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.3.block.1.2: torch.nn.modules.activation.SiLU/silu_33: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_33 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_99,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.3', 'encoder.stages.4.3.block', 'encoder.stages.4.3.block.1', 'encoder.stages.4.3.block.1.2', 'silu_33']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ı
silu_33
val_67mean_11node_mean_11"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÆ
	namespace†: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.3: torchvision.models.efficientnet.MBConv/encoder.stages.4.3.block: torch.nn.modules.container.Sequential/encoder.stages.4.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.3.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_11: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jí
pkg.torch.onnx.fx_nodex%mean_11 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_33, [-1, -2], True), kwargs = {})J√
pkg.torch.onnx.name_scopes§['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.3', 'encoder.stages.4.3.block', 'encoder.stages.4.3.block.2', 'encoder.stages.4.3.block.2.avgpool', 'mean_11']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
ù
mean_11
%encoder.stages.4.3.block.2.fc1.weight
#encoder.stages.4.3.block.2.fc1.bias	conv2d_56node_conv2d_56"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.3: torchvision.models.efficientnet.MBConv/encoder.stages.4.3.block: torch.nn.modules.container.Sequential/encoder.stages.4.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.3.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_56: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_56 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_11, %p_encoder_stages_4_3_block_2_fc1_weight, %p_encoder_stages_4_3_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.3', 'encoder.stages.4.3.block', 'encoder.stages.4.3.block.2', 'encoder.stages.4.3.block.2.fc1', 'conv2d_56']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_56val_474node_Sigmoid_474"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.3: torchvision.models.efficientnet.MBConv/encoder.stages.4.3.block: torch.nn.modules.container.Sequential/encoder.stages.4.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.3.block.2.activation: torch.nn.modules.activation.SiLU/silu_34: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_34 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_56,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.3', 'encoder.stages.4.3.block', 'encoder.stages.4.3.block.2', 'encoder.stages.4.3.block.2.activation', 'silu_34']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_56
val_474silu_34node_silu_34"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.3: torchvision.models.efficientnet.MBConv/encoder.stages.4.3.block: torch.nn.modules.container.Sequential/encoder.stages.4.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.3.block.2.activation: torch.nn.modules.activation.SiLU/silu_34: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_34 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_56,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.3', 'encoder.stages.4.3.block', 'encoder.stages.4.3.block.2', 'encoder.stages.4.3.block.2.activation', 'silu_34']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_34
%encoder.stages.4.3.block.2.fc2.weight
#encoder.stages.4.3.block.2.fc2.bias	conv2d_57node_conv2d_57"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.3: torchvision.models.efficientnet.MBConv/encoder.stages.4.3.block: torch.nn.modules.container.Sequential/encoder.stages.4.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.3.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_57: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_57 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_34, %p_encoder_stages_4_3_block_2_fc2_weight, %p_encoder_stages_4_3_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.3', 'encoder.stages.4.3.block', 'encoder.stages.4.3.block.2', 'encoder.stages.4.3.block.2.fc2', 'conv2d_57']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
¡
	conv2d_57
sigmoid_11node_sigmoid_11"SigmoidJ∫
	namespace¨: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.3: torchvision.models.efficientnet.MBConv/encoder.stages.4.3.block: torch.nn.modules.container.Sequential/encoder.stages.4.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.3.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_11: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jè
pkg.torch.onnx.fx_nodeu%sigmoid_11 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_57,), kwargs = {})Jœ
pkg.torch.onnx.name_scopes∞['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.3', 'encoder.stages.4.3.block', 'encoder.stages.4.3.block.2', 'encoder.stages.4.3.block.2.scale_activation', 'sigmoid_11']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ÿ

sigmoid_11
silu_33mul_1509node_mul_1509"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.3: torchvision.models.efficientnet.MBConv/encoder.stages.4.3.block: torch.nn.modules.container.Sequential/encoder.stages.4.3.block.2: torchvision.ops.misc.SqueezeExcitation/mul_1509: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_1509 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_11, %silu_33), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.3', 'encoder.stages.4.3.block', 'encoder.stages.4.3.block.2', 'mul_1509']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
å
mul_1509
#encoder.stages.4.3.block.3.0.weight
(encoder.stages.4.3.block.3.0.weight_biasgetitem_102node_Conv_1463"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.3: torchvision.models.efficientnet.MBConv/encoder.stages.4.3.block: torch.nn.modules.container.Sequential/encoder.stages.4.3.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.3.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_34: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_34 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_58, %p_encoder_stages_4_3_block_3_1_weight, %p_encoder_stages_4_3_block_3_1_bias, %b_encoder_stages_4_3_block_3_1_running_mean, %b_encoder_stages_4_3_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.3', 'encoder.stages.4.3.block', 'encoder.stages.4.3.block.3', 'encoder.stages.4.3.block.3.1', '_native_batch_norm_legit_no_training_34']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ò

getitem_102
add_1101add_1205node_add_1205"AddJﬂ
	namespace—: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.3: torchvision.models.efficientnet.MBConv/add_1205: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_1205 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_102, %add_1101), kwargs = {})Jc
pkg.torch.onnx.name_scopesE['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.3', 'add_1205']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
å
add_1205
#encoder.stages.4.4.block.0.0.weight
(encoder.stages.4.4.block.0.0.weight_biasgetitem_105node_Conv_1465"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.4: torchvision.models.efficientnet.MBConv/encoder.stages.4.4.block: torch.nn.modules.container.Sequential/encoder.stages.4.4.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.4.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_35: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_35 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_59, %p_encoder_stages_4_4_block_0_1_weight, %p_encoder_stages_4_4_block_0_1_bias, %b_encoder_stages_4_4_block_0_1_running_mean, %b_encoder_stages_4_4_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.4', 'encoder.stages.4.4.block', 'encoder.stages.4.4.block.0', 'encoder.stages.4.4.block.0.1', '_native_batch_norm_legit_no_training_35']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_105val_497node_Sigmoid_497"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.4: torchvision.models.efficientnet.MBConv/encoder.stages.4.4.block: torch.nn.modules.container.Sequential/encoder.stages.4.4.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.4.block.0.2: torch.nn.modules.activation.SiLU/silu_35: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_35 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_105,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.4', 'encoder.stages.4.4.block', 'encoder.stages.4.4.block.0', 'encoder.stages.4.4.block.0.2', 'silu_35']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_105
val_497silu_35node_silu_35"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.4: torchvision.models.efficientnet.MBConv/encoder.stages.4.4.block: torch.nn.modules.container.Sequential/encoder.stages.4.4.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.4.block.0.2: torch.nn.modules.activation.SiLU/silu_35: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_35 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_105,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.4', 'encoder.stages.4.4.block', 'encoder.stages.4.4.block.0', 'encoder.stages.4.4.block.0.2', 'silu_35']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
å
silu_35
#encoder.stages.4.4.block.1.0.weight
(encoder.stages.4.4.block.1.0.weight_biasgetitem_108node_Conv_1467"Conv*
group¿†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.4: torchvision.models.efficientnet.MBConv/encoder.stages.4.4.block: torch.nn.modules.container.Sequential/encoder.stages.4.4.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.4.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_36: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_36 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_60, %p_encoder_stages_4_4_block_1_1_weight, %p_encoder_stages_4_4_block_1_1_bias, %b_encoder_stages_4_4_block_1_1_running_mean, %b_encoder_stages_4_4_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.4', 'encoder.stages.4.4.block', 'encoder.stages.4.4.block.1', 'encoder.stages.4.4.block.1.1', '_native_batch_norm_legit_no_training_36']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_108val_509node_Sigmoid_509"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.4: torchvision.models.efficientnet.MBConv/encoder.stages.4.4.block: torch.nn.modules.container.Sequential/encoder.stages.4.4.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.4.block.1.2: torch.nn.modules.activation.SiLU/silu_36: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_36 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_108,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.4', 'encoder.stages.4.4.block', 'encoder.stages.4.4.block.1', 'encoder.stages.4.4.block.1.2', 'silu_36']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_108
val_509silu_36node_silu_36"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.4: torchvision.models.efficientnet.MBConv/encoder.stages.4.4.block: torch.nn.modules.container.Sequential/encoder.stages.4.4.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.4.block.1.2: torch.nn.modules.activation.SiLU/silu_36: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_36 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_108,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.4', 'encoder.stages.4.4.block', 'encoder.stages.4.4.block.1', 'encoder.stages.4.4.block.1.2', 'silu_36']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ı
silu_36
val_67mean_12node_mean_12"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÆ
	namespace†: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.4: torchvision.models.efficientnet.MBConv/encoder.stages.4.4.block: torch.nn.modules.container.Sequential/encoder.stages.4.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.4.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_12: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jí
pkg.torch.onnx.fx_nodex%mean_12 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_36, [-1, -2], True), kwargs = {})J√
pkg.torch.onnx.name_scopes§['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.4', 'encoder.stages.4.4.block', 'encoder.stages.4.4.block.2', 'encoder.stages.4.4.block.2.avgpool', 'mean_12']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
ù
mean_12
%encoder.stages.4.4.block.2.fc1.weight
#encoder.stages.4.4.block.2.fc1.bias	conv2d_61node_conv2d_61"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.4: torchvision.models.efficientnet.MBConv/encoder.stages.4.4.block: torch.nn.modules.container.Sequential/encoder.stages.4.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.4.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_61: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_61 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_12, %p_encoder_stages_4_4_block_2_fc1_weight, %p_encoder_stages_4_4_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.4', 'encoder.stages.4.4.block', 'encoder.stages.4.4.block.2', 'encoder.stages.4.4.block.2.fc1', 'conv2d_61']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_61val_512node_Sigmoid_512"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.4: torchvision.models.efficientnet.MBConv/encoder.stages.4.4.block: torch.nn.modules.container.Sequential/encoder.stages.4.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.4.block.2.activation: torch.nn.modules.activation.SiLU/silu_37: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_37 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_61,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.4', 'encoder.stages.4.4.block', 'encoder.stages.4.4.block.2', 'encoder.stages.4.4.block.2.activation', 'silu_37']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_61
val_512silu_37node_silu_37"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.4: torchvision.models.efficientnet.MBConv/encoder.stages.4.4.block: torch.nn.modules.container.Sequential/encoder.stages.4.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.4.block.2.activation: torch.nn.modules.activation.SiLU/silu_37: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_37 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_61,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.4', 'encoder.stages.4.4.block', 'encoder.stages.4.4.block.2', 'encoder.stages.4.4.block.2.activation', 'silu_37']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_37
%encoder.stages.4.4.block.2.fc2.weight
#encoder.stages.4.4.block.2.fc2.bias	conv2d_62node_conv2d_62"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.4: torchvision.models.efficientnet.MBConv/encoder.stages.4.4.block: torch.nn.modules.container.Sequential/encoder.stages.4.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.4.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_62: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_62 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_37, %p_encoder_stages_4_4_block_2_fc2_weight, %p_encoder_stages_4_4_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.4', 'encoder.stages.4.4.block', 'encoder.stages.4.4.block.2', 'encoder.stages.4.4.block.2.fc2', 'conv2d_62']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
¡
	conv2d_62
sigmoid_12node_sigmoid_12"SigmoidJ∫
	namespace¨: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.4: torchvision.models.efficientnet.MBConv/encoder.stages.4.4.block: torch.nn.modules.container.Sequential/encoder.stages.4.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.4.4.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_12: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jè
pkg.torch.onnx.fx_nodeu%sigmoid_12 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_62,), kwargs = {})Jœ
pkg.torch.onnx.name_scopes∞['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.4', 'encoder.stages.4.4.block', 'encoder.stages.4.4.block.2', 'encoder.stages.4.4.block.2.scale_activation', 'sigmoid_12']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ÿ

sigmoid_12
silu_36mul_1638node_mul_1638"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.4: torchvision.models.efficientnet.MBConv/encoder.stages.4.4.block: torch.nn.modules.container.Sequential/encoder.stages.4.4.block.2: torchvision.ops.misc.SqueezeExcitation/mul_1638: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_1638 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_12, %silu_36), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.4', 'encoder.stages.4.4.block', 'encoder.stages.4.4.block.2', 'mul_1638']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
å
mul_1638
#encoder.stages.4.4.block.3.0.weight
(encoder.stages.4.4.block.3.0.weight_biasgetitem_111node_Conv_1469"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.4: torchvision.models.efficientnet.MBConv/encoder.stages.4.4.block: torch.nn.modules.container.Sequential/encoder.stages.4.4.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.4.4.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_37: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_37 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_63, %p_encoder_stages_4_4_block_3_1_weight, %p_encoder_stages_4_4_block_3_1_bias, %b_encoder_stages_4_4_block_3_1_running_mean, %b_encoder_stages_4_4_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.4', 'encoder.stages.4.4.block', 'encoder.stages.4.4.block.3', 'encoder.stages.4.4.block.3.1', '_native_batch_norm_legit_no_training_37']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ò

getitem_111
add_1205add_1309node_add_1309"AddJﬂ
	namespace—: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.4: torch.nn.modules.container.Sequential/encoder.stages.4.4: torchvision.models.efficientnet.MBConv/add_1309: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_1309 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_111, %add_1205), kwargs = {})Jc
pkg.torch.onnx.name_scopesE['', 'encoder', 'encoder.stages.4', 'encoder.stages.4.4', 'add_1309']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
å
add_1309
#encoder.stages.5.0.block.0.0.weight
(encoder.stages.5.0.block.0.0.weight_biasgetitem_114node_Conv_1471"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.0: torchvision.models.efficientnet.MBConv/encoder.stages.5.0.block: torch.nn.modules.container.Sequential/encoder.stages.5.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.0.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_38: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_38 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_64, %p_encoder_stages_5_0_block_0_1_weight, %p_encoder_stages_5_0_block_0_1_bias, %b_encoder_stages_5_0_block_0_1_running_mean, %b_encoder_stages_5_0_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.0', 'encoder.stages.5.0.block', 'encoder.stages.5.0.block.0', 'encoder.stages.5.0.block.0.1', '_native_batch_norm_legit_no_training_38']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_114val_535node_Sigmoid_535"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.0: torchvision.models.efficientnet.MBConv/encoder.stages.5.0.block: torch.nn.modules.container.Sequential/encoder.stages.5.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.0.block.0.2: torch.nn.modules.activation.SiLU/silu_38: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_38 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_114,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.0', 'encoder.stages.5.0.block', 'encoder.stages.5.0.block.0', 'encoder.stages.5.0.block.0.2', 'silu_38']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_114
val_535silu_38node_silu_38"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.0: torchvision.models.efficientnet.MBConv/encoder.stages.5.0.block: torch.nn.modules.container.Sequential/encoder.stages.5.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.0.block.0.2: torch.nn.modules.activation.SiLU/silu_38: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_38 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_114,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.0', 'encoder.stages.5.0.block', 'encoder.stages.5.0.block.0', 'encoder.stages.5.0.block.0.2', 'silu_38']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
å
silu_38
#encoder.stages.5.0.block.1.0.weight
(encoder.stages.5.0.block.1.0.weight_biasgetitem_117node_Conv_1473"Conv*
group¿†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.0: torchvision.models.efficientnet.MBConv/encoder.stages.5.0.block: torch.nn.modules.container.Sequential/encoder.stages.5.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.0.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_39: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_39 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_65, %p_encoder_stages_5_0_block_1_1_weight, %p_encoder_stages_5_0_block_1_1_bias, %b_encoder_stages_5_0_block_1_1_running_mean, %b_encoder_stages_5_0_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.0', 'encoder.stages.5.0.block', 'encoder.stages.5.0.block.1', 'encoder.stages.5.0.block.1.1', '_native_batch_norm_legit_no_training_39']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_117val_547node_Sigmoid_547"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.0: torchvision.models.efficientnet.MBConv/encoder.stages.5.0.block: torch.nn.modules.container.Sequential/encoder.stages.5.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.0.block.1.2: torch.nn.modules.activation.SiLU/silu_39: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_39 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_117,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.0', 'encoder.stages.5.0.block', 'encoder.stages.5.0.block.1', 'encoder.stages.5.0.block.1.2', 'silu_39']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_117
val_547silu_39node_silu_39"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.0: torchvision.models.efficientnet.MBConv/encoder.stages.5.0.block: torch.nn.modules.container.Sequential/encoder.stages.5.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.0.block.1.2: torch.nn.modules.activation.SiLU/silu_39: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_39 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_117,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.0', 'encoder.stages.5.0.block', 'encoder.stages.5.0.block.1', 'encoder.stages.5.0.block.1.2', 'silu_39']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ı
silu_39
val_67mean_13node_mean_13"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÆ
	namespace†: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.0: torchvision.models.efficientnet.MBConv/encoder.stages.5.0.block: torch.nn.modules.container.Sequential/encoder.stages.5.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.0.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_13: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jí
pkg.torch.onnx.fx_nodex%mean_13 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_39, [-1, -2], True), kwargs = {})J√
pkg.torch.onnx.name_scopes§['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.0', 'encoder.stages.5.0.block', 'encoder.stages.5.0.block.2', 'encoder.stages.5.0.block.2.avgpool', 'mean_13']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
ù
mean_13
%encoder.stages.5.0.block.2.fc1.weight
#encoder.stages.5.0.block.2.fc1.bias	conv2d_66node_conv2d_66"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.0: torchvision.models.efficientnet.MBConv/encoder.stages.5.0.block: torch.nn.modules.container.Sequential/encoder.stages.5.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.0.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_66: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_66 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_13, %p_encoder_stages_5_0_block_2_fc1_weight, %p_encoder_stages_5_0_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.0', 'encoder.stages.5.0.block', 'encoder.stages.5.0.block.2', 'encoder.stages.5.0.block.2.fc1', 'conv2d_66']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_66val_550node_Sigmoid_550"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.0: torchvision.models.efficientnet.MBConv/encoder.stages.5.0.block: torch.nn.modules.container.Sequential/encoder.stages.5.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.0.block.2.activation: torch.nn.modules.activation.SiLU/silu_40: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_40 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_66,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.0', 'encoder.stages.5.0.block', 'encoder.stages.5.0.block.2', 'encoder.stages.5.0.block.2.activation', 'silu_40']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_66
val_550silu_40node_silu_40"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.0: torchvision.models.efficientnet.MBConv/encoder.stages.5.0.block: torch.nn.modules.container.Sequential/encoder.stages.5.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.0.block.2.activation: torch.nn.modules.activation.SiLU/silu_40: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_40 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_66,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.0', 'encoder.stages.5.0.block', 'encoder.stages.5.0.block.2', 'encoder.stages.5.0.block.2.activation', 'silu_40']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_40
%encoder.stages.5.0.block.2.fc2.weight
#encoder.stages.5.0.block.2.fc2.bias	conv2d_67node_conv2d_67"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.0: torchvision.models.efficientnet.MBConv/encoder.stages.5.0.block: torch.nn.modules.container.Sequential/encoder.stages.5.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.0.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_67: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_67 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_40, %p_encoder_stages_5_0_block_2_fc2_weight, %p_encoder_stages_5_0_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.0', 'encoder.stages.5.0.block', 'encoder.stages.5.0.block.2', 'encoder.stages.5.0.block.2.fc2', 'conv2d_67']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
¡
	conv2d_67
sigmoid_13node_sigmoid_13"SigmoidJ∫
	namespace¨: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.0: torchvision.models.efficientnet.MBConv/encoder.stages.5.0.block: torch.nn.modules.container.Sequential/encoder.stages.5.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.0.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_13: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jè
pkg.torch.onnx.fx_nodeu%sigmoid_13 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_67,), kwargs = {})Jœ
pkg.torch.onnx.name_scopes∞['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.0', 'encoder.stages.5.0.block', 'encoder.stages.5.0.block.2', 'encoder.stages.5.0.block.2.scale_activation', 'sigmoid_13']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ÿ

sigmoid_13
silu_39mul_1767node_mul_1767"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.0: torchvision.models.efficientnet.MBConv/encoder.stages.5.0.block: torch.nn.modules.container.Sequential/encoder.stages.5.0.block.2: torchvision.ops.misc.SqueezeExcitation/mul_1767: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_1767 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_13, %silu_39), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.0', 'encoder.stages.5.0.block', 'encoder.stages.5.0.block.2', 'mul_1767']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
å
mul_1767
#encoder.stages.5.0.block.3.0.weight
(encoder.stages.5.0.block.3.0.weight_biasgetitem_120node_Conv_1475"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.0: torchvision.models.efficientnet.MBConv/encoder.stages.5.0.block: torch.nn.modules.container.Sequential/encoder.stages.5.0.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.0.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_40: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_40 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_68, %p_encoder_stages_5_0_block_3_1_weight, %p_encoder_stages_5_0_block_3_1_bias, %b_encoder_stages_5_0_block_3_1_running_mean, %b_encoder_stages_5_0_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.0', 'encoder.stages.5.0.block', 'encoder.stages.5.0.block.3', 'encoder.stages.5.0.block.3.1', '_native_batch_norm_legit_no_training_40']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
è
getitem_120
#encoder.stages.5.1.block.0.0.weight
(encoder.stages.5.1.block.0.0.weight_biasgetitem_123node_Conv_1477"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.1: torchvision.models.efficientnet.MBConv/encoder.stages.5.1.block: torch.nn.modules.container.Sequential/encoder.stages.5.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.1.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_41: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_41 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_69, %p_encoder_stages_5_1_block_0_1_weight, %p_encoder_stages_5_1_block_0_1_bias, %b_encoder_stages_5_1_block_0_1_running_mean, %b_encoder_stages_5_1_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.1', 'encoder.stages.5.1.block', 'encoder.stages.5.1.block.0', 'encoder.stages.5.1.block.0.1', '_native_batch_norm_legit_no_training_41']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_123val_573node_Sigmoid_573"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.1: torchvision.models.efficientnet.MBConv/encoder.stages.5.1.block: torch.nn.modules.container.Sequential/encoder.stages.5.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.1.block.0.2: torch.nn.modules.activation.SiLU/silu_41: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_41 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_123,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.1', 'encoder.stages.5.1.block', 'encoder.stages.5.1.block.0', 'encoder.stages.5.1.block.0.2', 'silu_41']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_123
val_573silu_41node_silu_41"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.1: torchvision.models.efficientnet.MBConv/encoder.stages.5.1.block: torch.nn.modules.container.Sequential/encoder.stages.5.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.1.block.0.2: torch.nn.modules.activation.SiLU/silu_41: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_41 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_123,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.1', 'encoder.stages.5.1.block', 'encoder.stages.5.1.block.0', 'encoder.stages.5.1.block.0.2', 'silu_41']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
å
silu_41
#encoder.stages.5.1.block.1.0.weight
(encoder.stages.5.1.block.1.0.weight_biasgetitem_126node_Conv_1479"Conv*
group∞†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.1: torchvision.models.efficientnet.MBConv/encoder.stages.5.1.block: torch.nn.modules.container.Sequential/encoder.stages.5.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.1.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_42: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_42 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_70, %p_encoder_stages_5_1_block_1_1_weight, %p_encoder_stages_5_1_block_1_1_bias, %b_encoder_stages_5_1_block_1_1_running_mean, %b_encoder_stages_5_1_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.1', 'encoder.stages.5.1.block', 'encoder.stages.5.1.block.1', 'encoder.stages.5.1.block.1.1', '_native_batch_norm_legit_no_training_42']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_126val_585node_Sigmoid_585"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.1: torchvision.models.efficientnet.MBConv/encoder.stages.5.1.block: torch.nn.modules.container.Sequential/encoder.stages.5.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.1.block.1.2: torch.nn.modules.activation.SiLU/silu_42: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_42 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_126,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.1', 'encoder.stages.5.1.block', 'encoder.stages.5.1.block.1', 'encoder.stages.5.1.block.1.2', 'silu_42']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_126
val_585silu_42node_silu_42"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.1: torchvision.models.efficientnet.MBConv/encoder.stages.5.1.block: torch.nn.modules.container.Sequential/encoder.stages.5.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.1.block.1.2: torch.nn.modules.activation.SiLU/silu_42: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_42 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_126,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.1', 'encoder.stages.5.1.block', 'encoder.stages.5.1.block.1', 'encoder.stages.5.1.block.1.2', 'silu_42']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ı
silu_42
val_67mean_14node_mean_14"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÆ
	namespace†: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.1: torchvision.models.efficientnet.MBConv/encoder.stages.5.1.block: torch.nn.modules.container.Sequential/encoder.stages.5.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.1.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_14: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jí
pkg.torch.onnx.fx_nodex%mean_14 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_42, [-1, -2], True), kwargs = {})J√
pkg.torch.onnx.name_scopes§['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.1', 'encoder.stages.5.1.block', 'encoder.stages.5.1.block.2', 'encoder.stages.5.1.block.2.avgpool', 'mean_14']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
ù
mean_14
%encoder.stages.5.1.block.2.fc1.weight
#encoder.stages.5.1.block.2.fc1.bias	conv2d_71node_conv2d_71"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.1: torchvision.models.efficientnet.MBConv/encoder.stages.5.1.block: torch.nn.modules.container.Sequential/encoder.stages.5.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.1.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_71: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_71 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_14, %p_encoder_stages_5_1_block_2_fc1_weight, %p_encoder_stages_5_1_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.1', 'encoder.stages.5.1.block', 'encoder.stages.5.1.block.2', 'encoder.stages.5.1.block.2.fc1', 'conv2d_71']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_71val_588node_Sigmoid_588"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.1: torchvision.models.efficientnet.MBConv/encoder.stages.5.1.block: torch.nn.modules.container.Sequential/encoder.stages.5.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.1.block.2.activation: torch.nn.modules.activation.SiLU/silu_43: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_43 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_71,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.1', 'encoder.stages.5.1.block', 'encoder.stages.5.1.block.2', 'encoder.stages.5.1.block.2.activation', 'silu_43']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_71
val_588silu_43node_silu_43"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.1: torchvision.models.efficientnet.MBConv/encoder.stages.5.1.block: torch.nn.modules.container.Sequential/encoder.stages.5.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.1.block.2.activation: torch.nn.modules.activation.SiLU/silu_43: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_43 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_71,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.1', 'encoder.stages.5.1.block', 'encoder.stages.5.1.block.2', 'encoder.stages.5.1.block.2.activation', 'silu_43']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_43
%encoder.stages.5.1.block.2.fc2.weight
#encoder.stages.5.1.block.2.fc2.bias	conv2d_72node_conv2d_72"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.1: torchvision.models.efficientnet.MBConv/encoder.stages.5.1.block: torch.nn.modules.container.Sequential/encoder.stages.5.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.1.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_72: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_72 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_43, %p_encoder_stages_5_1_block_2_fc2_weight, %p_encoder_stages_5_1_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.1', 'encoder.stages.5.1.block', 'encoder.stages.5.1.block.2', 'encoder.stages.5.1.block.2.fc2', 'conv2d_72']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
¡
	conv2d_72
sigmoid_14node_sigmoid_14"SigmoidJ∫
	namespace¨: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.1: torchvision.models.efficientnet.MBConv/encoder.stages.5.1.block: torch.nn.modules.container.Sequential/encoder.stages.5.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.1.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_14: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jè
pkg.torch.onnx.fx_nodeu%sigmoid_14 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_72,), kwargs = {})Jœ
pkg.torch.onnx.name_scopes∞['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.1', 'encoder.stages.5.1.block', 'encoder.stages.5.1.block.2', 'encoder.stages.5.1.block.2.scale_activation', 'sigmoid_14']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ÿ

sigmoid_14
silu_42mul_1884node_mul_1884"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.1: torchvision.models.efficientnet.MBConv/encoder.stages.5.1.block: torch.nn.modules.container.Sequential/encoder.stages.5.1.block.2: torchvision.ops.misc.SqueezeExcitation/mul_1884: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_1884 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_14, %silu_42), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.1', 'encoder.stages.5.1.block', 'encoder.stages.5.1.block.2', 'mul_1884']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
å
mul_1884
#encoder.stages.5.1.block.3.0.weight
(encoder.stages.5.1.block.3.0.weight_biasgetitem_129node_Conv_1481"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.1: torchvision.models.efficientnet.MBConv/encoder.stages.5.1.block: torch.nn.modules.container.Sequential/encoder.stages.5.1.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.1.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_43: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_43 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_73, %p_encoder_stages_5_1_block_3_1_weight, %p_encoder_stages_5_1_block_3_1_bias, %b_encoder_stages_5_1_block_3_1_running_mean, %b_encoder_stages_5_1_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.1', 'encoder.stages.5.1.block', 'encoder.stages.5.1.block.3', 'encoder.stages.5.1.block.3.1', '_native_batch_norm_legit_no_training_43']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
˜

getitem_129
getitem_120add_1501node_add_1501"AddJﬂ
	namespace—: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.1: torchvision.models.efficientnet.MBConv/add_1501: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jó
pkg.torch.onnx.fx_node}%add_1501 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_129, %getitem_120), kwargs = {})Jc
pkg.torch.onnx.name_scopesE['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.1', 'add_1501']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
å
add_1501
#encoder.stages.5.2.block.0.0.weight
(encoder.stages.5.2.block.0.0.weight_biasgetitem_132node_Conv_1483"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.2: torchvision.models.efficientnet.MBConv/encoder.stages.5.2.block: torch.nn.modules.container.Sequential/encoder.stages.5.2.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.2.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_44: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_44 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_74, %p_encoder_stages_5_2_block_0_1_weight, %p_encoder_stages_5_2_block_0_1_bias, %b_encoder_stages_5_2_block_0_1_running_mean, %b_encoder_stages_5_2_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.2', 'encoder.stages.5.2.block', 'encoder.stages.5.2.block.0', 'encoder.stages.5.2.block.0.1', '_native_batch_norm_legit_no_training_44']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_132val_611node_Sigmoid_611"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.2: torchvision.models.efficientnet.MBConv/encoder.stages.5.2.block: torch.nn.modules.container.Sequential/encoder.stages.5.2.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.2.block.0.2: torch.nn.modules.activation.SiLU/silu_44: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_44 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_132,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.2', 'encoder.stages.5.2.block', 'encoder.stages.5.2.block.0', 'encoder.stages.5.2.block.0.2', 'silu_44']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_132
val_611silu_44node_silu_44"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.2: torchvision.models.efficientnet.MBConv/encoder.stages.5.2.block: torch.nn.modules.container.Sequential/encoder.stages.5.2.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.2.block.0.2: torch.nn.modules.activation.SiLU/silu_44: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_44 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_132,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.2', 'encoder.stages.5.2.block', 'encoder.stages.5.2.block.0', 'encoder.stages.5.2.block.0.2', 'silu_44']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
å
silu_44
#encoder.stages.5.2.block.1.0.weight
(encoder.stages.5.2.block.1.0.weight_biasgetitem_135node_Conv_1485"Conv*
group∞†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.2: torchvision.models.efficientnet.MBConv/encoder.stages.5.2.block: torch.nn.modules.container.Sequential/encoder.stages.5.2.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.2.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_45: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_45 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_75, %p_encoder_stages_5_2_block_1_1_weight, %p_encoder_stages_5_2_block_1_1_bias, %b_encoder_stages_5_2_block_1_1_running_mean, %b_encoder_stages_5_2_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.2', 'encoder.stages.5.2.block', 'encoder.stages.5.2.block.1', 'encoder.stages.5.2.block.1.1', '_native_batch_norm_legit_no_training_45']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_135val_623node_Sigmoid_623"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.2: torchvision.models.efficientnet.MBConv/encoder.stages.5.2.block: torch.nn.modules.container.Sequential/encoder.stages.5.2.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.2.block.1.2: torch.nn.modules.activation.SiLU/silu_45: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_45 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_135,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.2', 'encoder.stages.5.2.block', 'encoder.stages.5.2.block.1', 'encoder.stages.5.2.block.1.2', 'silu_45']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_135
val_623silu_45node_silu_45"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.2: torchvision.models.efficientnet.MBConv/encoder.stages.5.2.block: torch.nn.modules.container.Sequential/encoder.stages.5.2.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.2.block.1.2: torch.nn.modules.activation.SiLU/silu_45: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_45 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_135,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.2', 'encoder.stages.5.2.block', 'encoder.stages.5.2.block.1', 'encoder.stages.5.2.block.1.2', 'silu_45']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ı
silu_45
val_67mean_15node_mean_15"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÆ
	namespace†: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.2: torchvision.models.efficientnet.MBConv/encoder.stages.5.2.block: torch.nn.modules.container.Sequential/encoder.stages.5.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.2.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_15: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jí
pkg.torch.onnx.fx_nodex%mean_15 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_45, [-1, -2], True), kwargs = {})J√
pkg.torch.onnx.name_scopes§['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.2', 'encoder.stages.5.2.block', 'encoder.stages.5.2.block.2', 'encoder.stages.5.2.block.2.avgpool', 'mean_15']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
ù
mean_15
%encoder.stages.5.2.block.2.fc1.weight
#encoder.stages.5.2.block.2.fc1.bias	conv2d_76node_conv2d_76"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.2: torchvision.models.efficientnet.MBConv/encoder.stages.5.2.block: torch.nn.modules.container.Sequential/encoder.stages.5.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.2.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_76: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_76 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_15, %p_encoder_stages_5_2_block_2_fc1_weight, %p_encoder_stages_5_2_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.2', 'encoder.stages.5.2.block', 'encoder.stages.5.2.block.2', 'encoder.stages.5.2.block.2.fc1', 'conv2d_76']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_76val_626node_Sigmoid_626"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.2: torchvision.models.efficientnet.MBConv/encoder.stages.5.2.block: torch.nn.modules.container.Sequential/encoder.stages.5.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.2.block.2.activation: torch.nn.modules.activation.SiLU/silu_46: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_46 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_76,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.2', 'encoder.stages.5.2.block', 'encoder.stages.5.2.block.2', 'encoder.stages.5.2.block.2.activation', 'silu_46']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_76
val_626silu_46node_silu_46"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.2: torchvision.models.efficientnet.MBConv/encoder.stages.5.2.block: torch.nn.modules.container.Sequential/encoder.stages.5.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.2.block.2.activation: torch.nn.modules.activation.SiLU/silu_46: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_46 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_76,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.2', 'encoder.stages.5.2.block', 'encoder.stages.5.2.block.2', 'encoder.stages.5.2.block.2.activation', 'silu_46']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_46
%encoder.stages.5.2.block.2.fc2.weight
#encoder.stages.5.2.block.2.fc2.bias	conv2d_77node_conv2d_77"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.2: torchvision.models.efficientnet.MBConv/encoder.stages.5.2.block: torch.nn.modules.container.Sequential/encoder.stages.5.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.2.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_77: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_77 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_46, %p_encoder_stages_5_2_block_2_fc2_weight, %p_encoder_stages_5_2_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.2', 'encoder.stages.5.2.block', 'encoder.stages.5.2.block.2', 'encoder.stages.5.2.block.2.fc2', 'conv2d_77']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
¡
	conv2d_77
sigmoid_15node_sigmoid_15"SigmoidJ∫
	namespace¨: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.2: torchvision.models.efficientnet.MBConv/encoder.stages.5.2.block: torch.nn.modules.container.Sequential/encoder.stages.5.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.2.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_15: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jè
pkg.torch.onnx.fx_nodeu%sigmoid_15 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_77,), kwargs = {})Jœ
pkg.torch.onnx.name_scopes∞['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.2', 'encoder.stages.5.2.block', 'encoder.stages.5.2.block.2', 'encoder.stages.5.2.block.2.scale_activation', 'sigmoid_15']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ÿ

sigmoid_15
silu_45mul_2013node_mul_2013"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.2: torchvision.models.efficientnet.MBConv/encoder.stages.5.2.block: torch.nn.modules.container.Sequential/encoder.stages.5.2.block.2: torchvision.ops.misc.SqueezeExcitation/mul_2013: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_2013 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_15, %silu_45), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.2', 'encoder.stages.5.2.block', 'encoder.stages.5.2.block.2', 'mul_2013']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
å
mul_2013
#encoder.stages.5.2.block.3.0.weight
(encoder.stages.5.2.block.3.0.weight_biasgetitem_138node_Conv_1487"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.2: torchvision.models.efficientnet.MBConv/encoder.stages.5.2.block: torch.nn.modules.container.Sequential/encoder.stages.5.2.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.2.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_46: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_46 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_78, %p_encoder_stages_5_2_block_3_1_weight, %p_encoder_stages_5_2_block_3_1_bias, %b_encoder_stages_5_2_block_3_1_running_mean, %b_encoder_stages_5_2_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.2', 'encoder.stages.5.2.block', 'encoder.stages.5.2.block.3', 'encoder.stages.5.2.block.3.1', '_native_batch_norm_legit_no_training_46']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ò

getitem_138
add_1501add_1605node_add_1605"AddJﬂ
	namespace—: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.2: torchvision.models.efficientnet.MBConv/add_1605: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_1605 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_138, %add_1501), kwargs = {})Jc
pkg.torch.onnx.name_scopesE['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.2', 'add_1605']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
å
add_1605
#encoder.stages.5.3.block.0.0.weight
(encoder.stages.5.3.block.0.0.weight_biasgetitem_141node_Conv_1489"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.3: torchvision.models.efficientnet.MBConv/encoder.stages.5.3.block: torch.nn.modules.container.Sequential/encoder.stages.5.3.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.3.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_47: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_47 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_79, %p_encoder_stages_5_3_block_0_1_weight, %p_encoder_stages_5_3_block_0_1_bias, %b_encoder_stages_5_3_block_0_1_running_mean, %b_encoder_stages_5_3_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.3', 'encoder.stages.5.3.block', 'encoder.stages.5.3.block.0', 'encoder.stages.5.3.block.0.1', '_native_batch_norm_legit_no_training_47']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_141val_649node_Sigmoid_649"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.3: torchvision.models.efficientnet.MBConv/encoder.stages.5.3.block: torch.nn.modules.container.Sequential/encoder.stages.5.3.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.3.block.0.2: torch.nn.modules.activation.SiLU/silu_47: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_47 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_141,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.3', 'encoder.stages.5.3.block', 'encoder.stages.5.3.block.0', 'encoder.stages.5.3.block.0.2', 'silu_47']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_141
val_649silu_47node_silu_47"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.3: torchvision.models.efficientnet.MBConv/encoder.stages.5.3.block: torch.nn.modules.container.Sequential/encoder.stages.5.3.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.3.block.0.2: torch.nn.modules.activation.SiLU/silu_47: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_47 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_141,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.3', 'encoder.stages.5.3.block', 'encoder.stages.5.3.block.0', 'encoder.stages.5.3.block.0.2', 'silu_47']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
å
silu_47
#encoder.stages.5.3.block.1.0.weight
(encoder.stages.5.3.block.1.0.weight_biasgetitem_144node_Conv_1491"Conv*
group∞†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.3: torchvision.models.efficientnet.MBConv/encoder.stages.5.3.block: torch.nn.modules.container.Sequential/encoder.stages.5.3.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.3.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_48: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_48 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_80, %p_encoder_stages_5_3_block_1_1_weight, %p_encoder_stages_5_3_block_1_1_bias, %b_encoder_stages_5_3_block_1_1_running_mean, %b_encoder_stages_5_3_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.3', 'encoder.stages.5.3.block', 'encoder.stages.5.3.block.1', 'encoder.stages.5.3.block.1.1', '_native_batch_norm_legit_no_training_48']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_144val_661node_Sigmoid_661"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.3: torchvision.models.efficientnet.MBConv/encoder.stages.5.3.block: torch.nn.modules.container.Sequential/encoder.stages.5.3.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.3.block.1.2: torch.nn.modules.activation.SiLU/silu_48: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_48 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_144,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.3', 'encoder.stages.5.3.block', 'encoder.stages.5.3.block.1', 'encoder.stages.5.3.block.1.2', 'silu_48']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_144
val_661silu_48node_silu_48"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.3: torchvision.models.efficientnet.MBConv/encoder.stages.5.3.block: torch.nn.modules.container.Sequential/encoder.stages.5.3.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.3.block.1.2: torch.nn.modules.activation.SiLU/silu_48: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_48 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_144,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.3', 'encoder.stages.5.3.block', 'encoder.stages.5.3.block.1', 'encoder.stages.5.3.block.1.2', 'silu_48']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ı
silu_48
val_67mean_16node_mean_16"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÆ
	namespace†: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.3: torchvision.models.efficientnet.MBConv/encoder.stages.5.3.block: torch.nn.modules.container.Sequential/encoder.stages.5.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.3.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_16: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jí
pkg.torch.onnx.fx_nodex%mean_16 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_48, [-1, -2], True), kwargs = {})J√
pkg.torch.onnx.name_scopes§['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.3', 'encoder.stages.5.3.block', 'encoder.stages.5.3.block.2', 'encoder.stages.5.3.block.2.avgpool', 'mean_16']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
ù
mean_16
%encoder.stages.5.3.block.2.fc1.weight
#encoder.stages.5.3.block.2.fc1.bias	conv2d_81node_conv2d_81"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.3: torchvision.models.efficientnet.MBConv/encoder.stages.5.3.block: torch.nn.modules.container.Sequential/encoder.stages.5.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.3.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_81: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_81 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_16, %p_encoder_stages_5_3_block_2_fc1_weight, %p_encoder_stages_5_3_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.3', 'encoder.stages.5.3.block', 'encoder.stages.5.3.block.2', 'encoder.stages.5.3.block.2.fc1', 'conv2d_81']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_81val_664node_Sigmoid_664"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.3: torchvision.models.efficientnet.MBConv/encoder.stages.5.3.block: torch.nn.modules.container.Sequential/encoder.stages.5.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.3.block.2.activation: torch.nn.modules.activation.SiLU/silu_49: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_49 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_81,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.3', 'encoder.stages.5.3.block', 'encoder.stages.5.3.block.2', 'encoder.stages.5.3.block.2.activation', 'silu_49']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_81
val_664silu_49node_silu_49"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.3: torchvision.models.efficientnet.MBConv/encoder.stages.5.3.block: torch.nn.modules.container.Sequential/encoder.stages.5.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.3.block.2.activation: torch.nn.modules.activation.SiLU/silu_49: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_49 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_81,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.3', 'encoder.stages.5.3.block', 'encoder.stages.5.3.block.2', 'encoder.stages.5.3.block.2.activation', 'silu_49']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_49
%encoder.stages.5.3.block.2.fc2.weight
#encoder.stages.5.3.block.2.fc2.bias	conv2d_82node_conv2d_82"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.3: torchvision.models.efficientnet.MBConv/encoder.stages.5.3.block: torch.nn.modules.container.Sequential/encoder.stages.5.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.3.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_82: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_82 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_49, %p_encoder_stages_5_3_block_2_fc2_weight, %p_encoder_stages_5_3_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.3', 'encoder.stages.5.3.block', 'encoder.stages.5.3.block.2', 'encoder.stages.5.3.block.2.fc2', 'conv2d_82']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
¡
	conv2d_82
sigmoid_16node_sigmoid_16"SigmoidJ∫
	namespace¨: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.3: torchvision.models.efficientnet.MBConv/encoder.stages.5.3.block: torch.nn.modules.container.Sequential/encoder.stages.5.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.3.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_16: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jè
pkg.torch.onnx.fx_nodeu%sigmoid_16 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_82,), kwargs = {})Jœ
pkg.torch.onnx.name_scopes∞['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.3', 'encoder.stages.5.3.block', 'encoder.stages.5.3.block.2', 'encoder.stages.5.3.block.2.scale_activation', 'sigmoid_16']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ÿ

sigmoid_16
silu_48mul_2142node_mul_2142"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.3: torchvision.models.efficientnet.MBConv/encoder.stages.5.3.block: torch.nn.modules.container.Sequential/encoder.stages.5.3.block.2: torchvision.ops.misc.SqueezeExcitation/mul_2142: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_2142 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_16, %silu_48), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.3', 'encoder.stages.5.3.block', 'encoder.stages.5.3.block.2', 'mul_2142']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
å
mul_2142
#encoder.stages.5.3.block.3.0.weight
(encoder.stages.5.3.block.3.0.weight_biasgetitem_147node_Conv_1493"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.3: torchvision.models.efficientnet.MBConv/encoder.stages.5.3.block: torch.nn.modules.container.Sequential/encoder.stages.5.3.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.3.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_49: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_49 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_83, %p_encoder_stages_5_3_block_3_1_weight, %p_encoder_stages_5_3_block_3_1_bias, %b_encoder_stages_5_3_block_3_1_running_mean, %b_encoder_stages_5_3_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.3', 'encoder.stages.5.3.block', 'encoder.stages.5.3.block.3', 'encoder.stages.5.3.block.3.1', '_native_batch_norm_legit_no_training_49']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ò

getitem_147
add_1605add_1709node_add_1709"AddJﬂ
	namespace—: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.3: torchvision.models.efficientnet.MBConv/add_1709: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_1709 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_147, %add_1605), kwargs = {})Jc
pkg.torch.onnx.name_scopesE['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.3', 'add_1709']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
å
add_1709
#encoder.stages.5.4.block.0.0.weight
(encoder.stages.5.4.block.0.0.weight_biasgetitem_150node_Conv_1495"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.4: torchvision.models.efficientnet.MBConv/encoder.stages.5.4.block: torch.nn.modules.container.Sequential/encoder.stages.5.4.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.4.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_50: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_50 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_84, %p_encoder_stages_5_4_block_0_1_weight, %p_encoder_stages_5_4_block_0_1_bias, %b_encoder_stages_5_4_block_0_1_running_mean, %b_encoder_stages_5_4_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.4', 'encoder.stages.5.4.block', 'encoder.stages.5.4.block.0', 'encoder.stages.5.4.block.0.1', '_native_batch_norm_legit_no_training_50']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_150val_687node_Sigmoid_687"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.4: torchvision.models.efficientnet.MBConv/encoder.stages.5.4.block: torch.nn.modules.container.Sequential/encoder.stages.5.4.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.4.block.0.2: torch.nn.modules.activation.SiLU/silu_50: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_50 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_150,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.4', 'encoder.stages.5.4.block', 'encoder.stages.5.4.block.0', 'encoder.stages.5.4.block.0.2', 'silu_50']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_150
val_687silu_50node_silu_50"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.4: torchvision.models.efficientnet.MBConv/encoder.stages.5.4.block: torch.nn.modules.container.Sequential/encoder.stages.5.4.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.4.block.0.2: torch.nn.modules.activation.SiLU/silu_50: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_50 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_150,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.4', 'encoder.stages.5.4.block', 'encoder.stages.5.4.block.0', 'encoder.stages.5.4.block.0.2', 'silu_50']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
å
silu_50
#encoder.stages.5.4.block.1.0.weight
(encoder.stages.5.4.block.1.0.weight_biasgetitem_153node_Conv_1497"Conv*
group∞†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.4: torchvision.models.efficientnet.MBConv/encoder.stages.5.4.block: torch.nn.modules.container.Sequential/encoder.stages.5.4.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.4.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_51: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_51 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_85, %p_encoder_stages_5_4_block_1_1_weight, %p_encoder_stages_5_4_block_1_1_bias, %b_encoder_stages_5_4_block_1_1_running_mean, %b_encoder_stages_5_4_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.4', 'encoder.stages.5.4.block', 'encoder.stages.5.4.block.1', 'encoder.stages.5.4.block.1.1', '_native_batch_norm_legit_no_training_51']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_153val_699node_Sigmoid_699"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.4: torchvision.models.efficientnet.MBConv/encoder.stages.5.4.block: torch.nn.modules.container.Sequential/encoder.stages.5.4.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.4.block.1.2: torch.nn.modules.activation.SiLU/silu_51: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_51 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_153,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.4', 'encoder.stages.5.4.block', 'encoder.stages.5.4.block.1', 'encoder.stages.5.4.block.1.2', 'silu_51']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_153
val_699silu_51node_silu_51"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.4: torchvision.models.efficientnet.MBConv/encoder.stages.5.4.block: torch.nn.modules.container.Sequential/encoder.stages.5.4.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.4.block.1.2: torch.nn.modules.activation.SiLU/silu_51: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_51 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_153,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.4', 'encoder.stages.5.4.block', 'encoder.stages.5.4.block.1', 'encoder.stages.5.4.block.1.2', 'silu_51']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ı
silu_51
val_67mean_17node_mean_17"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÆ
	namespace†: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.4: torchvision.models.efficientnet.MBConv/encoder.stages.5.4.block: torch.nn.modules.container.Sequential/encoder.stages.5.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.4.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_17: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jí
pkg.torch.onnx.fx_nodex%mean_17 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_51, [-1, -2], True), kwargs = {})J√
pkg.torch.onnx.name_scopes§['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.4', 'encoder.stages.5.4.block', 'encoder.stages.5.4.block.2', 'encoder.stages.5.4.block.2.avgpool', 'mean_17']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
ù
mean_17
%encoder.stages.5.4.block.2.fc1.weight
#encoder.stages.5.4.block.2.fc1.bias	conv2d_86node_conv2d_86"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.4: torchvision.models.efficientnet.MBConv/encoder.stages.5.4.block: torch.nn.modules.container.Sequential/encoder.stages.5.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.4.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_86: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_86 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_17, %p_encoder_stages_5_4_block_2_fc1_weight, %p_encoder_stages_5_4_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.4', 'encoder.stages.5.4.block', 'encoder.stages.5.4.block.2', 'encoder.stages.5.4.block.2.fc1', 'conv2d_86']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_86val_702node_Sigmoid_702"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.4: torchvision.models.efficientnet.MBConv/encoder.stages.5.4.block: torch.nn.modules.container.Sequential/encoder.stages.5.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.4.block.2.activation: torch.nn.modules.activation.SiLU/silu_52: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_52 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_86,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.4', 'encoder.stages.5.4.block', 'encoder.stages.5.4.block.2', 'encoder.stages.5.4.block.2.activation', 'silu_52']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_86
val_702silu_52node_silu_52"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.4: torchvision.models.efficientnet.MBConv/encoder.stages.5.4.block: torch.nn.modules.container.Sequential/encoder.stages.5.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.4.block.2.activation: torch.nn.modules.activation.SiLU/silu_52: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_52 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_86,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.4', 'encoder.stages.5.4.block', 'encoder.stages.5.4.block.2', 'encoder.stages.5.4.block.2.activation', 'silu_52']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_52
%encoder.stages.5.4.block.2.fc2.weight
#encoder.stages.5.4.block.2.fc2.bias	conv2d_87node_conv2d_87"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.4: torchvision.models.efficientnet.MBConv/encoder.stages.5.4.block: torch.nn.modules.container.Sequential/encoder.stages.5.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.4.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_87: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_87 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_52, %p_encoder_stages_5_4_block_2_fc2_weight, %p_encoder_stages_5_4_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.4', 'encoder.stages.5.4.block', 'encoder.stages.5.4.block.2', 'encoder.stages.5.4.block.2.fc2', 'conv2d_87']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
¡
	conv2d_87
sigmoid_17node_sigmoid_17"SigmoidJ∫
	namespace¨: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.4: torchvision.models.efficientnet.MBConv/encoder.stages.5.4.block: torch.nn.modules.container.Sequential/encoder.stages.5.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.5.4.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_17: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jè
pkg.torch.onnx.fx_nodeu%sigmoid_17 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_87,), kwargs = {})Jœ
pkg.torch.onnx.name_scopes∞['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.4', 'encoder.stages.5.4.block', 'encoder.stages.5.4.block.2', 'encoder.stages.5.4.block.2.scale_activation', 'sigmoid_17']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ÿ

sigmoid_17
silu_51mul_2271node_mul_2271"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.4: torchvision.models.efficientnet.MBConv/encoder.stages.5.4.block: torch.nn.modules.container.Sequential/encoder.stages.5.4.block.2: torchvision.ops.misc.SqueezeExcitation/mul_2271: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_2271 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_17, %silu_51), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.4', 'encoder.stages.5.4.block', 'encoder.stages.5.4.block.2', 'mul_2271']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
å
mul_2271
#encoder.stages.5.4.block.3.0.weight
(encoder.stages.5.4.block.3.0.weight_biasgetitem_156node_Conv_1499"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.4: torchvision.models.efficientnet.MBConv/encoder.stages.5.4.block: torch.nn.modules.container.Sequential/encoder.stages.5.4.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.5.4.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_52: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_52 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_88, %p_encoder_stages_5_4_block_3_1_weight, %p_encoder_stages_5_4_block_3_1_bias, %b_encoder_stages_5_4_block_3_1_running_mean, %b_encoder_stages_5_4_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.4', 'encoder.stages.5.4.block', 'encoder.stages.5.4.block.3', 'encoder.stages.5.4.block.3.1', '_native_batch_norm_legit_no_training_52']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ò

getitem_156
add_1709add_1813node_add_1813"AddJﬂ
	namespace—: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.5: torch.nn.modules.container.Sequential/encoder.stages.5.4: torchvision.models.efficientnet.MBConv/add_1813: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_1813 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_156, %add_1709), kwargs = {})Jc
pkg.torch.onnx.name_scopesE['', 'encoder', 'encoder.stages.5', 'encoder.stages.5.4', 'add_1813']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
å
add_1813
#encoder.stages.6.0.block.0.0.weight
(encoder.stages.6.0.block.0.0.weight_biasgetitem_159node_Conv_1501"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.0: torchvision.models.efficientnet.MBConv/encoder.stages.6.0.block: torch.nn.modules.container.Sequential/encoder.stages.6.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.0.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_53: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_53 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_89, %p_encoder_stages_6_0_block_0_1_weight, %p_encoder_stages_6_0_block_0_1_bias, %b_encoder_stages_6_0_block_0_1_running_mean, %b_encoder_stages_6_0_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.0', 'encoder.stages.6.0.block', 'encoder.stages.6.0.block.0', 'encoder.stages.6.0.block.0.1', '_native_batch_norm_legit_no_training_53']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_159val_725node_Sigmoid_725"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.0: torchvision.models.efficientnet.MBConv/encoder.stages.6.0.block: torch.nn.modules.container.Sequential/encoder.stages.6.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.0.block.0.2: torch.nn.modules.activation.SiLU/silu_53: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_53 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_159,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.0', 'encoder.stages.6.0.block', 'encoder.stages.6.0.block.0', 'encoder.stages.6.0.block.0.2', 'silu_53']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_159
val_725silu_53node_silu_53"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.0: torchvision.models.efficientnet.MBConv/encoder.stages.6.0.block: torch.nn.modules.container.Sequential/encoder.stages.6.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.0.block.0.2: torch.nn.modules.activation.SiLU/silu_53: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_53 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_159,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.0', 'encoder.stages.6.0.block', 'encoder.stages.6.0.block.0', 'encoder.stages.6.0.block.0.2', 'silu_53']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
å
silu_53
#encoder.stages.6.0.block.1.0.weight
(encoder.stages.6.0.block.1.0.weight_biasgetitem_162node_Conv_1503"Conv*
group∞†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.0: torchvision.models.efficientnet.MBConv/encoder.stages.6.0.block: torch.nn.modules.container.Sequential/encoder.stages.6.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.0.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_54: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_54 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_90, %p_encoder_stages_6_0_block_1_1_weight, %p_encoder_stages_6_0_block_1_1_bias, %b_encoder_stages_6_0_block_1_1_running_mean, %b_encoder_stages_6_0_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.0', 'encoder.stages.6.0.block', 'encoder.stages.6.0.block.1', 'encoder.stages.6.0.block.1.1', '_native_batch_norm_legit_no_training_54']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_162val_737node_Sigmoid_737"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.0: torchvision.models.efficientnet.MBConv/encoder.stages.6.0.block: torch.nn.modules.container.Sequential/encoder.stages.6.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.0.block.1.2: torch.nn.modules.activation.SiLU/silu_54: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_54 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_162,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.0', 'encoder.stages.6.0.block', 'encoder.stages.6.0.block.1', 'encoder.stages.6.0.block.1.2', 'silu_54']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_162
val_737silu_54node_silu_54"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.0: torchvision.models.efficientnet.MBConv/encoder.stages.6.0.block: torch.nn.modules.container.Sequential/encoder.stages.6.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.0.block.1.2: torch.nn.modules.activation.SiLU/silu_54: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_54 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_162,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.0', 'encoder.stages.6.0.block', 'encoder.stages.6.0.block.1', 'encoder.stages.6.0.block.1.2', 'silu_54']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ı
silu_54
val_67mean_18node_mean_18"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÆ
	namespace†: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.0: torchvision.models.efficientnet.MBConv/encoder.stages.6.0.block: torch.nn.modules.container.Sequential/encoder.stages.6.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.0.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_18: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jí
pkg.torch.onnx.fx_nodex%mean_18 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_54, [-1, -2], True), kwargs = {})J√
pkg.torch.onnx.name_scopes§['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.0', 'encoder.stages.6.0.block', 'encoder.stages.6.0.block.2', 'encoder.stages.6.0.block.2.avgpool', 'mean_18']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
ù
mean_18
%encoder.stages.6.0.block.2.fc1.weight
#encoder.stages.6.0.block.2.fc1.bias	conv2d_91node_conv2d_91"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.0: torchvision.models.efficientnet.MBConv/encoder.stages.6.0.block: torch.nn.modules.container.Sequential/encoder.stages.6.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.0.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_91: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_91 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_18, %p_encoder_stages_6_0_block_2_fc1_weight, %p_encoder_stages_6_0_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.0', 'encoder.stages.6.0.block', 'encoder.stages.6.0.block.2', 'encoder.stages.6.0.block.2.fc1', 'conv2d_91']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_91val_740node_Sigmoid_740"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.0: torchvision.models.efficientnet.MBConv/encoder.stages.6.0.block: torch.nn.modules.container.Sequential/encoder.stages.6.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.0.block.2.activation: torch.nn.modules.activation.SiLU/silu_55: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_55 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_91,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.0', 'encoder.stages.6.0.block', 'encoder.stages.6.0.block.2', 'encoder.stages.6.0.block.2.activation', 'silu_55']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_91
val_740silu_55node_silu_55"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.0: torchvision.models.efficientnet.MBConv/encoder.stages.6.0.block: torch.nn.modules.container.Sequential/encoder.stages.6.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.0.block.2.activation: torch.nn.modules.activation.SiLU/silu_55: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_55 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_91,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.0', 'encoder.stages.6.0.block', 'encoder.stages.6.0.block.2', 'encoder.stages.6.0.block.2.activation', 'silu_55']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_55
%encoder.stages.6.0.block.2.fc2.weight
#encoder.stages.6.0.block.2.fc2.bias	conv2d_92node_conv2d_92"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.0: torchvision.models.efficientnet.MBConv/encoder.stages.6.0.block: torch.nn.modules.container.Sequential/encoder.stages.6.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.0.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_92: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_92 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_55, %p_encoder_stages_6_0_block_2_fc2_weight, %p_encoder_stages_6_0_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.0', 'encoder.stages.6.0.block', 'encoder.stages.6.0.block.2', 'encoder.stages.6.0.block.2.fc2', 'conv2d_92']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
¡
	conv2d_92
sigmoid_18node_sigmoid_18"SigmoidJ∫
	namespace¨: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.0: torchvision.models.efficientnet.MBConv/encoder.stages.6.0.block: torch.nn.modules.container.Sequential/encoder.stages.6.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.0.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_18: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jè
pkg.torch.onnx.fx_nodeu%sigmoid_18 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_92,), kwargs = {})Jœ
pkg.torch.onnx.name_scopes∞['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.0', 'encoder.stages.6.0.block', 'encoder.stages.6.0.block.2', 'encoder.stages.6.0.block.2.scale_activation', 'sigmoid_18']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ÿ

sigmoid_18
silu_54mul_2400node_mul_2400"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.0: torchvision.models.efficientnet.MBConv/encoder.stages.6.0.block: torch.nn.modules.container.Sequential/encoder.stages.6.0.block.2: torchvision.ops.misc.SqueezeExcitation/mul_2400: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_2400 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_18, %silu_54), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.0', 'encoder.stages.6.0.block', 'encoder.stages.6.0.block.2', 'mul_2400']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
å
mul_2400
#encoder.stages.6.0.block.3.0.weight
(encoder.stages.6.0.block.3.0.weight_biasgetitem_165node_Conv_1505"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.0: torchvision.models.efficientnet.MBConv/encoder.stages.6.0.block: torch.nn.modules.container.Sequential/encoder.stages.6.0.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.0.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_55: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_55 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_93, %p_encoder_stages_6_0_block_3_1_weight, %p_encoder_stages_6_0_block_3_1_bias, %b_encoder_stages_6_0_block_3_1_running_mean, %b_encoder_stages_6_0_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.0', 'encoder.stages.6.0.block', 'encoder.stages.6.0.block.3', 'encoder.stages.6.0.block.3.1', '_native_batch_norm_legit_no_training_55']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
è
getitem_165
#encoder.stages.6.1.block.0.0.weight
(encoder.stages.6.1.block.0.0.weight_biasgetitem_168node_Conv_1507"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.1: torchvision.models.efficientnet.MBConv/encoder.stages.6.1.block: torch.nn.modules.container.Sequential/encoder.stages.6.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.1.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_56: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_56 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_94, %p_encoder_stages_6_1_block_0_1_weight, %p_encoder_stages_6_1_block_0_1_bias, %b_encoder_stages_6_1_block_0_1_running_mean, %b_encoder_stages_6_1_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.1', 'encoder.stages.6.1.block', 'encoder.stages.6.1.block.0', 'encoder.stages.6.1.block.0.1', '_native_batch_norm_legit_no_training_56']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_168val_763node_Sigmoid_763"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.1: torchvision.models.efficientnet.MBConv/encoder.stages.6.1.block: torch.nn.modules.container.Sequential/encoder.stages.6.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.1.block.0.2: torch.nn.modules.activation.SiLU/silu_56: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_56 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_168,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.1', 'encoder.stages.6.1.block', 'encoder.stages.6.1.block.0', 'encoder.stages.6.1.block.0.2', 'silu_56']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_168
val_763silu_56node_silu_56"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.1: torchvision.models.efficientnet.MBConv/encoder.stages.6.1.block: torch.nn.modules.container.Sequential/encoder.stages.6.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.1.block.0.2: torch.nn.modules.activation.SiLU/silu_56: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_56 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_168,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.1', 'encoder.stages.6.1.block', 'encoder.stages.6.1.block.0', 'encoder.stages.6.1.block.0.2', 'silu_56']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
å
silu_56
#encoder.stages.6.1.block.1.0.weight
(encoder.stages.6.1.block.1.0.weight_biasgetitem_171node_Conv_1509"Conv*
group
†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.1: torchvision.models.efficientnet.MBConv/encoder.stages.6.1.block: torch.nn.modules.container.Sequential/encoder.stages.6.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.1.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_57: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_57 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_95, %p_encoder_stages_6_1_block_1_1_weight, %p_encoder_stages_6_1_block_1_1_bias, %b_encoder_stages_6_1_block_1_1_running_mean, %b_encoder_stages_6_1_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.1', 'encoder.stages.6.1.block', 'encoder.stages.6.1.block.1', 'encoder.stages.6.1.block.1.1', '_native_batch_norm_legit_no_training_57']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_171val_775node_Sigmoid_775"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.1: torchvision.models.efficientnet.MBConv/encoder.stages.6.1.block: torch.nn.modules.container.Sequential/encoder.stages.6.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.1.block.1.2: torch.nn.modules.activation.SiLU/silu_57: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_57 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_171,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.1', 'encoder.stages.6.1.block', 'encoder.stages.6.1.block.1', 'encoder.stages.6.1.block.1.2', 'silu_57']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_171
val_775silu_57node_silu_57"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.1: torchvision.models.efficientnet.MBConv/encoder.stages.6.1.block: torch.nn.modules.container.Sequential/encoder.stages.6.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.1.block.1.2: torch.nn.modules.activation.SiLU/silu_57: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_57 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_171,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.1', 'encoder.stages.6.1.block', 'encoder.stages.6.1.block.1', 'encoder.stages.6.1.block.1.2', 'silu_57']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ı
silu_57
val_67mean_19node_mean_19"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÆ
	namespace†: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.1: torchvision.models.efficientnet.MBConv/encoder.stages.6.1.block: torch.nn.modules.container.Sequential/encoder.stages.6.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.1.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_19: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jí
pkg.torch.onnx.fx_nodex%mean_19 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_57, [-1, -2], True), kwargs = {})J√
pkg.torch.onnx.name_scopes§['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.1', 'encoder.stages.6.1.block', 'encoder.stages.6.1.block.2', 'encoder.stages.6.1.block.2.avgpool', 'mean_19']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
ù
mean_19
%encoder.stages.6.1.block.2.fc1.weight
#encoder.stages.6.1.block.2.fc1.bias	conv2d_96node_conv2d_96"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.1: torchvision.models.efficientnet.MBConv/encoder.stages.6.1.block: torch.nn.modules.container.Sequential/encoder.stages.6.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.1.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_96: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_96 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_19, %p_encoder_stages_6_1_block_2_fc1_weight, %p_encoder_stages_6_1_block_2_fc1_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.1', 'encoder.stages.6.1.block', 'encoder.stages.6.1.block.2', 'encoder.stages.6.1.block.2.fc1', 'conv2d_96']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
™
	conv2d_96val_778node_Sigmoid_778"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.1: torchvision.models.efficientnet.MBConv/encoder.stages.6.1.block: torch.nn.modules.container.Sequential/encoder.stages.6.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.1.block.2.activation: torch.nn.modules.activation.SiLU/silu_58: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_58 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_96,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.1', 'encoder.stages.6.1.block', 'encoder.stages.6.1.block.2', 'encoder.stages.6.1.block.2.activation', 'silu_58']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
´
	conv2d_96
val_778silu_58node_silu_58"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.1: torchvision.models.efficientnet.MBConv/encoder.stages.6.1.block: torch.nn.modules.container.Sequential/encoder.stages.6.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.1.block.2.activation: torch.nn.modules.activation.SiLU/silu_58: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jâ
pkg.torch.onnx.fx_nodeo%silu_58 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_96,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.1', 'encoder.stages.6.1.block', 'encoder.stages.6.1.block.2', 'encoder.stages.6.1.block.2.activation', 'silu_58']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ù
silu_58
%encoder.stages.6.1.block.2.fc2.weight
#encoder.stages.6.1.block.2.fc2.bias	conv2d_97node_conv2d_97"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J§
	namespaceñ: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.1: torchvision.models.efficientnet.MBConv/encoder.stages.6.1.block: torch.nn.modules.container.Sequential/encoder.stages.6.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.1.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_97: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J›
pkg.torch.onnx.fx_node¬%conv2d_97 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_58, %p_encoder_stages_6_1_block_2_fc2_weight, %p_encoder_stages_6_1_block_2_fc2_bias), kwargs = {})J¡
pkg.torch.onnx.name_scopes¢['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.1', 'encoder.stages.6.1.block', 'encoder.stages.6.1.block.2', 'encoder.stages.6.1.block.2.fc2', 'conv2d_97']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
¡
	conv2d_97
sigmoid_19node_sigmoid_19"SigmoidJ∫
	namespace¨: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.1: torchvision.models.efficientnet.MBConv/encoder.stages.6.1.block: torch.nn.modules.container.Sequential/encoder.stages.6.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.1.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_19: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jè
pkg.torch.onnx.fx_nodeu%sigmoid_19 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_97,), kwargs = {})Jœ
pkg.torch.onnx.name_scopes∞['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.1', 'encoder.stages.6.1.block', 'encoder.stages.6.1.block.2', 'encoder.stages.6.1.block.2.scale_activation', 'sigmoid_19']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ÿ

sigmoid_19
silu_57mul_2517node_mul_2517"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.1: torchvision.models.efficientnet.MBConv/encoder.stages.6.1.block: torch.nn.modules.container.Sequential/encoder.stages.6.1.block.2: torchvision.ops.misc.SqueezeExcitation/mul_2517: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_2517 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_19, %silu_57), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.1', 'encoder.stages.6.1.block', 'encoder.stages.6.1.block.2', 'mul_2517']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
å
mul_2517
#encoder.stages.6.1.block.3.0.weight
(encoder.stages.6.1.block.3.0.weight_biasgetitem_174node_Conv_1511"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.1: torchvision.models.efficientnet.MBConv/encoder.stages.6.1.block: torch.nn.modules.container.Sequential/encoder.stages.6.1.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.1.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_58: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_58 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_98, %p_encoder_stages_6_1_block_3_1_weight, %p_encoder_stages_6_1_block_3_1_bias, %b_encoder_stages_6_1_block_3_1_running_mean, %b_encoder_stages_6_1_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.1', 'encoder.stages.6.1.block', 'encoder.stages.6.1.block.3', 'encoder.stages.6.1.block.3.1', '_native_batch_norm_legit_no_training_58']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
˜

getitem_174
getitem_165add_2005node_add_2005"AddJﬂ
	namespace—: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.1: torchvision.models.efficientnet.MBConv/add_2005: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jó
pkg.torch.onnx.fx_node}%add_2005 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_174, %getitem_165), kwargs = {})Jc
pkg.torch.onnx.name_scopesE['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.1', 'add_2005']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
å
add_2005
#encoder.stages.6.2.block.0.0.weight
(encoder.stages.6.2.block.0.0.weight_biasgetitem_177node_Conv_1513"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.2: torchvision.models.efficientnet.MBConv/encoder.stages.6.2.block: torch.nn.modules.container.Sequential/encoder.stages.6.2.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.2.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_59: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']J˛
pkg.torch.onnx.fx_node„%_native_batch_norm_legit_no_training_59 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_99, %p_encoder_stages_6_2_block_0_1_weight, %p_encoder_stages_6_2_block_0_1_bias, %b_encoder_stages_6_2_block_0_1_running_mean, %b_encoder_stages_6_2_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.2', 'encoder.stages.6.2.block', 'encoder.stages.6.2.block.0', 'encoder.stages.6.2.block.0.1', '_native_batch_norm_legit_no_training_59']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_177val_801node_Sigmoid_801"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.2: torchvision.models.efficientnet.MBConv/encoder.stages.6.2.block: torch.nn.modules.container.Sequential/encoder.stages.6.2.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.2.block.0.2: torch.nn.modules.activation.SiLU/silu_59: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_59 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_177,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.2', 'encoder.stages.6.2.block', 'encoder.stages.6.2.block.0', 'encoder.stages.6.2.block.0.2', 'silu_59']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_177
val_801silu_59node_silu_59"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.2: torchvision.models.efficientnet.MBConv/encoder.stages.6.2.block: torch.nn.modules.container.Sequential/encoder.stages.6.2.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.2.block.0.2: torch.nn.modules.activation.SiLU/silu_59: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_59 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_177,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.2', 'encoder.stages.6.2.block', 'encoder.stages.6.2.block.0', 'encoder.stages.6.2.block.0.2', 'silu_59']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ç
silu_59
#encoder.stages.6.2.block.1.0.weight
(encoder.stages.6.2.block.1.0.weight_biasgetitem_180node_Conv_1515"Conv*
group
†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.2: torchvision.models.efficientnet.MBConv/encoder.stages.6.2.block: torch.nn.modules.container.Sequential/encoder.stages.6.2.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.2.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_60: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_60 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_100, %p_encoder_stages_6_2_block_1_1_weight, %p_encoder_stages_6_2_block_1_1_bias, %b_encoder_stages_6_2_block_1_1_running_mean, %b_encoder_stages_6_2_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.2', 'encoder.stages.6.2.block', 'encoder.stages.6.2.block.1', 'encoder.stages.6.2.block.1.1', '_native_batch_norm_legit_no_training_60']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_180val_813node_Sigmoid_813"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.2: torchvision.models.efficientnet.MBConv/encoder.stages.6.2.block: torch.nn.modules.container.Sequential/encoder.stages.6.2.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.2.block.1.2: torch.nn.modules.activation.SiLU/silu_60: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_60 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_180,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.2', 'encoder.stages.6.2.block', 'encoder.stages.6.2.block.1', 'encoder.stages.6.2.block.1.2', 'silu_60']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_180
val_813silu_60node_silu_60"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.2: torchvision.models.efficientnet.MBConv/encoder.stages.6.2.block: torch.nn.modules.container.Sequential/encoder.stages.6.2.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.2.block.1.2: torch.nn.modules.activation.SiLU/silu_60: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_60 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_180,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.2', 'encoder.stages.6.2.block', 'encoder.stages.6.2.block.1', 'encoder.stages.6.2.block.1.2', 'silu_60']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ı
silu_60
val_67mean_20node_mean_20"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÆ
	namespace†: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.2: torchvision.models.efficientnet.MBConv/encoder.stages.6.2.block: torch.nn.modules.container.Sequential/encoder.stages.6.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.2.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_20: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jí
pkg.torch.onnx.fx_nodex%mean_20 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_60, [-1, -2], True), kwargs = {})J√
pkg.torch.onnx.name_scopes§['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.2', 'encoder.stages.6.2.block', 'encoder.stages.6.2.block.2', 'encoder.stages.6.2.block.2.avgpool', 'mean_20']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
¢
mean_20
%encoder.stages.6.2.block.2.fc1.weight
#encoder.stages.6.2.block.2.fc1.bias
conv2d_101node_conv2d_101"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.2: torchvision.models.efficientnet.MBConv/encoder.stages.6.2.block: torch.nn.modules.container.Sequential/encoder.stages.6.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.2.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_101: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']Jﬁ
pkg.torch.onnx.fx_node√%conv2d_101 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_20, %p_encoder_stages_6_2_block_2_fc1_weight, %p_encoder_stages_6_2_block_2_fc1_bias), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.2', 'encoder.stages.6.2.block', 'encoder.stages.6.2.block.2', 'encoder.stages.6.2.block.2.fc1', 'conv2d_101']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
¨

conv2d_101val_816node_Sigmoid_816"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.2: torchvision.models.efficientnet.MBConv/encoder.stages.6.2.block: torch.nn.modules.container.Sequential/encoder.stages.6.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.2.block.2.activation: torch.nn.modules.activation.SiLU/silu_61: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_61 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_101,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.2', 'encoder.stages.6.2.block', 'encoder.stages.6.2.block.2', 'encoder.stages.6.2.block.2.activation', 'silu_61']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
≠

conv2d_101
val_816silu_61node_silu_61"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.2: torchvision.models.efficientnet.MBConv/encoder.stages.6.2.block: torch.nn.modules.container.Sequential/encoder.stages.6.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.2.block.2.activation: torch.nn.modules.activation.SiLU/silu_61: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_61 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_101,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.2', 'encoder.stages.6.2.block', 'encoder.stages.6.2.block.2', 'encoder.stages.6.2.block.2.activation', 'silu_61']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢
silu_61
%encoder.stages.6.2.block.2.fc2.weight
#encoder.stages.6.2.block.2.fc2.bias
conv2d_102node_conv2d_102"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.2: torchvision.models.efficientnet.MBConv/encoder.stages.6.2.block: torch.nn.modules.container.Sequential/encoder.stages.6.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.2.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_102: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']Jﬁ
pkg.torch.onnx.fx_node√%conv2d_102 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_61, %p_encoder_stages_6_2_block_2_fc2_weight, %p_encoder_stages_6_2_block_2_fc2_bias), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.2', 'encoder.stages.6.2.block', 'encoder.stages.6.2.block.2', 'encoder.stages.6.2.block.2.fc2', 'conv2d_102']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
√

conv2d_102
sigmoid_20node_sigmoid_20"SigmoidJ∫
	namespace¨: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.2: torchvision.models.efficientnet.MBConv/encoder.stages.6.2.block: torch.nn.modules.container.Sequential/encoder.stages.6.2.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.2.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_20: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jê
pkg.torch.onnx.fx_nodev%sigmoid_20 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_102,), kwargs = {})Jœ
pkg.torch.onnx.name_scopes∞['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.2', 'encoder.stages.6.2.block', 'encoder.stages.6.2.block.2', 'encoder.stages.6.2.block.2.scale_activation', 'sigmoid_20']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ÿ

sigmoid_20
silu_60mul_2646node_mul_2646"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.2: torchvision.models.efficientnet.MBConv/encoder.stages.6.2.block: torch.nn.modules.container.Sequential/encoder.stages.6.2.block.2: torchvision.ops.misc.SqueezeExcitation/mul_2646: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_2646 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_20, %silu_60), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.2', 'encoder.stages.6.2.block', 'encoder.stages.6.2.block.2', 'mul_2646']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
ç
mul_2646
#encoder.stages.6.2.block.3.0.weight
(encoder.stages.6.2.block.3.0.weight_biasgetitem_183node_Conv_1517"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.2: torchvision.models.efficientnet.MBConv/encoder.stages.6.2.block: torch.nn.modules.container.Sequential/encoder.stages.6.2.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.2.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_61: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_61 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_103, %p_encoder_stages_6_2_block_3_1_weight, %p_encoder_stages_6_2_block_3_1_bias, %b_encoder_stages_6_2_block_3_1_running_mean, %b_encoder_stages_6_2_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.2', 'encoder.stages.6.2.block', 'encoder.stages.6.2.block.3', 'encoder.stages.6.2.block.3.1', '_native_batch_norm_legit_no_training_61']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ò

getitem_183
add_2005add_2109node_add_2109"AddJﬂ
	namespace—: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.2: torchvision.models.efficientnet.MBConv/add_2109: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_2109 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_183, %add_2005), kwargs = {})Jc
pkg.torch.onnx.name_scopesE['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.2', 'add_2109']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
ç
add_2109
#encoder.stages.6.3.block.0.0.weight
(encoder.stages.6.3.block.0.0.weight_biasgetitem_186node_Conv_1519"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.3: torchvision.models.efficientnet.MBConv/encoder.stages.6.3.block: torch.nn.modules.container.Sequential/encoder.stages.6.3.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.3.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_62: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_62 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_104, %p_encoder_stages_6_3_block_0_1_weight, %p_encoder_stages_6_3_block_0_1_bias, %b_encoder_stages_6_3_block_0_1_running_mean, %b_encoder_stages_6_3_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.3', 'encoder.stages.6.3.block', 'encoder.stages.6.3.block.0', 'encoder.stages.6.3.block.0.1', '_native_batch_norm_legit_no_training_62']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_186val_839node_Sigmoid_839"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.3: torchvision.models.efficientnet.MBConv/encoder.stages.6.3.block: torch.nn.modules.container.Sequential/encoder.stages.6.3.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.3.block.0.2: torch.nn.modules.activation.SiLU/silu_62: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_62 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_186,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.3', 'encoder.stages.6.3.block', 'encoder.stages.6.3.block.0', 'encoder.stages.6.3.block.0.2', 'silu_62']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_186
val_839silu_62node_silu_62"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.3: torchvision.models.efficientnet.MBConv/encoder.stages.6.3.block: torch.nn.modules.container.Sequential/encoder.stages.6.3.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.3.block.0.2: torch.nn.modules.activation.SiLU/silu_62: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_62 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_186,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.3', 'encoder.stages.6.3.block', 'encoder.stages.6.3.block.0', 'encoder.stages.6.3.block.0.2', 'silu_62']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ç
silu_62
#encoder.stages.6.3.block.1.0.weight
(encoder.stages.6.3.block.1.0.weight_biasgetitem_189node_Conv_1521"Conv*
group
†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.3: torchvision.models.efficientnet.MBConv/encoder.stages.6.3.block: torch.nn.modules.container.Sequential/encoder.stages.6.3.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.3.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_63: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_63 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_105, %p_encoder_stages_6_3_block_1_1_weight, %p_encoder_stages_6_3_block_1_1_bias, %b_encoder_stages_6_3_block_1_1_running_mean, %b_encoder_stages_6_3_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.3', 'encoder.stages.6.3.block', 'encoder.stages.6.3.block.1', 'encoder.stages.6.3.block.1.1', '_native_batch_norm_legit_no_training_63']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_189val_851node_Sigmoid_851"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.3: torchvision.models.efficientnet.MBConv/encoder.stages.6.3.block: torch.nn.modules.container.Sequential/encoder.stages.6.3.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.3.block.1.2: torch.nn.modules.activation.SiLU/silu_63: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_63 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_189,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.3', 'encoder.stages.6.3.block', 'encoder.stages.6.3.block.1', 'encoder.stages.6.3.block.1.2', 'silu_63']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_189
val_851silu_63node_silu_63"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.3: torchvision.models.efficientnet.MBConv/encoder.stages.6.3.block: torch.nn.modules.container.Sequential/encoder.stages.6.3.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.3.block.1.2: torch.nn.modules.activation.SiLU/silu_63: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_63 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_189,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.3', 'encoder.stages.6.3.block', 'encoder.stages.6.3.block.1', 'encoder.stages.6.3.block.1.2', 'silu_63']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ı
silu_63
val_67mean_21node_mean_21"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÆ
	namespace†: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.3: torchvision.models.efficientnet.MBConv/encoder.stages.6.3.block: torch.nn.modules.container.Sequential/encoder.stages.6.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.3.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_21: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jí
pkg.torch.onnx.fx_nodex%mean_21 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_63, [-1, -2], True), kwargs = {})J√
pkg.torch.onnx.name_scopes§['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.3', 'encoder.stages.6.3.block', 'encoder.stages.6.3.block.2', 'encoder.stages.6.3.block.2.avgpool', 'mean_21']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
¢
mean_21
%encoder.stages.6.3.block.2.fc1.weight
#encoder.stages.6.3.block.2.fc1.bias
conv2d_106node_conv2d_106"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.3: torchvision.models.efficientnet.MBConv/encoder.stages.6.3.block: torch.nn.modules.container.Sequential/encoder.stages.6.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.3.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_106: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']Jﬁ
pkg.torch.onnx.fx_node√%conv2d_106 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_21, %p_encoder_stages_6_3_block_2_fc1_weight, %p_encoder_stages_6_3_block_2_fc1_bias), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.3', 'encoder.stages.6.3.block', 'encoder.stages.6.3.block.2', 'encoder.stages.6.3.block.2.fc1', 'conv2d_106']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
¨

conv2d_106val_854node_Sigmoid_854"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.3: torchvision.models.efficientnet.MBConv/encoder.stages.6.3.block: torch.nn.modules.container.Sequential/encoder.stages.6.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.3.block.2.activation: torch.nn.modules.activation.SiLU/silu_64: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_64 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_106,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.3', 'encoder.stages.6.3.block', 'encoder.stages.6.3.block.2', 'encoder.stages.6.3.block.2.activation', 'silu_64']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
≠

conv2d_106
val_854silu_64node_silu_64"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.3: torchvision.models.efficientnet.MBConv/encoder.stages.6.3.block: torch.nn.modules.container.Sequential/encoder.stages.6.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.3.block.2.activation: torch.nn.modules.activation.SiLU/silu_64: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_64 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_106,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.3', 'encoder.stages.6.3.block', 'encoder.stages.6.3.block.2', 'encoder.stages.6.3.block.2.activation', 'silu_64']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢
silu_64
%encoder.stages.6.3.block.2.fc2.weight
#encoder.stages.6.3.block.2.fc2.bias
conv2d_107node_conv2d_107"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.3: torchvision.models.efficientnet.MBConv/encoder.stages.6.3.block: torch.nn.modules.container.Sequential/encoder.stages.6.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.3.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_107: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']Jﬁ
pkg.torch.onnx.fx_node√%conv2d_107 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_64, %p_encoder_stages_6_3_block_2_fc2_weight, %p_encoder_stages_6_3_block_2_fc2_bias), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.3', 'encoder.stages.6.3.block', 'encoder.stages.6.3.block.2', 'encoder.stages.6.3.block.2.fc2', 'conv2d_107']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
√

conv2d_107
sigmoid_21node_sigmoid_21"SigmoidJ∫
	namespace¨: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.3: torchvision.models.efficientnet.MBConv/encoder.stages.6.3.block: torch.nn.modules.container.Sequential/encoder.stages.6.3.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.3.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_21: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jê
pkg.torch.onnx.fx_nodev%sigmoid_21 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_107,), kwargs = {})Jœ
pkg.torch.onnx.name_scopes∞['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.3', 'encoder.stages.6.3.block', 'encoder.stages.6.3.block.2', 'encoder.stages.6.3.block.2.scale_activation', 'sigmoid_21']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ÿ

sigmoid_21
silu_63mul_2775node_mul_2775"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.3: torchvision.models.efficientnet.MBConv/encoder.stages.6.3.block: torch.nn.modules.container.Sequential/encoder.stages.6.3.block.2: torchvision.ops.misc.SqueezeExcitation/mul_2775: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_2775 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_21, %silu_63), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.3', 'encoder.stages.6.3.block', 'encoder.stages.6.3.block.2', 'mul_2775']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
ç
mul_2775
#encoder.stages.6.3.block.3.0.weight
(encoder.stages.6.3.block.3.0.weight_biasgetitem_192node_Conv_1523"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.3: torchvision.models.efficientnet.MBConv/encoder.stages.6.3.block: torch.nn.modules.container.Sequential/encoder.stages.6.3.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.3.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_64: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_64 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_108, %p_encoder_stages_6_3_block_3_1_weight, %p_encoder_stages_6_3_block_3_1_bias, %b_encoder_stages_6_3_block_3_1_running_mean, %b_encoder_stages_6_3_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.3', 'encoder.stages.6.3.block', 'encoder.stages.6.3.block.3', 'encoder.stages.6.3.block.3.1', '_native_batch_norm_legit_no_training_64']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ò

getitem_192
add_2109add_2213node_add_2213"AddJﬂ
	namespace—: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.3: torchvision.models.efficientnet.MBConv/add_2213: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_2213 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_192, %add_2109), kwargs = {})Jc
pkg.torch.onnx.name_scopesE['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.3', 'add_2213']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
ç
add_2213
#encoder.stages.6.4.block.0.0.weight
(encoder.stages.6.4.block.0.0.weight_biasgetitem_195node_Conv_1525"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.4: torchvision.models.efficientnet.MBConv/encoder.stages.6.4.block: torch.nn.modules.container.Sequential/encoder.stages.6.4.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.4.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_65: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_65 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_109, %p_encoder_stages_6_4_block_0_1_weight, %p_encoder_stages_6_4_block_0_1_bias, %b_encoder_stages_6_4_block_0_1_running_mean, %b_encoder_stages_6_4_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.4', 'encoder.stages.6.4.block', 'encoder.stages.6.4.block.0', 'encoder.stages.6.4.block.0.1', '_native_batch_norm_legit_no_training_65']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_195val_877node_Sigmoid_877"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.4: torchvision.models.efficientnet.MBConv/encoder.stages.6.4.block: torch.nn.modules.container.Sequential/encoder.stages.6.4.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.4.block.0.2: torch.nn.modules.activation.SiLU/silu_65: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_65 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_195,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.4', 'encoder.stages.6.4.block', 'encoder.stages.6.4.block.0', 'encoder.stages.6.4.block.0.2', 'silu_65']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_195
val_877silu_65node_silu_65"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.4: torchvision.models.efficientnet.MBConv/encoder.stages.6.4.block: torch.nn.modules.container.Sequential/encoder.stages.6.4.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.4.block.0.2: torch.nn.modules.activation.SiLU/silu_65: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_65 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_195,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.4', 'encoder.stages.6.4.block', 'encoder.stages.6.4.block.0', 'encoder.stages.6.4.block.0.2', 'silu_65']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ç
silu_65
#encoder.stages.6.4.block.1.0.weight
(encoder.stages.6.4.block.1.0.weight_biasgetitem_198node_Conv_1527"Conv*
group
†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.4: torchvision.models.efficientnet.MBConv/encoder.stages.6.4.block: torch.nn.modules.container.Sequential/encoder.stages.6.4.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.4.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_66: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_66 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_110, %p_encoder_stages_6_4_block_1_1_weight, %p_encoder_stages_6_4_block_1_1_bias, %b_encoder_stages_6_4_block_1_1_running_mean, %b_encoder_stages_6_4_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.4', 'encoder.stages.6.4.block', 'encoder.stages.6.4.block.1', 'encoder.stages.6.4.block.1.1', '_native_batch_norm_legit_no_training_66']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_198val_889node_Sigmoid_889"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.4: torchvision.models.efficientnet.MBConv/encoder.stages.6.4.block: torch.nn.modules.container.Sequential/encoder.stages.6.4.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.4.block.1.2: torch.nn.modules.activation.SiLU/silu_66: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_66 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_198,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.4', 'encoder.stages.6.4.block', 'encoder.stages.6.4.block.1', 'encoder.stages.6.4.block.1.2', 'silu_66']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_198
val_889silu_66node_silu_66"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.4: torchvision.models.efficientnet.MBConv/encoder.stages.6.4.block: torch.nn.modules.container.Sequential/encoder.stages.6.4.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.4.block.1.2: torch.nn.modules.activation.SiLU/silu_66: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_66 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_198,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.4', 'encoder.stages.6.4.block', 'encoder.stages.6.4.block.1', 'encoder.stages.6.4.block.1.2', 'silu_66']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ı
silu_66
val_67mean_22node_mean_22"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÆ
	namespace†: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.4: torchvision.models.efficientnet.MBConv/encoder.stages.6.4.block: torch.nn.modules.container.Sequential/encoder.stages.6.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.4.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_22: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jí
pkg.torch.onnx.fx_nodex%mean_22 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_66, [-1, -2], True), kwargs = {})J√
pkg.torch.onnx.name_scopes§['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.4', 'encoder.stages.6.4.block', 'encoder.stages.6.4.block.2', 'encoder.stages.6.4.block.2.avgpool', 'mean_22']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
¢
mean_22
%encoder.stages.6.4.block.2.fc1.weight
#encoder.stages.6.4.block.2.fc1.bias
conv2d_111node_conv2d_111"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.4: torchvision.models.efficientnet.MBConv/encoder.stages.6.4.block: torch.nn.modules.container.Sequential/encoder.stages.6.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.4.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_111: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']Jﬁ
pkg.torch.onnx.fx_node√%conv2d_111 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_22, %p_encoder_stages_6_4_block_2_fc1_weight, %p_encoder_stages_6_4_block_2_fc1_bias), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.4', 'encoder.stages.6.4.block', 'encoder.stages.6.4.block.2', 'encoder.stages.6.4.block.2.fc1', 'conv2d_111']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
¨

conv2d_111val_892node_Sigmoid_892"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.4: torchvision.models.efficientnet.MBConv/encoder.stages.6.4.block: torch.nn.modules.container.Sequential/encoder.stages.6.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.4.block.2.activation: torch.nn.modules.activation.SiLU/silu_67: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_67 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_111,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.4', 'encoder.stages.6.4.block', 'encoder.stages.6.4.block.2', 'encoder.stages.6.4.block.2.activation', 'silu_67']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
≠

conv2d_111
val_892silu_67node_silu_67"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.4: torchvision.models.efficientnet.MBConv/encoder.stages.6.4.block: torch.nn.modules.container.Sequential/encoder.stages.6.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.4.block.2.activation: torch.nn.modules.activation.SiLU/silu_67: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_67 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_111,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.4', 'encoder.stages.6.4.block', 'encoder.stages.6.4.block.2', 'encoder.stages.6.4.block.2.activation', 'silu_67']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢
silu_67
%encoder.stages.6.4.block.2.fc2.weight
#encoder.stages.6.4.block.2.fc2.bias
conv2d_112node_conv2d_112"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.4: torchvision.models.efficientnet.MBConv/encoder.stages.6.4.block: torch.nn.modules.container.Sequential/encoder.stages.6.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.4.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_112: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']Jﬁ
pkg.torch.onnx.fx_node√%conv2d_112 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_67, %p_encoder_stages_6_4_block_2_fc2_weight, %p_encoder_stages_6_4_block_2_fc2_bias), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.4', 'encoder.stages.6.4.block', 'encoder.stages.6.4.block.2', 'encoder.stages.6.4.block.2.fc2', 'conv2d_112']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
√

conv2d_112
sigmoid_22node_sigmoid_22"SigmoidJ∫
	namespace¨: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.4: torchvision.models.efficientnet.MBConv/encoder.stages.6.4.block: torch.nn.modules.container.Sequential/encoder.stages.6.4.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.4.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_22: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jê
pkg.torch.onnx.fx_nodev%sigmoid_22 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_112,), kwargs = {})Jœ
pkg.torch.onnx.name_scopes∞['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.4', 'encoder.stages.6.4.block', 'encoder.stages.6.4.block.2', 'encoder.stages.6.4.block.2.scale_activation', 'sigmoid_22']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ÿ

sigmoid_22
silu_66mul_2904node_mul_2904"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.4: torchvision.models.efficientnet.MBConv/encoder.stages.6.4.block: torch.nn.modules.container.Sequential/encoder.stages.6.4.block.2: torchvision.ops.misc.SqueezeExcitation/mul_2904: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_2904 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_22, %silu_66), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.4', 'encoder.stages.6.4.block', 'encoder.stages.6.4.block.2', 'mul_2904']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
ç
mul_2904
#encoder.stages.6.4.block.3.0.weight
(encoder.stages.6.4.block.3.0.weight_biasgetitem_201node_Conv_1529"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.4: torchvision.models.efficientnet.MBConv/encoder.stages.6.4.block: torch.nn.modules.container.Sequential/encoder.stages.6.4.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.4.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_67: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_67 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_113, %p_encoder_stages_6_4_block_3_1_weight, %p_encoder_stages_6_4_block_3_1_bias, %b_encoder_stages_6_4_block_3_1_running_mean, %b_encoder_stages_6_4_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.4', 'encoder.stages.6.4.block', 'encoder.stages.6.4.block.3', 'encoder.stages.6.4.block.3.1', '_native_batch_norm_legit_no_training_67']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ò

getitem_201
add_2213add_2317node_add_2317"AddJﬂ
	namespace—: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.4: torchvision.models.efficientnet.MBConv/add_2317: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_2317 : [num_users=2] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_201, %add_2213), kwargs = {})Jc
pkg.torch.onnx.name_scopesE['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.4', 'add_2317']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
ç
add_2317
#encoder.stages.6.5.block.0.0.weight
(encoder.stages.6.5.block.0.0.weight_biasgetitem_204node_Conv_1531"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.5: torchvision.models.efficientnet.MBConv/encoder.stages.6.5.block: torch.nn.modules.container.Sequential/encoder.stages.6.5.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.5.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_68: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_68 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_114, %p_encoder_stages_6_5_block_0_1_weight, %p_encoder_stages_6_5_block_0_1_bias, %b_encoder_stages_6_5_block_0_1_running_mean, %b_encoder_stages_6_5_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.5', 'encoder.stages.6.5.block', 'encoder.stages.6.5.block.0', 'encoder.stages.6.5.block.0.1', '_native_batch_norm_legit_no_training_68']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_204val_915node_Sigmoid_915"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.5: torchvision.models.efficientnet.MBConv/encoder.stages.6.5.block: torch.nn.modules.container.Sequential/encoder.stages.6.5.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.5.block.0.2: torch.nn.modules.activation.SiLU/silu_68: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_68 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_204,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.5', 'encoder.stages.6.5.block', 'encoder.stages.6.5.block.0', 'encoder.stages.6.5.block.0.2', 'silu_68']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_204
val_915silu_68node_silu_68"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.5: torchvision.models.efficientnet.MBConv/encoder.stages.6.5.block: torch.nn.modules.container.Sequential/encoder.stages.6.5.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.5.block.0.2: torch.nn.modules.activation.SiLU/silu_68: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_68 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_204,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.5', 'encoder.stages.6.5.block', 'encoder.stages.6.5.block.0', 'encoder.stages.6.5.block.0.2', 'silu_68']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ç
silu_68
#encoder.stages.6.5.block.1.0.weight
(encoder.stages.6.5.block.1.0.weight_biasgetitem_207node_Conv_1533"Conv*
group
†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.5: torchvision.models.efficientnet.MBConv/encoder.stages.6.5.block: torch.nn.modules.container.Sequential/encoder.stages.6.5.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.5.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_69: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_69 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_115, %p_encoder_stages_6_5_block_1_1_weight, %p_encoder_stages_6_5_block_1_1_bias, %b_encoder_stages_6_5_block_1_1_running_mean, %b_encoder_stages_6_5_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.5', 'encoder.stages.6.5.block', 'encoder.stages.6.5.block.1', 'encoder.stages.6.5.block.1.1', '_native_batch_norm_legit_no_training_69']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_207val_927node_Sigmoid_927"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.5: torchvision.models.efficientnet.MBConv/encoder.stages.6.5.block: torch.nn.modules.container.Sequential/encoder.stages.6.5.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.5.block.1.2: torch.nn.modules.activation.SiLU/silu_69: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_69 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_207,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.5', 'encoder.stages.6.5.block', 'encoder.stages.6.5.block.1', 'encoder.stages.6.5.block.1.2', 'silu_69']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_207
val_927silu_69node_silu_69"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.5: torchvision.models.efficientnet.MBConv/encoder.stages.6.5.block: torch.nn.modules.container.Sequential/encoder.stages.6.5.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.5.block.1.2: torch.nn.modules.activation.SiLU/silu_69: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_69 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_207,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.5', 'encoder.stages.6.5.block', 'encoder.stages.6.5.block.1', 'encoder.stages.6.5.block.1.2', 'silu_69']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ı
silu_69
val_67mean_23node_mean_23"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÆ
	namespace†: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.5: torchvision.models.efficientnet.MBConv/encoder.stages.6.5.block: torch.nn.modules.container.Sequential/encoder.stages.6.5.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.5.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_23: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jí
pkg.torch.onnx.fx_nodex%mean_23 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_69, [-1, -2], True), kwargs = {})J√
pkg.torch.onnx.name_scopes§['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.5', 'encoder.stages.6.5.block', 'encoder.stages.6.5.block.2', 'encoder.stages.6.5.block.2.avgpool', 'mean_23']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
¢
mean_23
%encoder.stages.6.5.block.2.fc1.weight
#encoder.stages.6.5.block.2.fc1.bias
conv2d_116node_conv2d_116"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.5: torchvision.models.efficientnet.MBConv/encoder.stages.6.5.block: torch.nn.modules.container.Sequential/encoder.stages.6.5.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.5.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_116: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']Jﬁ
pkg.torch.onnx.fx_node√%conv2d_116 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_23, %p_encoder_stages_6_5_block_2_fc1_weight, %p_encoder_stages_6_5_block_2_fc1_bias), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.5', 'encoder.stages.6.5.block', 'encoder.stages.6.5.block.2', 'encoder.stages.6.5.block.2.fc1', 'conv2d_116']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
¨

conv2d_116val_930node_Sigmoid_930"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.5: torchvision.models.efficientnet.MBConv/encoder.stages.6.5.block: torch.nn.modules.container.Sequential/encoder.stages.6.5.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.5.block.2.activation: torch.nn.modules.activation.SiLU/silu_70: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_70 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_116,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.5', 'encoder.stages.6.5.block', 'encoder.stages.6.5.block.2', 'encoder.stages.6.5.block.2.activation', 'silu_70']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
≠

conv2d_116
val_930silu_70node_silu_70"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.5: torchvision.models.efficientnet.MBConv/encoder.stages.6.5.block: torch.nn.modules.container.Sequential/encoder.stages.6.5.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.5.block.2.activation: torch.nn.modules.activation.SiLU/silu_70: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_70 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_116,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.5', 'encoder.stages.6.5.block', 'encoder.stages.6.5.block.2', 'encoder.stages.6.5.block.2.activation', 'silu_70']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢
silu_70
%encoder.stages.6.5.block.2.fc2.weight
#encoder.stages.6.5.block.2.fc2.bias
conv2d_117node_conv2d_117"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.5: torchvision.models.efficientnet.MBConv/encoder.stages.6.5.block: torch.nn.modules.container.Sequential/encoder.stages.6.5.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.5.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_117: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']Jﬁ
pkg.torch.onnx.fx_node√%conv2d_117 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_70, %p_encoder_stages_6_5_block_2_fc2_weight, %p_encoder_stages_6_5_block_2_fc2_bias), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.5', 'encoder.stages.6.5.block', 'encoder.stages.6.5.block.2', 'encoder.stages.6.5.block.2.fc2', 'conv2d_117']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
√

conv2d_117
sigmoid_23node_sigmoid_23"SigmoidJ∫
	namespace¨: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.5: torchvision.models.efficientnet.MBConv/encoder.stages.6.5.block: torch.nn.modules.container.Sequential/encoder.stages.6.5.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.6.5.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_23: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jê
pkg.torch.onnx.fx_nodev%sigmoid_23 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_117,), kwargs = {})Jœ
pkg.torch.onnx.name_scopes∞['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.5', 'encoder.stages.6.5.block', 'encoder.stages.6.5.block.2', 'encoder.stages.6.5.block.2.scale_activation', 'sigmoid_23']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ÿ

sigmoid_23
silu_69mul_3033node_mul_3033"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.5: torchvision.models.efficientnet.MBConv/encoder.stages.6.5.block: torch.nn.modules.container.Sequential/encoder.stages.6.5.block.2: torchvision.ops.misc.SqueezeExcitation/mul_3033: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_3033 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_23, %silu_69), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.5', 'encoder.stages.6.5.block', 'encoder.stages.6.5.block.2', 'mul_3033']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
ç
mul_3033
#encoder.stages.6.5.block.3.0.weight
(encoder.stages.6.5.block.3.0.weight_biasgetitem_210node_Conv_1535"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.5: torchvision.models.efficientnet.MBConv/encoder.stages.6.5.block: torch.nn.modules.container.Sequential/encoder.stages.6.5.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.6.5.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_70: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_70 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_118, %p_encoder_stages_6_5_block_3_1_weight, %p_encoder_stages_6_5_block_3_1_bias, %b_encoder_stages_6_5_block_3_1_running_mean, %b_encoder_stages_6_5_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.5', 'encoder.stages.6.5.block', 'encoder.stages.6.5.block.3', 'encoder.stages.6.5.block.3.1', '_native_batch_norm_legit_no_training_70']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Ò

getitem_210
add_2317add_2421node_add_2421"AddJﬂ
	namespace—: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.6: torch.nn.modules.container.Sequential/encoder.stages.6.5: torchvision.models.efficientnet.MBConv/add_2421: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jî
pkg.torch.onnx.fx_nodez%add_2421 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_210, %add_2317), kwargs = {})Jc
pkg.torch.onnx.name_scopesE['', 'encoder', 'encoder.stages.6', 'encoder.stages.6.5', 'add_2421']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
ç
add_2421
#encoder.stages.7.0.block.0.0.weight
(encoder.stages.7.0.block.0.0.weight_biasgetitem_213node_Conv_1537"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.0: torchvision.models.efficientnet.MBConv/encoder.stages.7.0.block: torch.nn.modules.container.Sequential/encoder.stages.7.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.7.0.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_71: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_71 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_119, %p_encoder_stages_7_0_block_0_1_weight, %p_encoder_stages_7_0_block_0_1_bias, %b_encoder_stages_7_0_block_0_1_running_mean, %b_encoder_stages_7_0_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.0', 'encoder.stages.7.0.block', 'encoder.stages.7.0.block.0', 'encoder.stages.7.0.block.0.1', '_native_batch_norm_legit_no_training_71']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_213val_953node_Sigmoid_953"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.0: torchvision.models.efficientnet.MBConv/encoder.stages.7.0.block: torch.nn.modules.container.Sequential/encoder.stages.7.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.7.0.block.0.2: torch.nn.modules.activation.SiLU/silu_71: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_71 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_213,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.0', 'encoder.stages.7.0.block', 'encoder.stages.7.0.block.0', 'encoder.stages.7.0.block.0.2', 'silu_71']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_213
val_953silu_71node_silu_71"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.0: torchvision.models.efficientnet.MBConv/encoder.stages.7.0.block: torch.nn.modules.container.Sequential/encoder.stages.7.0.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.7.0.block.0.2: torch.nn.modules.activation.SiLU/silu_71: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_71 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_213,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.0', 'encoder.stages.7.0.block', 'encoder.stages.7.0.block.0', 'encoder.stages.7.0.block.0.2', 'silu_71']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ç
silu_71
#encoder.stages.7.0.block.1.0.weight
(encoder.stages.7.0.block.1.0.weight_biasgetitem_216node_Conv_1539"Conv*
group
†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.0: torchvision.models.efficientnet.MBConv/encoder.stages.7.0.block: torch.nn.modules.container.Sequential/encoder.stages.7.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.7.0.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_72: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_72 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_120, %p_encoder_stages_7_0_block_1_1_weight, %p_encoder_stages_7_0_block_1_1_bias, %b_encoder_stages_7_0_block_1_1_running_mean, %b_encoder_stages_7_0_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.0', 'encoder.stages.7.0.block', 'encoder.stages.7.0.block.1', 'encoder.stages.7.0.block.1.1', '_native_batch_norm_legit_no_training_72']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_216val_965node_Sigmoid_965"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.0: torchvision.models.efficientnet.MBConv/encoder.stages.7.0.block: torch.nn.modules.container.Sequential/encoder.stages.7.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.7.0.block.1.2: torch.nn.modules.activation.SiLU/silu_72: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_72 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_216,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.0', 'encoder.stages.7.0.block', 'encoder.stages.7.0.block.1', 'encoder.stages.7.0.block.1.2', 'silu_72']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_216
val_965silu_72node_silu_72"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.0: torchvision.models.efficientnet.MBConv/encoder.stages.7.0.block: torch.nn.modules.container.Sequential/encoder.stages.7.0.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.7.0.block.1.2: torch.nn.modules.activation.SiLU/silu_72: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_72 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_216,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.0', 'encoder.stages.7.0.block', 'encoder.stages.7.0.block.1', 'encoder.stages.7.0.block.1.2', 'silu_72']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ı
silu_72
val_67mean_24node_mean_24"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÆ
	namespace†: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.0: torchvision.models.efficientnet.MBConv/encoder.stages.7.0.block: torch.nn.modules.container.Sequential/encoder.stages.7.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.7.0.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_24: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jí
pkg.torch.onnx.fx_nodex%mean_24 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_72, [-1, -2], True), kwargs = {})J√
pkg.torch.onnx.name_scopes§['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.0', 'encoder.stages.7.0.block', 'encoder.stages.7.0.block.2', 'encoder.stages.7.0.block.2.avgpool', 'mean_24']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
¢
mean_24
%encoder.stages.7.0.block.2.fc1.weight
#encoder.stages.7.0.block.2.fc1.bias
conv2d_121node_conv2d_121"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.0: torchvision.models.efficientnet.MBConv/encoder.stages.7.0.block: torch.nn.modules.container.Sequential/encoder.stages.7.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.7.0.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_121: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']Jﬁ
pkg.torch.onnx.fx_node√%conv2d_121 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_24, %p_encoder_stages_7_0_block_2_fc1_weight, %p_encoder_stages_7_0_block_2_fc1_bias), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.0', 'encoder.stages.7.0.block', 'encoder.stages.7.0.block.2', 'encoder.stages.7.0.block.2.fc1', 'conv2d_121']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
¨

conv2d_121val_968node_Sigmoid_968"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.0: torchvision.models.efficientnet.MBConv/encoder.stages.7.0.block: torch.nn.modules.container.Sequential/encoder.stages.7.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.7.0.block.2.activation: torch.nn.modules.activation.SiLU/silu_73: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_73 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_121,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.0', 'encoder.stages.7.0.block', 'encoder.stages.7.0.block.2', 'encoder.stages.7.0.block.2.activation', 'silu_73']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
≠

conv2d_121
val_968silu_73node_silu_73"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.0: torchvision.models.efficientnet.MBConv/encoder.stages.7.0.block: torch.nn.modules.container.Sequential/encoder.stages.7.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.7.0.block.2.activation: torch.nn.modules.activation.SiLU/silu_73: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_73 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_121,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.0', 'encoder.stages.7.0.block', 'encoder.stages.7.0.block.2', 'encoder.stages.7.0.block.2.activation', 'silu_73']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢
silu_73
%encoder.stages.7.0.block.2.fc2.weight
#encoder.stages.7.0.block.2.fc2.bias
conv2d_122node_conv2d_122"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.0: torchvision.models.efficientnet.MBConv/encoder.stages.7.0.block: torch.nn.modules.container.Sequential/encoder.stages.7.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.7.0.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_122: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']Jﬁ
pkg.torch.onnx.fx_node√%conv2d_122 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_73, %p_encoder_stages_7_0_block_2_fc2_weight, %p_encoder_stages_7_0_block_2_fc2_bias), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.0', 'encoder.stages.7.0.block', 'encoder.stages.7.0.block.2', 'encoder.stages.7.0.block.2.fc2', 'conv2d_122']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
√

conv2d_122
sigmoid_24node_sigmoid_24"SigmoidJ∫
	namespace¨: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.0: torchvision.models.efficientnet.MBConv/encoder.stages.7.0.block: torch.nn.modules.container.Sequential/encoder.stages.7.0.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.7.0.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_24: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jê
pkg.torch.onnx.fx_nodev%sigmoid_24 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_122,), kwargs = {})Jœ
pkg.torch.onnx.name_scopes∞['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.0', 'encoder.stages.7.0.block', 'encoder.stages.7.0.block.2', 'encoder.stages.7.0.block.2.scale_activation', 'sigmoid_24']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ÿ

sigmoid_24
silu_72mul_3162node_mul_3162"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.0: torchvision.models.efficientnet.MBConv/encoder.stages.7.0.block: torch.nn.modules.container.Sequential/encoder.stages.7.0.block.2: torchvision.ops.misc.SqueezeExcitation/mul_3162: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_3162 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_24, %silu_72), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.0', 'encoder.stages.7.0.block', 'encoder.stages.7.0.block.2', 'mul_3162']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
ç
mul_3162
#encoder.stages.7.0.block.3.0.weight
(encoder.stages.7.0.block.3.0.weight_biasgetitem_219node_Conv_1541"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.0: torchvision.models.efficientnet.MBConv/encoder.stages.7.0.block: torch.nn.modules.container.Sequential/encoder.stages.7.0.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.7.0.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_73: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_73 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_123, %p_encoder_stages_7_0_block_3_1_weight, %p_encoder_stages_7_0_block_3_1_bias, %b_encoder_stages_7_0_block_3_1_running_mean, %b_encoder_stages_7_0_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.0', 'encoder.stages.7.0.block', 'encoder.stages.7.0.block.3', 'encoder.stages.7.0.block.3.1', '_native_batch_norm_legit_no_training_73']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
ê
getitem_219
#encoder.stages.7.1.block.0.0.weight
(encoder.stages.7.1.block.0.0.weight_biasgetitem_222node_Conv_1543"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.1: torchvision.models.efficientnet.MBConv/encoder.stages.7.1.block: torch.nn.modules.container.Sequential/encoder.stages.7.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.7.1.block.0.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_74: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_74 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_124, %p_encoder_stages_7_1_block_0_1_weight, %p_encoder_stages_7_1_block_0_1_bias, %b_encoder_stages_7_1_block_0_1_running_mean, %b_encoder_stages_7_1_block_0_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.1', 'encoder.stages.7.1.block', 'encoder.stages.7.1.block.0', 'encoder.stages.7.1.block.0.1', '_native_batch_norm_legit_no_training_74']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
£
getitem_222val_991node_Sigmoid_991"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.1: torchvision.models.efficientnet.MBConv/encoder.stages.7.1.block: torch.nn.modules.container.Sequential/encoder.stages.7.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.7.1.block.0.2: torch.nn.modules.activation.SiLU/silu_74: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_74 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_222,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.1', 'encoder.stages.7.1.block', 'encoder.stages.7.1.block.0', 'encoder.stages.7.1.block.0.2', 'silu_74']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
§
getitem_222
val_991silu_74node_silu_74"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.1: torchvision.models.efficientnet.MBConv/encoder.stages.7.1.block: torch.nn.modules.container.Sequential/encoder.stages.7.1.block.0: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.7.1.block.0.2: torch.nn.modules.activation.SiLU/silu_74: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_74 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_222,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.1', 'encoder.stages.7.1.block', 'encoder.stages.7.1.block.0', 'encoder.stages.7.1.block.0.2', 'silu_74']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ç
silu_74
#encoder.stages.7.1.block.1.0.weight
(encoder.stages.7.1.block.1.0.weight_biasgetitem_225node_Conv_1545"Conv*
groupÄ†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.1: torchvision.models.efficientnet.MBConv/encoder.stages.7.1.block: torch.nn.modules.container.Sequential/encoder.stages.7.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.7.1.block.1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_75: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_75 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_125, %p_encoder_stages_7_1_block_1_1_weight, %p_encoder_stages_7_1_block_1_1_bias, %b_encoder_stages_7_1_block_1_1_running_mean, %b_encoder_stages_7_1_block_1_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.1', 'encoder.stages.7.1.block', 'encoder.stages.7.1.block.1', 'encoder.stages.7.1.block.1.1', '_native_batch_norm_legit_no_training_75']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
•
getitem_225val_1003node_Sigmoid_1003"SigmoidJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.1: torchvision.models.efficientnet.MBConv/encoder.stages.7.1.block: torch.nn.modules.container.Sequential/encoder.stages.7.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.7.1.block.1.2: torch.nn.modules.activation.SiLU/silu_75: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_75 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_225,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.1', 'encoder.stages.7.1.block', 'encoder.stages.7.1.block.1', 'encoder.stages.7.1.block.1.2', 'silu_75']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
•
getitem_225
val_1003silu_75node_silu_75"MulJ•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.1: torchvision.models.efficientnet.MBConv/encoder.stages.7.1.block: torch.nn.modules.container.Sequential/encoder.stages.7.1.block.1: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.7.1.block.1.2: torch.nn.modules.activation.SiLU/silu_75: aten.silu.defaultJ≈
pkg.torch.onnx.class_hierarchy¢['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jã
pkg.torch.onnx.fx_nodeq%silu_75 : [num_users=2] = call_function[target=torch.ops.aten.silu.default](args = (%getitem_225,), kwargs = {})JΩ
pkg.torch.onnx.name_scopesû['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.1', 'encoder.stages.7.1.block', 'encoder.stages.7.1.block.1', 'encoder.stages.7.1.block.1.2', 'silu_75']J±	
pkg.torch.onnx.stack_traceí	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
ı
silu_75
val_67mean_25node_mean_25"
ReduceMean*
noop_with_empty_axes †*
keepdims†JÆ
	namespace†: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.1: torchvision.models.efficientnet.MBConv/encoder.stages.7.1.block: torch.nn.modules.container.Sequential/encoder.stages.7.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.7.1.block.2.avgpool: torch.nn.modules.pooling.AdaptiveAvgPool2d/mean_25: aten.mean.dimJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'aten.mean.dim']Jí
pkg.torch.onnx.fx_nodex%mean_25 : [num_users=1] = call_function[target=torch.ops.aten.mean.dim](args = (%silu_75, [-1, -2], True), kwargs = {})J√
pkg.torch.onnx.name_scopes§['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.1', 'encoder.stages.7.1.block', 'encoder.stages.7.1.block.2', 'encoder.stages.7.1.block.2.avgpool', 'mean_25']Jπ	
pkg.torch.onnx.stack_traceö	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/pooling.py", line 1510, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
¢
mean_25
%encoder.stages.7.1.block.2.fc1.weight
#encoder.stages.7.1.block.2.fc1.bias
conv2d_126node_conv2d_126"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.1: torchvision.models.efficientnet.MBConv/encoder.stages.7.1.block: torch.nn.modules.container.Sequential/encoder.stages.7.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.7.1.block.2.fc1: torch.nn.modules.conv.Conv2d/conv2d_126: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']Jﬁ
pkg.torch.onnx.fx_node√%conv2d_126 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%mean_25, %p_encoder_stages_7_1_block_2_fc1_weight, %p_encoder_stages_7_1_block_2_fc1_bias), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.1', 'encoder.stages.7.1.block', 'encoder.stages.7.1.block.2', 'encoder.stages.7.1.block.2.fc1', 'conv2d_126']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
Æ

conv2d_126val_1006node_Sigmoid_1006"SigmoidJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.1: torchvision.models.efficientnet.MBConv/encoder.stages.7.1.block: torch.nn.modules.container.Sequential/encoder.stages.7.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.7.1.block.2.activation: torch.nn.modules.activation.SiLU/silu_76: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_76 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_126,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.1', 'encoder.stages.7.1.block', 'encoder.stages.7.1.block.2', 'encoder.stages.7.1.block.2.activation', 'silu_76']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
Æ

conv2d_126
val_1006silu_76node_silu_76"MulJ´
	namespaceù: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.1: torchvision.models.efficientnet.MBConv/encoder.stages.7.1.block: torch.nn.modules.container.Sequential/encoder.stages.7.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.7.1.block.2.activation: torch.nn.modules.activation.SiLU/silu_76: aten.silu.defaultJ¬
pkg.torch.onnx.class_hierarchyü['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.SiLU', 'aten.silu.default']Jä
pkg.torch.onnx.fx_nodep%silu_76 : [num_users=1] = call_function[target=torch.ops.aten.silu.default](args = (%conv2d_126,), kwargs = {})J∆
pkg.torch.onnx.name_scopesß['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.1', 'encoder.stages.7.1.block', 'encoder.stages.7.1.block.2', 'encoder.stages.7.1.block.2.activation', 'silu_76']J∞	
pkg.torch.onnx.stack_traceë	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 472, in forward
    return F.silu(input, inplace=self.inplace)
¢
silu_76
%encoder.stages.7.1.block.2.fc2.weight
#encoder.stages.7.1.block.2.fc2.bias
conv2d_127node_conv2d_127"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J•
	namespaceó: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.1: torchvision.models.efficientnet.MBConv/encoder.stages.7.1.block: torch.nn.modules.container.Sequential/encoder.stages.7.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.7.1.block.2.fc2: torch.nn.modules.conv.Conv2d/conv2d_127: aten.conv2d.defaultJ¿
pkg.torch.onnx.class_hierarchyù['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']Jﬁ
pkg.torch.onnx.fx_node√%conv2d_127 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%silu_76, %p_encoder_stages_7_1_block_2_fc2_weight, %p_encoder_stages_7_1_block_2_fc2_bias), kwargs = {})J¬
pkg.torch.onnx.name_scopes£['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.1', 'encoder.stages.7.1.block', 'encoder.stages.7.1.block.2', 'encoder.stages.7.1.block.2.fc2', 'conv2d_127']J∏	
pkg.torch.onnx.stack_traceô	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
√

conv2d_127
sigmoid_25node_sigmoid_25"SigmoidJ∫
	namespace¨: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.1: torchvision.models.efficientnet.MBConv/encoder.stages.7.1.block: torch.nn.modules.container.Sequential/encoder.stages.7.1.block.2: torchvision.ops.misc.SqueezeExcitation/encoder.stages.7.1.block.2.scale_activation: torch.nn.modules.activation.Sigmoid/sigmoid_25: aten.sigmoid.defaultJ»
pkg.torch.onnx.class_hierarchy•['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'torch.nn.modules.activation.Sigmoid', 'aten.sigmoid.default']Jê
pkg.torch.onnx.fx_nodev%sigmoid_25 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%conv2d_127,), kwargs = {})Jœ
pkg.torch.onnx.name_scopes∞['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.1', 'encoder.stages.7.1.block', 'encoder.stages.7.1.block.2', 'encoder.stages.7.1.block.2.scale_activation', 'sigmoid_25']J°	
pkg.torch.onnx.stack_traceÇ	File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 260, in forward
    scale = self._scale(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 358, in forward
    return torch.sigmoid(input)
ÿ

sigmoid_25
silu_75mul_3279node_mul_3279"MulJ‚
	namespace‘: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.1: torchvision.models.efficientnet.MBConv/encoder.stages.7.1.block: torch.nn.modules.container.Sequential/encoder.stages.7.1.block.2: torchvision.ops.misc.SqueezeExcitation/mul_3279: aten.mul.TensorJú
pkg.torch.onnx.class_hierarchy˘['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.SqueezeExcitation', 'aten.mul.Tensor']Jí
pkg.torch.onnx.fx_nodex%mul_3279 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sigmoid_25, %silu_75), kwargs = {})Jù
pkg.torch.onnx.name_scopes['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.1', 'encoder.stages.7.1.block', 'encoder.stages.7.1.block.2', 'mul_3279']JÈ
pkg.torch.onnx.stack_trace File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/ops/misc.py", line 261, in forward
    return scale * input
ç
mul_3279
#encoder.stages.7.1.block.3.0.weight
(encoder.stages.7.1.block.3.0.weight_biasgetitem_228node_Conv_1547"Conv*
group†*
pads@ @ @ @ †*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†JÎ
	namespace›: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.1: torchvision.models.efficientnet.MBConv/encoder.stages.7.1.block: torch.nn.modules.container.Sequential/encoder.stages.7.1.block.3: torchvision.ops.misc.Conv2dNormActivation/encoder.stages.7.1.block.3.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_76: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÎ
pkg.torch.onnx.class_hierarchy»['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'torch.nn.modules.container.Sequential', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']Jˇ
pkg.torch.onnx.fx_node‰%_native_batch_norm_legit_no_training_76 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_128, %p_encoder_stages_7_1_block_3_1_weight, %p_encoder_stages_7_1_block_3_1_bias, %b_encoder_stages_7_1_block_3_1_running_mean, %b_encoder_stages_7_1_block_3_1_running_var, 0.1, 1e-05), kwargs = {})J›
pkg.torch.onnx.name_scopesæ['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.1', 'encoder.stages.7.1.block', 'encoder.stages.7.1.block.3', 'encoder.stages.7.1.block.3.1', '_native_batch_norm_legit_no_training_76']Jö	
pkg.torch.onnx.stack_trace˚File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 165, in forward
    result = self.block(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
˜

getitem_228
getitem_219add_2613node_add_2613"AddJﬂ
	namespace—: nn.model.SegmentationNet/encoder: nn.backbone.EfficientNetBackbone/encoder.stages.7: torch.nn.modules.container.Sequential/encoder.stages.7.1: torchvision.models.efficientnet.MBConv/add_2613: aten.add.TensorJ…
pkg.torch.onnx.class_hierarchy¶['nn.model.SegmentationNet', 'nn.backbone.EfficientNetBackbone', 'torch.nn.modules.container.Sequential', 'torchvision.models.efficientnet.MBConv', 'aten.add.Tensor']Jó
pkg.torch.onnx.fx_node}%add_2613 : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem_228, %getitem_219), kwargs = {})Jc
pkg.torch.onnx.name_scopesE['', 'encoder', 'encoder.stages.7', 'encoder.stages.7.1', 'add_2613']Jè
pkg.torch.onnx.stack_traceFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 156, in forward
    features = self.encoder(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/backbone.py", line 85, in forward
    x = stage(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torchvision/models/efficientnet.py", line 168, in forward
    result += input
Ë

add_2613
 
val_1018upsample_nearest2dnode_upsample_nearest2d"Resize*
extrapolation_value    †*&
keep_aspect_ratio_policy"stretch†*
	antialias †*
nearest_mode"floor†*
exclude_outside †*
cubic_coeff_a  @ø†*/
coordinate_transformation_mode"
asymmetric†*
mode"nearest†J¢
	namespaceî: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.0: nn.decoder.DecoderBlock/upsample_nearest2d: aten.upsample_nearest2d.vecJí
pkg.torch.onnx.class_hierarchyp['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'aten.upsample_nearest2d.vec']JØ
pkg.torch.onnx.fx_nodeî%upsample_nearest2d : [num_users=1] = call_function[target=torch.ops.aten.upsample_nearest2d.vec](args = (%add_2613, None, [2.0, 2.0]), kwargs = {})JW
pkg.torch.onnx.name_scopes9['', 'decoder', 'decoder.blocks.0', 'upsample_nearest2d']JÏ
pkg.torch.onnx.stack_traceÕFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 25, in forward
    x = F.interpolate(x, scale_factor=2)
™
upsample_nearest2d
add_1813catnode_cat"Concat*
axis†Já
	namespacez: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.0: nn.decoder.DecoderBlock/cat: aten.cat.defaultJá
pkg.torch.onnx.class_hierarchye['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'aten.cat.default']Jù
pkg.torch.onnx.fx_nodeÇ%cat : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%upsample_nearest2d, %add_1813], 1), kwargs = {})JH
pkg.torch.onnx.name_scopes*['', 'decoder', 'decoder.blocks.0', 'cat']JÁ
pkg.torch.onnx.stack_trace»File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 27, in forward
    x = torch.cat([x, skip], dim=1)
ƒ
cat
decoder.blocks.0.conv1.0.weight
$decoder.blocks.0.conv1.0.weight_biasgetitem_231node_Conv_1549"Conv*
group†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J–
	namespace¬: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.0: nn.decoder.DecoderBlock/decoder.blocks.0.conv1: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.0.conv1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_77: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÄ
pkg.torch.onnx.class_hierarchy›['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']JÔ
pkg.torch.onnx.fx_node‘%_native_batch_norm_legit_no_training_77 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_129, %p_decoder_blocks_0_conv1_1_weight, %p_decoder_blocks_0_conv1_1_bias, %b_decoder_blocks_0_conv1_1_running_mean, %b_decoder_blocks_0_conv1_1_running_var, 0.1, 1e-05), kwargs = {})J£
pkg.torch.onnx.name_scopesÑ['', 'decoder', 'decoder.blocks.0', 'decoder.blocks.0.conv1', 'decoder.blocks.0.conv1.1', '_native_batch_norm_legit_no_training_77']JÆ
pkg.torch.onnx.stack_traceèFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 28, in forward
    x = self.conv1(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
ﬂ
getitem_231relu	node_relu"ReluJá
	namespace˘: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.0: nn.decoder.DecoderBlock/decoder.blocks.0.conv1: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.0.conv1.2: torch.nn.modules.activation.ReLU/relu: aten.relu.defaultJ⁄
pkg.torch.onnx.class_hierarchy∑['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jà
pkg.torch.onnx.fx_noden%relu : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_231,), kwargs = {})J
pkg.torch.onnx.name_scopesa['', 'decoder', 'decoder.blocks.0', 'decoder.blocks.0.conv1', 'decoder.blocks.0.conv1.2', 'relu']J≈
pkg.torch.onnx.stack_trace¶File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 28, in forward
    x = self.conv1(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 143, in forward
    return F.relu(input, inplace=self.inplace)
≈
relu
decoder.blocks.0.conv2.0.weight
$decoder.blocks.0.conv2.0.weight_biasgetitem_234node_Conv_1551"Conv*
group†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J–
	namespace¬: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.0: nn.decoder.DecoderBlock/decoder.blocks.0.conv2: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.0.conv2.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_78: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÄ
pkg.torch.onnx.class_hierarchy›['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']JÔ
pkg.torch.onnx.fx_node‘%_native_batch_norm_legit_no_training_78 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_130, %p_decoder_blocks_0_conv2_1_weight, %p_decoder_blocks_0_conv2_1_bias, %b_decoder_blocks_0_conv2_1_running_mean, %b_decoder_blocks_0_conv2_1_running_var, 0.1, 1e-05), kwargs = {})J£
pkg.torch.onnx.name_scopesÑ['', 'decoder', 'decoder.blocks.0', 'decoder.blocks.0.conv2', 'decoder.blocks.0.conv2.1', '_native_batch_norm_legit_no_training_78']JÆ
pkg.torch.onnx.stack_traceèFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 29, in forward
    x = self.conv2(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Í
getitem_234relu_1node_relu_1"ReluJâ
	namespace˚: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.0: nn.decoder.DecoderBlock/decoder.blocks.0.conv2: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.0.conv2.2: torch.nn.modules.activation.ReLU/relu_1: aten.relu.defaultJ⁄
pkg.torch.onnx.class_hierarchy∑['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jä
pkg.torch.onnx.fx_nodep%relu_1 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_234,), kwargs = {})JÅ
pkg.torch.onnx.name_scopesc['', 'decoder', 'decoder.blocks.0', 'decoder.blocks.0.conv2', 'decoder.blocks.0.conv2.2', 'relu_1']J≈
pkg.torch.onnx.stack_trace¶File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 29, in forward
    x = self.conv2(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 143, in forward
    return F.relu(input, inplace=self.inplace)
Ó

relu_1
 
val_1018upsample_nearest2d_1node_upsample_nearest2d_1"Resize*
extrapolation_value    †*&
keep_aspect_ratio_policy"stretch†*
	antialias †*
nearest_mode"floor†*
exclude_outside †*
cubic_coeff_a  @ø†*/
coordinate_transformation_mode"
asymmetric†*
mode"nearest†J§
	namespaceñ: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.1: nn.decoder.DecoderBlock/upsample_nearest2d_1: aten.upsample_nearest2d.vecJí
pkg.torch.onnx.class_hierarchyp['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'aten.upsample_nearest2d.vec']JØ
pkg.torch.onnx.fx_nodeî%upsample_nearest2d_1 : [num_users=1] = call_function[target=torch.ops.aten.upsample_nearest2d.vec](args = (%relu_1, None, [2.0, 2.0]), kwargs = {})JY
pkg.torch.onnx.name_scopes;['', 'decoder', 'decoder.blocks.1', 'upsample_nearest2d_1']JÏ
pkg.torch.onnx.stack_traceÕFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 25, in forward
    x = F.interpolate(x, scale_factor=2)
∂
upsample_nearest2d_1
add_805cat_1
node_cat_1"Concat*
axis†Jâ
	namespace|: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.1: nn.decoder.DecoderBlock/cat_1: aten.cat.defaultJá
pkg.torch.onnx.class_hierarchye['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'aten.cat.default']J†
pkg.torch.onnx.fx_nodeÖ%cat_1 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%upsample_nearest2d_1, %add_805], 1), kwargs = {})JJ
pkg.torch.onnx.name_scopes,['', 'decoder', 'decoder.blocks.1', 'cat_1']JÁ
pkg.torch.onnx.stack_trace»File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 27, in forward
    x = torch.cat([x, skip], dim=1)
∆
cat_1
decoder.blocks.1.conv1.0.weight
$decoder.blocks.1.conv1.0.weight_biasgetitem_237node_Conv_1553"Conv*
group†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J–
	namespace¬: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.1: nn.decoder.DecoderBlock/decoder.blocks.1.conv1: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.1.conv1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_79: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÄ
pkg.torch.onnx.class_hierarchy›['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']JÔ
pkg.torch.onnx.fx_node‘%_native_batch_norm_legit_no_training_79 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_131, %p_decoder_blocks_1_conv1_1_weight, %p_decoder_blocks_1_conv1_1_bias, %b_decoder_blocks_1_conv1_1_running_mean, %b_decoder_blocks_1_conv1_1_running_var, 0.1, 1e-05), kwargs = {})J£
pkg.torch.onnx.name_scopesÑ['', 'decoder', 'decoder.blocks.1', 'decoder.blocks.1.conv1', 'decoder.blocks.1.conv1.1', '_native_batch_norm_legit_no_training_79']JÆ
pkg.torch.onnx.stack_traceèFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 28, in forward
    x = self.conv1(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Í
getitem_237relu_2node_relu_2"ReluJâ
	namespace˚: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.1: nn.decoder.DecoderBlock/decoder.blocks.1.conv1: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.1.conv1.2: torch.nn.modules.activation.ReLU/relu_2: aten.relu.defaultJ⁄
pkg.torch.onnx.class_hierarchy∑['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jä
pkg.torch.onnx.fx_nodep%relu_2 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_237,), kwargs = {})JÅ
pkg.torch.onnx.name_scopesc['', 'decoder', 'decoder.blocks.1', 'decoder.blocks.1.conv1', 'decoder.blocks.1.conv1.2', 'relu_2']J≈
pkg.torch.onnx.stack_trace¶File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 28, in forward
    x = self.conv1(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 143, in forward
    return F.relu(input, inplace=self.inplace)
«
relu_2
decoder.blocks.1.conv2.0.weight
$decoder.blocks.1.conv2.0.weight_biasgetitem_240node_Conv_1555"Conv*
group†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J–
	namespace¬: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.1: nn.decoder.DecoderBlock/decoder.blocks.1.conv2: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.1.conv2.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_80: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÄ
pkg.torch.onnx.class_hierarchy›['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']JÔ
pkg.torch.onnx.fx_node‘%_native_batch_norm_legit_no_training_80 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_132, %p_decoder_blocks_1_conv2_1_weight, %p_decoder_blocks_1_conv2_1_bias, %b_decoder_blocks_1_conv2_1_running_mean, %b_decoder_blocks_1_conv2_1_running_var, 0.1, 1e-05), kwargs = {})J£
pkg.torch.onnx.name_scopesÑ['', 'decoder', 'decoder.blocks.1', 'decoder.blocks.1.conv2', 'decoder.blocks.1.conv2.1', '_native_batch_norm_legit_no_training_80']JÆ
pkg.torch.onnx.stack_traceèFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 29, in forward
    x = self.conv2(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Í
getitem_240relu_3node_relu_3"ReluJâ
	namespace˚: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.1: nn.decoder.DecoderBlock/decoder.blocks.1.conv2: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.1.conv2.2: torch.nn.modules.activation.ReLU/relu_3: aten.relu.defaultJ⁄
pkg.torch.onnx.class_hierarchy∑['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jä
pkg.torch.onnx.fx_nodep%relu_3 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_240,), kwargs = {})JÅ
pkg.torch.onnx.name_scopesc['', 'decoder', 'decoder.blocks.1', 'decoder.blocks.1.conv2', 'decoder.blocks.1.conv2.2', 'relu_3']J≈
pkg.torch.onnx.stack_trace¶File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 29, in forward
    x = self.conv2(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 143, in forward
    return F.relu(input, inplace=self.inplace)
Ó

relu_3
 
val_1018upsample_nearest2d_2node_upsample_nearest2d_2"Resize*
extrapolation_value    †*&
keep_aspect_ratio_policy"stretch†*
	antialias †*
nearest_mode"floor†*
exclude_outside †*
cubic_coeff_a  @ø†*/
coordinate_transformation_mode"
asymmetric†*
mode"nearest†J§
	namespaceñ: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.2: nn.decoder.DecoderBlock/upsample_nearest2d_2: aten.upsample_nearest2d.vecJí
pkg.torch.onnx.class_hierarchyp['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'aten.upsample_nearest2d.vec']JØ
pkg.torch.onnx.fx_nodeî%upsample_nearest2d_2 : [num_users=1] = call_function[target=torch.ops.aten.upsample_nearest2d.vec](args = (%relu_3, None, [2.0, 2.0]), kwargs = {})JY
pkg.torch.onnx.name_scopes;['', 'decoder', 'decoder.blocks.2', 'upsample_nearest2d_2']JÏ
pkg.torch.onnx.stack_traceÕFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 25, in forward
    x = F.interpolate(x, scale_factor=2)
∂
upsample_nearest2d_2
add_509cat_2
node_cat_2"Concat*
axis†Jâ
	namespace|: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.2: nn.decoder.DecoderBlock/cat_2: aten.cat.defaultJá
pkg.torch.onnx.class_hierarchye['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'aten.cat.default']J†
pkg.torch.onnx.fx_nodeÖ%cat_2 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%upsample_nearest2d_2, %add_509], 1), kwargs = {})JJ
pkg.torch.onnx.name_scopes,['', 'decoder', 'decoder.blocks.2', 'cat_2']JÁ
pkg.torch.onnx.stack_trace»File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 27, in forward
    x = torch.cat([x, skip], dim=1)
∆
cat_2
decoder.blocks.2.conv1.0.weight
$decoder.blocks.2.conv1.0.weight_biasgetitem_243node_Conv_1557"Conv*
group†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J–
	namespace¬: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.2: nn.decoder.DecoderBlock/decoder.blocks.2.conv1: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.2.conv1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_81: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÄ
pkg.torch.onnx.class_hierarchy›['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']JÔ
pkg.torch.onnx.fx_node‘%_native_batch_norm_legit_no_training_81 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_133, %p_decoder_blocks_2_conv1_1_weight, %p_decoder_blocks_2_conv1_1_bias, %b_decoder_blocks_2_conv1_1_running_mean, %b_decoder_blocks_2_conv1_1_running_var, 0.1, 1e-05), kwargs = {})J£
pkg.torch.onnx.name_scopesÑ['', 'decoder', 'decoder.blocks.2', 'decoder.blocks.2.conv1', 'decoder.blocks.2.conv1.1', '_native_batch_norm_legit_no_training_81']JÆ
pkg.torch.onnx.stack_traceèFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 28, in forward
    x = self.conv1(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Í
getitem_243relu_4node_relu_4"ReluJâ
	namespace˚: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.2: nn.decoder.DecoderBlock/decoder.blocks.2.conv1: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.2.conv1.2: torch.nn.modules.activation.ReLU/relu_4: aten.relu.defaultJ⁄
pkg.torch.onnx.class_hierarchy∑['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jä
pkg.torch.onnx.fx_nodep%relu_4 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_243,), kwargs = {})JÅ
pkg.torch.onnx.name_scopesc['', 'decoder', 'decoder.blocks.2', 'decoder.blocks.2.conv1', 'decoder.blocks.2.conv1.2', 'relu_4']J≈
pkg.torch.onnx.stack_trace¶File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 28, in forward
    x = self.conv1(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 143, in forward
    return F.relu(input, inplace=self.inplace)
«
relu_4
decoder.blocks.2.conv2.0.weight
$decoder.blocks.2.conv2.0.weight_biasgetitem_246node_Conv_1559"Conv*
group†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J–
	namespace¬: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.2: nn.decoder.DecoderBlock/decoder.blocks.2.conv2: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.2.conv2.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_82: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÄ
pkg.torch.onnx.class_hierarchy›['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']JÔ
pkg.torch.onnx.fx_node‘%_native_batch_norm_legit_no_training_82 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_134, %p_decoder_blocks_2_conv2_1_weight, %p_decoder_blocks_2_conv2_1_bias, %b_decoder_blocks_2_conv2_1_running_mean, %b_decoder_blocks_2_conv2_1_running_var, 0.1, 1e-05), kwargs = {})J£
pkg.torch.onnx.name_scopesÑ['', 'decoder', 'decoder.blocks.2', 'decoder.blocks.2.conv2', 'decoder.blocks.2.conv2.1', '_native_batch_norm_legit_no_training_82']JÆ
pkg.torch.onnx.stack_traceèFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 29, in forward
    x = self.conv2(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Í
getitem_246relu_5node_relu_5"ReluJâ
	namespace˚: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.2: nn.decoder.DecoderBlock/decoder.blocks.2.conv2: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.2.conv2.2: torch.nn.modules.activation.ReLU/relu_5: aten.relu.defaultJ⁄
pkg.torch.onnx.class_hierarchy∑['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jä
pkg.torch.onnx.fx_nodep%relu_5 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_246,), kwargs = {})JÅ
pkg.torch.onnx.name_scopesc['', 'decoder', 'decoder.blocks.2', 'decoder.blocks.2.conv2', 'decoder.blocks.2.conv2.2', 'relu_5']J≈
pkg.torch.onnx.stack_trace¶File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 29, in forward
    x = self.conv2(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 143, in forward
    return F.relu(input, inplace=self.inplace)
Ó

relu_5
 
val_1018upsample_nearest2d_3node_upsample_nearest2d_3"Resize*
extrapolation_value    †*&
keep_aspect_ratio_policy"stretch†*
	antialias †*
nearest_mode"floor†*
exclude_outside †*
cubic_coeff_a  @ø†*/
coordinate_transformation_mode"
asymmetric†*
mode"nearest†J§
	namespaceñ: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.3: nn.decoder.DecoderBlock/upsample_nearest2d_3: aten.upsample_nearest2d.vecJí
pkg.torch.onnx.class_hierarchyp['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'aten.upsample_nearest2d.vec']JØ
pkg.torch.onnx.fx_nodeî%upsample_nearest2d_3 : [num_users=1] = call_function[target=torch.ops.aten.upsample_nearest2d.vec](args = (%relu_5, None, [2.0, 2.0]), kwargs = {})JY
pkg.torch.onnx.name_scopes;['', 'decoder', 'decoder.blocks.3', 'upsample_nearest2d_3']JÏ
pkg.torch.onnx.stack_traceÕFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 25, in forward
    x = F.interpolate(x, scale_factor=2)
∞
upsample_nearest2d_3
silucat_3
node_cat_3"Concat*
axis†Jâ
	namespace|: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.3: nn.decoder.DecoderBlock/cat_3: aten.cat.defaultJá
pkg.torch.onnx.class_hierarchye['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'aten.cat.default']Jù
pkg.torch.onnx.fx_nodeÇ%cat_3 : [num_users=1] = call_function[target=torch.ops.aten.cat.default](args = ([%upsample_nearest2d_3, %silu], 1), kwargs = {})JJ
pkg.torch.onnx.name_scopes,['', 'decoder', 'decoder.blocks.3', 'cat_3']JÁ
pkg.torch.onnx.stack_trace»File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 27, in forward
    x = torch.cat([x, skip], dim=1)
∆
cat_3
decoder.blocks.3.conv1.0.weight
$decoder.blocks.3.conv1.0.weight_biasgetitem_249node_Conv_1561"Conv*
group†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J–
	namespace¬: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.3: nn.decoder.DecoderBlock/decoder.blocks.3.conv1: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.3.conv1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_83: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÄ
pkg.torch.onnx.class_hierarchy›['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']JÔ
pkg.torch.onnx.fx_node‘%_native_batch_norm_legit_no_training_83 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_135, %p_decoder_blocks_3_conv1_1_weight, %p_decoder_blocks_3_conv1_1_bias, %b_decoder_blocks_3_conv1_1_running_mean, %b_decoder_blocks_3_conv1_1_running_var, 0.1, 1e-05), kwargs = {})J£
pkg.torch.onnx.name_scopesÑ['', 'decoder', 'decoder.blocks.3', 'decoder.blocks.3.conv1', 'decoder.blocks.3.conv1.1', '_native_batch_norm_legit_no_training_83']JÆ
pkg.torch.onnx.stack_traceèFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 28, in forward
    x = self.conv1(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Í
getitem_249relu_6node_relu_6"ReluJâ
	namespace˚: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.3: nn.decoder.DecoderBlock/decoder.blocks.3.conv1: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.3.conv1.2: torch.nn.modules.activation.ReLU/relu_6: aten.relu.defaultJ⁄
pkg.torch.onnx.class_hierarchy∑['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jä
pkg.torch.onnx.fx_nodep%relu_6 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_249,), kwargs = {})JÅ
pkg.torch.onnx.name_scopesc['', 'decoder', 'decoder.blocks.3', 'decoder.blocks.3.conv1', 'decoder.blocks.3.conv1.2', 'relu_6']J≈
pkg.torch.onnx.stack_trace¶File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 28, in forward
    x = self.conv1(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 143, in forward
    return F.relu(input, inplace=self.inplace)
«
relu_6
decoder.blocks.3.conv2.0.weight
$decoder.blocks.3.conv2.0.weight_biasgetitem_252node_Conv_1563"Conv*
group†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J–
	namespace¬: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.3: nn.decoder.DecoderBlock/decoder.blocks.3.conv2: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.3.conv2.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_84: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÄ
pkg.torch.onnx.class_hierarchy›['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']JÔ
pkg.torch.onnx.fx_node‘%_native_batch_norm_legit_no_training_84 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_136, %p_decoder_blocks_3_conv2_1_weight, %p_decoder_blocks_3_conv2_1_bias, %b_decoder_blocks_3_conv2_1_running_mean, %b_decoder_blocks_3_conv2_1_running_var, 0.1, 1e-05), kwargs = {})J£
pkg.torch.onnx.name_scopesÑ['', 'decoder', 'decoder.blocks.3', 'decoder.blocks.3.conv2', 'decoder.blocks.3.conv2.1', '_native_batch_norm_legit_no_training_84']JÆ
pkg.torch.onnx.stack_traceèFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 29, in forward
    x = self.conv2(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Í
getitem_252relu_7node_relu_7"ReluJâ
	namespace˚: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.3: nn.decoder.DecoderBlock/decoder.blocks.3.conv2: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.3.conv2.2: torch.nn.modules.activation.ReLU/relu_7: aten.relu.defaultJ⁄
pkg.torch.onnx.class_hierarchy∑['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jä
pkg.torch.onnx.fx_nodep%relu_7 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_252,), kwargs = {})JÅ
pkg.torch.onnx.name_scopesc['', 'decoder', 'decoder.blocks.3', 'decoder.blocks.3.conv2', 'decoder.blocks.3.conv2.2', 'relu_7']J≈
pkg.torch.onnx.stack_trace¶File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 29, in forward
    x = self.conv2(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 143, in forward
    return F.relu(input, inplace=self.inplace)
Ó

relu_7
 
val_1018upsample_nearest2d_4node_upsample_nearest2d_4"Resize*
extrapolation_value    †*&
keep_aspect_ratio_policy"stretch†*
	antialias †*
nearest_mode"floor†*
exclude_outside †*
cubic_coeff_a  @ø†*/
coordinate_transformation_mode"
asymmetric†*
mode"nearest†J§
	namespaceñ: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.4: nn.decoder.DecoderBlock/upsample_nearest2d_4: aten.upsample_nearest2d.vecJí
pkg.torch.onnx.class_hierarchyp['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'aten.upsample_nearest2d.vec']JØ
pkg.torch.onnx.fx_nodeî%upsample_nearest2d_4 : [num_users=1] = call_function[target=torch.ops.aten.upsample_nearest2d.vec](args = (%relu_7, None, [2.0, 2.0]), kwargs = {})JY
pkg.torch.onnx.name_scopes;['', 'decoder', 'decoder.blocks.4', 'upsample_nearest2d_4']JÏ
pkg.torch.onnx.stack_traceÕFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 25, in forward
    x = F.interpolate(x, scale_factor=2)
’
upsample_nearest2d_4
decoder.blocks.4.conv1.0.weight
$decoder.blocks.4.conv1.0.weight_biasgetitem_255node_Conv_1565"Conv*
group†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J–
	namespace¬: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.4: nn.decoder.DecoderBlock/decoder.blocks.4.conv1: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.4.conv1.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_85: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÄ
pkg.torch.onnx.class_hierarchy›['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']JÔ
pkg.torch.onnx.fx_node‘%_native_batch_norm_legit_no_training_85 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_137, %p_decoder_blocks_4_conv1_1_weight, %p_decoder_blocks_4_conv1_1_bias, %b_decoder_blocks_4_conv1_1_running_mean, %b_decoder_blocks_4_conv1_1_running_var, 0.1, 1e-05), kwargs = {})J£
pkg.torch.onnx.name_scopesÑ['', 'decoder', 'decoder.blocks.4', 'decoder.blocks.4.conv1', 'decoder.blocks.4.conv1.1', '_native_batch_norm_legit_no_training_85']JÆ
pkg.torch.onnx.stack_traceèFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 28, in forward
    x = self.conv1(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Í
getitem_255relu_8node_relu_8"ReluJâ
	namespace˚: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.4: nn.decoder.DecoderBlock/decoder.blocks.4.conv1: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.4.conv1.2: torch.nn.modules.activation.ReLU/relu_8: aten.relu.defaultJ⁄
pkg.torch.onnx.class_hierarchy∑['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jä
pkg.torch.onnx.fx_nodep%relu_8 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_255,), kwargs = {})JÅ
pkg.torch.onnx.name_scopesc['', 'decoder', 'decoder.blocks.4', 'decoder.blocks.4.conv1', 'decoder.blocks.4.conv1.2', 'relu_8']J≈
pkg.torch.onnx.stack_trace¶File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 28, in forward
    x = self.conv1(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 143, in forward
    return F.relu(input, inplace=self.inplace)
«
relu_8
decoder.blocks.4.conv2.0.weight
$decoder.blocks.4.conv2.0.weight_biasgetitem_258node_Conv_1567"Conv*
group†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†J–
	namespace¬: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.4: nn.decoder.DecoderBlock/decoder.blocks.4.conv2: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.4.conv2.1: torch.nn.modules.batchnorm.BatchNorm2d/_native_batch_norm_legit_no_training_86: aten._native_batch_norm_legit_no_training.defaultJV
!pkg.onnxscript.rewriter.rule_name1FuseBatchNormIntoConv, RemoveOptionalBiasFromConvJÄ
pkg.torch.onnx.class_hierarchy›['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.batchnorm.BatchNorm2d', 'aten._native_batch_norm_legit_no_training.default']JÔ
pkg.torch.onnx.fx_node‘%_native_batch_norm_legit_no_training_86 : [num_users=1] = call_function[target=torch.ops.aten._native_batch_norm_legit_no_training.default](args = (%conv2d_138, %p_decoder_blocks_4_conv2_1_weight, %p_decoder_blocks_4_conv2_1_bias, %b_decoder_blocks_4_conv2_1_running_mean, %b_decoder_blocks_4_conv2_1_running_var, 0.1, 1e-05), kwargs = {})J£
pkg.torch.onnx.name_scopesÑ['', 'decoder', 'decoder.blocks.4', 'decoder.blocks.4.conv2', 'decoder.blocks.4.conv2.1', '_native_batch_norm_legit_no_training_86']JÆ
pkg.torch.onnx.stack_traceèFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 29, in forward
    x = self.conv2(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py", line 194, in forward
    return F.batch_norm(
Í
getitem_258relu_9node_relu_9"ReluJâ
	namespace˚: nn.model.SegmentationNet/decoder: nn.decoder.UNetDecoder/decoder.blocks.4: nn.decoder.DecoderBlock/decoder.blocks.4.conv2: torchvision.ops.misc.Conv2dNormActivation/decoder.blocks.4.conv2.2: torch.nn.modules.activation.ReLU/relu_9: aten.relu.defaultJ⁄
pkg.torch.onnx.class_hierarchy∑['nn.model.SegmentationNet', 'nn.decoder.UNetDecoder', 'nn.decoder.DecoderBlock', 'torchvision.ops.misc.Conv2dNormActivation', 'torch.nn.modules.activation.ReLU', 'aten.relu.default']Jä
pkg.torch.onnx.fx_nodep%relu_9 : [num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%getitem_258,), kwargs = {})JÅ
pkg.torch.onnx.name_scopesc['', 'decoder', 'decoder.blocks.4', 'decoder.blocks.4.conv2', 'decoder.blocks.4.conv2.2', 'relu_9']J≈
pkg.torch.onnx.stack_trace¶File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 157, in forward
    decoder_output = self.decoder(features)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 55, in forward
    x = block(x, skip)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/decoder.py", line 29, in forward
    x = self.conv2(x)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/container.py", line 253, in forward
    input = module(input)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 143, in forward
    return F.relu(input, inplace=self.inplace)
’
relu_9
segmentation_head.weight
segmentation_head.biasoutputnode_conv2d_139"Conv*
group†*
pads@@@@†*
strides@@†*
auto_pad"NOTSET†*
	dilations@@†Jw
	namespacej: nn.model.SegmentationNet/segmentation_head: torch.nn.modules.conv.Conv2d/conv2d_139: aten.conv2d.defaultJu
pkg.torch.onnx.class_hierarchyS['nn.model.SegmentationNet', 'torch.nn.modules.conv.Conv2d', 'aten.conv2d.default']J”
pkg.torch.onnx.fx_node∏%conv2d_139 : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%relu_9, %p_segmentation_head_weight, %p_segmentation_head_bias, [1, 1], [1, 1]), kwargs = {})JE
pkg.torch.onnx.name_scopes'['', 'segmentation_head', 'conv2d_139']Jé
pkg.torch.onnx.stack_traceÔFile "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/train-ego-path-detection/src/nn/model.py", line 158, in forward
    masks = self.segmentation_head(decoder_output)
  File "/Users/jeffreyiyamah/Desktop/axis-robotics-v0/axis-env/lib/python3.13/site-packages/torch/nn/modules/conv.py", line 553, in forward
    return self._conv_forward(input, self.weight, self.bias)
main_graph*}(B#encoder.stages.1.0.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset35264j
length1440p*
(B%encoder.stages.1.0.block.1.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset39776j
length1600p*S
B#encoder.stages.1.0.block.1.fc1.biasJ(sΩî>q2ìø¬È¡øŸ)´øKòøOÄ´øÒÑ>ÈÍ·æî∑èøƒ√pø*(
B%encoder.stages.1.0.block.1.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset41376j
length1600p*Ã(B#encoder.stages.1.0.block.1.fc2.biasJ†ìFÕ>m0»ΩJìø§ÅåæL}â@•Z∑?Àâ_@Ë§s?7¨r?üw{@úöl@ı>ó@Û5¡>,Çâ@ùzT>ß4>@∏V€<Ä5@ÊÜåø–ùøŒL∂?êbø˛FX@v2ø/b¢?Tü0?∞¡?›=§øVH@Tﬁ´?áIæzŸ?∂|}@‹õø¸Ñ@Ù??ßB?œnø±Hø;¢`@*~(B#encoder.stages.1.0.block.2.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset135712j
length3840p*|B#encoder.stages.1.1.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset16416j
length864p*}B%encoder.stages.1.1.block.1.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset6048j
length576p*CB#encoder.stages.1.1.block.1.fc1.biasJËŒé>√
¿<¢?{Û:æAä?2÷7ø*}B%encoder.stages.1.1.block.1.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset6624j
length576p*ãB#encoder.stages.1.1.block.1.fc2.biasJ`8ÖU¿1§c¿–\¿£c¿:NÂø:ZÕø‘∫`¿ÁNT¿≤~\¿ó´≥øâ^¿ÏôX¿%EÒø∫¿º@¿†0P¿0ÊøãzuøghÃøıp>¿Q£Lø¯^ö¿â\¿¿oK¿*}B#encoder.stages.1.1.block.2.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset42976j
length2304p*ÅêB%encoder.stages.2.0.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset128800j
length3456p*CB#encoder.stages.2.0.block.2.fc1.biasJoÄ?∆∫;?d%ºõ≤>ˇˆn?-2P?*ÅêB%encoder.stages.2.0.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset132256j
length3456p*vêB#encoder.stages.2.0.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset7200j
length576p*KB#encoder.stages.2.1.block.2.fc1.biasJ @Å*?>/≥?É¡T>`ßFæïk?Wf;?ù˝&?‡ÜC@*v¿B#encoder.stages.2.1.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset9504j
length768p*KB#encoder.stages.2.2.block.2.fc1.biasJ 7/ö?›w@'yÁ?Ω¨ü?÷‹®?TÍ…?4»?·Ç¨?*w¿B#encoder.stages.2.2.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset10272j
length768p*KB#encoder.stages.3.0.block.2.fc1.biasJ àÂæ»cDøY‘ø¬+:øfxøíøqÂÅ>‘Ò˛æ*w¿B#encoder.stages.3.0.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset11040j
length768p*[B#encoder.stages.3.1.block.2.fc1.biasJ0¸ë†?Ö>å?nóã?ù¢?Û¡?aêæ•∏S?’Y4@,LQ?¸Œ?ãıã?W1æ*x†B#encoder.stages.3.1.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset24896j
length1152p*[B#encoder.stages.3.2.block.2.fc1.biasJ0è0å?%L?ƒ¨Ñ?≥"K?gw—?à÷q?≤óÛ>ã´?çüç?\VÜ?
õ?ÙÒñ?*x†B#encoder.stages.3.2.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset26048j
length1152p*[B#encoder.stages.4.0.block.2.fc1.biasJ0HÊ
ø)™ﬁæ$ÕæÒ”ææêj<Æ›øS‘´æøm©æò®æ|Ÿ‰æŒæÅæø*x†B#encoder.stages.4.0.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset27200j
length1152p*ãB#encoder.stages.4.1.block.2.fc1.biasJ`ÙŒ≠?Û+C?ˆõ?OÆã?«Fæ?˘k{>	9Z?û[à>∫ö?ß	>∫iõæo`o?ù∫?= >}∆s?ó√=Qπp?·R0>7‹)?W˚.@√£¶?†»>Õyì?5Ç?*x¿B#encoder.stages.4.1.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset45280j
length2304p*ãB#encoder.stages.4.2.block.2.fc1.biasJ`”é?,ﬁ?€ò‘>hZo?Æ2t?7‰?)«D=‹π?ŸdÄ?ﬂ@q.‘?ZEh?´ﬂ“?.Är?g7?e_˙>·n%@‹Ñw?÷π?¨øKÇ?ª‘>ÈwV?’çª?*x¿B#encoder.stages.4.2.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset47584j
length2304p*ãB#encoder.stages.4.3.block.2.fc1.biasJ`aì≤?€ŒÚ?◊–“=	Œ?‰QC?*Ï9>4øtQ_ΩO»©>«©Ì>◊o?kŸ>^È?Ã˜ >~bÒ>Özß>Ëı$?õJ?Ó>jAY?%¥?óR∫?⁄{ ?‡?*x¿B#encoder.stages.4.3.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset49888j
length2304p*ãB#encoder.stages.4.4.block.2.fc1.biasJ`]ÎÌ?µË>¯@e?|„¡?á‡À>£Uøt«,>Ëø?∆
@E	Ö>H?’S≥?¯œ?v˙Ë?LQøö(\?…Ñ¥?8òó?ˆ“ ºïRCΩ!¬Æ>ÒÛî?‹ª{?7üñ>*x¿B#encoder.stages.4.4.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset52192j
length2304p*ãB#encoder.stages.5.0.block.2.fc1.biasJ`´W±æ≠€®øµ^gø†âDø{té?^˚,øµo=ˇåz>åä?CäøövŸ?<X?¨ØæﬁË´;Úë?◊¶=H?D∆≈>9ıKøù2øIE{ø›í™æ¨Qæzx?*x¿B#encoder.stages.5.0.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset54496j
length2304p*¥"B#encoder.stages.5.1.block.2.fc1.biasJàc„a?l§;?può?ß∏«?R`÷=,ﬁ?ÕòÄ?ç«>bÚì>aU?Ì=d¡>ZßÜ>_ƒå?ÁñL?àÔîæ[KR?KKæ‹⁄B?ú?_^?µÁ|?a9?Ï„D<Dµ?µæ_ ˛>Èú>∞ÎÅ?4¡>≈°û?ÛY)?≈Äê?¢#‘?*x∞B#encoder.stages.5.1.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset79840j
length3264p*¥"B#encoder.stages.5.2.block.2.fc1.biasJàïvÜ?RL?':?ÿ·8?>˝≠?©?>óZ?6ºP? „)?”˘?ÄÕö?wgc?‡eÊ>øS>Ä±á?–\2?Çõ?Ù÷Ä?§ ?K_Ê>éXª>{K?9X|?Sò≤?Õ…ù?7¸w?¡ P?€‡Ç?,«:?@Q?UZ=?Â¨æ*x∞B#encoder.stages.5.2.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset83104j
length3264p*¥"B#encoder.stages.5.3.block.2.fc1.biasJàEî⁄>‹[ƒ<òö_?é6∏>©ùv>Å«Æ?A©??`ﬂ7?fï•?÷Ã¯>mRæt¨¥?{;ƒæ†	”>zm?˙G?ì#?§zë?Ÿ‰ﬁ>˙®º>aÿ>¶–4?=>2·B>‚[˙ª˙Ûxø¿"â>¯”
?∑É7?ƒ4?W∆ª>–îq?oó??ÔÇ?*x∞B#encoder.stages.5.3.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset86368j
length3264p*¥"B#encoder.stages.5.4.block.2.fc1.biasJà°Ó>(å?]©3?ÀH≈>„6W?∞#?AA>¥~á?1’>dÅ?Ê¸->nV?_í"?2&-?ø}?`?O;å?øÌ·>ı}5?	'?ªÖó?C)ø‘!†??õw>200?XçÖ=lsó>cÎÇ>∏E!@Â§>ÒŒö?ykéæùñ?!{?*x∞B#encoder.stages.5.4.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset89632j
length3264p*¥"B#encoder.stages.6.0.block.2.fc1.biasJà"p4øÀH„æcÔøeWÖº!?ëpLø∏ÁS>òâäø"»¿…Éø¸·–æZ˚ÄøÂÄøB_ø#∂Åø=ê`ø≈3ø©óÄø¬6œæ?ìæ_åø‹:?;π,ø€Ç≠ø“ZBøÏ^âøiòÑøtqIøÙÇÈ>± %ø6ÉøZ)öøŸ?üæ¨°çø*x∞B#encoder.stages.6.0.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset92896j
length3264p*î:B#encoder.stages.6.1.block.2.fc1.biasJËÑ	wΩÔ“>=hÑú<¢zÆæØÅÉ>J?>‰æø Ù?ÇäúΩx–Œæ_¶l<OΩæÂ.èΩ´—êæ€5˛æ˜”•æ8°(ΩrGj?ìïü=∏P->7µÏºîæ∂ªI?Y+
>‰ òæ´Ìø†,>q∫ß>ÀΩ“l>cëVæ∆ä;º20WæHô¯=Çºr?dñﬁº·ræº¨Ωîï>TøÚÓ†>˜´Ω≠Ë?
à™>’]˛=ÅTÄ?ΩX	p>£Ûbæ_¨ =§ƒ”æÏﬂæ!‡Fæ¯d»º1ƒ=æW…¯>(%ï>EVúæ*î:B#encoder.stages.6.2.block.2.fc1.biasJËπ¶G>‘¿ßΩP2∞>µe°æ√ÂïºtìΩª®∆>Ú⁄Ω–T?lû?6S?  Ωµ∞^æ>v:æ˘ﬂ’=ñú?>≠=ø+›Ò>ùoæëˇäæ@#ç<{$?13æ•∂*?âO=),˛>Xìø?i˝æ!„>ãùß=˚ƒ>÷‰∆>6¬êæ=∞Ã>◊ ⁄ºÀõ£<CK∆æ‰s ?	C˛Ω-≥±>ñÔ¶Ω«…=æÏΩ>Ó¯l>[>O{™<_ÊΩz∑°?£<?tu?1I7æ ^>ƒÚ´=mÎR>9|ç>tª;˛ì†>ÓE•º*î:B#encoder.stages.6.3.block.2.fc1.biasJËH≈7æƒ#™æÏ1|=D÷«>∂">…§à>◊v5æ1ª<>›øﬂ√Ωæﬁ?Ã>◊˛à>∆2æœhÑ>ﬁIæk∏#æf-W>|“H?5ÿá?—€¿ΩÜøQDf?ÉÑ=W®É>Ú]æ>~Çâ>1ıÈæE’ëΩPÄ>˚Í=~&f=¯ŸæMΩI>ñïC>ù`"?≠»cø\>4`>˝
Ô>Œa√>u`>÷œΩ7ëΩ{ ›=ú_æ‰õø!I“>⁄"ΩæM!>∞zg>ˆ±º/·>ŒÙµ>‰>¨\> 2?2Ìí?⁄™N=*î:B#encoder.stages.6.4.block.2.fc1.biasJË]©>¸ñΩ†DÕ=ÏÃΩ=É◊æ0(°Ω^i>?Æãø˘rB>	3?6rh?%ÓÚ</Â>Ø{>ùi;?ˇêñ>qëqøË»Ÿ>Z¯>˙~V?∑¸∞=≤ì”æbï®=V±ÈΩ^ \?O>æ≠ÇÖ=ﬂ˝Aætî=ú øÜÀ÷>ƒ„íæô⁄πæ"ê2>[ìæXÃu<©?_—ì?«™>≈ﬁZª¨
øı£±?=Êæ†
–=∞~æN}†?‰Õ>Tó`?Ê˛7='tæçÙæ5t>‰p??„p>êí>VE<?‚jµ<*î:B#encoder.stages.6.5.block.2.fc1.biasJËÆ›&Ω√µTæc`¥?õ?∞>Zkº>|@æÈrÏæ‹¬?9€¯>#œΩ[ÕﬂΩ˘Q^>v[¶æÀ∑£>mÏÅ<FYKæs›¢æÓí:>.Í<r¥î>BNÏ>â‹æœêΩíπ.?œ≥=^`>gË.ø*Ö0ø≤¨§øˆñ>∏ßªÑÚΩËAA?–:æd{ù>ìkæ	¥Ω#i=ø!øﬂV"?®ÂÉ=“bù>4˘yº 3;Ω«≠?bŸD?À∆ÉæÒ'¯;O®∑=qTæ£
ßΩO?ÏÂmæ&OMΩÎÉäæ›t>wX„æŒ<?*î:B#encoder.stages.7.0.block.2.fc1.biasJË¿~D(øömá?Î}Eø!_zæ%>ïø=©ø6£øâﬂ≠Ωjyæ∏o˝ø\X•økPøIiø≤÷_øeÆ?+õ≥ø“èiø£˙°øÁäæøTæôAΩ¶Ïæö*ø¡™ÌæŸ“æL7<z+ø›-Õø%•æÍ&‚æÿ§ø?ã@M	K=-{3øƒo	ømnbø÷‹øo˛ÄøÙhwø$Óôø¥™Øø∑6øÑŸ6ø>íàøÓbjæ ãHø…dç>(,7øìNWΩIπΩø»8UøÔKµø≤ØÈø∫ÂÌ>∞R°Ω&-›ø±·Wø*r`B#encoder.stages.7.1.block.2.fc1.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset0j
length384p*pBsegmentation_head.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset7776j
length576p*"Bsegmentation_head.biasJŒÉæ*t(Bencoder.stages.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset139552j
length4320p*ÄêB#encoder.stages.2.0.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset347200j
length13824p*êB#encoder.stages.2.0.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset143872j
length5184p*Ä êB#encoder.stages.2.0.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset443968j
length18432p*Ä¿ B#encoder.stages.2.1.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset582976j
length24576p*¿B#encoder.stages.2.1.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset286144j
length6912p*Å¿B%encoder.stages.2.1.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset249280j
length6144p*Å¿B%encoder.stages.2.1.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset255424j
length6144p*Ä ¿B#encoder.stages.2.1.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset607552j
length24576p*Ä¿ B#encoder.stages.2.2.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset632128j
length24576p*¿B#encoder.stages.2.2.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset293056j
length6912p*Å¿B%encoder.stages.2.2.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset261568j
length6144p*Å¿B%encoder.stages.2.2.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset267712j
length6144p*Ä ¿B#encoder.stages.2.2.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset656704j
length24576p*Ä¿ B#encoder.stages.3.0.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset681280j
length24576p*Ä¿B#encoder.stages.3.0.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset480832j
length19200p*Å¿B%encoder.stages.3.0.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset273856j
length6144p*Å¿B%encoder.stages.3.0.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset280000j
length6144p*Ä0¿B#encoder.stages.3.0.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset763456j
length36864p*Ä†0B#encoder.stages.3.1.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset887296j
length55296p*Ä†B#encoder.stages.3.1.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset705856j
length28800p*Ç†B%encoder.stages.3.1.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset361024j
length13824p*Ç†B%encoder.stages.3.1.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset374848j
length13824p*Ä0†B#encoder.stages.3.1.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset942592j
length55296p*Ä†0B#encoder.stages.3.2.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset997888j
length55296p*Ä†B#encoder.stages.3.2.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset734656j
length28800p*Ç†B%encoder.stages.3.2.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset388672j
length13824p*Ç†B%encoder.stages.3.2.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset402496j
length13824p*Å0†B#encoder.stages.3.2.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset1053184j
length55296p*Å†0B#encoder.stages.4.0.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset1108480j
length55296p*Ä†B#encoder.stages.4.0.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset336832j
length10368p*Ç†B%encoder.stages.4.0.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset416320j
length13824p*Ç†B%encoder.stages.4.0.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset430144j
length13824p*Ç`†B#encoder.stages.4.0.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset2265280j
length110592p*Ç¿`B#encoder.stages.4.1.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset4448896j
length221184p*Ä¿B#encoder.stages.4.1.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset500032j
length20736p*É¿B%encoder.stages.4.1.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset1163776j
length55296p*É¿B%encoder.stages.4.1.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset1219072j
length55296p*Ç`¿B#encoder.stages.4.1.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset4670080j
length221184p*Ç¿`B#encoder.stages.4.2.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset4891264j
length221184p*Ä¿B#encoder.stages.4.2.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset520768j
length20736p*É¿B%encoder.stages.4.2.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset1274368j
length55296p*É¿B%encoder.stages.4.2.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset1329664j
length55296p*Ç`¿B#encoder.stages.4.2.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset5112448j
length221184p*Ç¿`B#encoder.stages.4.3.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset5333632j
length221184p*Ä¿B#encoder.stages.4.3.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset541504j
length20736p*É¿B%encoder.stages.4.3.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset1384960j
length55296p*É¿B%encoder.stages.4.3.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset1440256j
length55296p*Ç`¿B#encoder.stages.4.3.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset5554816j
length221184p*Ç¿`B#encoder.stages.4.4.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset5776000j
length221184p*Ä¿B#encoder.stages.4.4.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset562240j
length20736p*É¿B%encoder.stages.4.4.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset1495552j
length55296p*É¿B%encoder.stages.4.4.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset1550848j
length55296p*Ç`¿B#encoder.stages.4.4.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset5997184j
length221184p*Ç¿`B#encoder.stages.5.0.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset6218368j
length221184p*Å¿B#encoder.stages.5.0.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset1716736j
length57600p*É¿B%encoder.stages.5.0.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset1606144j
length55296p*É¿B%encoder.stages.5.0.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset1661440j
length55296p*Éà¿B#encoder.stages.5.0.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset6439552j
length313344p*Ñ∞àB#encoder.stages.5.1.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset10996864j
length443904p*Å∞B#encoder.stages.5.1.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset1774336j
length81600p*Ñ"∞B%encoder.stages.5.1.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset2375872j
length110976p*Ñ∞"B%encoder.stages.5.1.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset2486848j
length110976p*Ñà∞B#encoder.stages.5.1.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset11440768j
length443904p*Ñ∞àB#encoder.stages.5.2.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset11884672j
length443904p*Å∞B#encoder.stages.5.2.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset1855936j
length81600p*Ñ"∞B%encoder.stages.5.2.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset2597824j
length110976p*Ñ∞"B%encoder.stages.5.2.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset2708800j
length110976p*Ñà∞B#encoder.stages.5.2.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset12328576j
length443904p*Ñ∞àB#encoder.stages.5.3.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset12772480j
length443904p*Å∞B#encoder.stages.5.3.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset1937536j
length81600p*Ñ"∞B%encoder.stages.5.3.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset2819776j
length110976p*Ñ∞"B%encoder.stages.5.3.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset2930752j
length110976p*Ñà∞B#encoder.stages.5.3.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset13216384j
length443904p*Ñ∞àB#encoder.stages.5.4.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset13660288j
length443904p*Å∞B#encoder.stages.5.4.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset2019136j
length81600p*Ñ"∞B%encoder.stages.5.4.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset3041728j
length110976p*Ñ∞"B%encoder.stages.5.4.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset3152704j
length110976p*Ñà∞B#encoder.stages.5.4.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset14104192j
length443904p*Ñ∞àB#encoder.stages.6.0.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset14548096j
length443904p*Å∞B#encoder.stages.6.0.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset2100736j
length81600p*Ñ"∞B%encoder.stages.6.0.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset3263680j
length110976p*Ñ∞"B%encoder.stages.6.0.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset3374656j
length110976p*ÑË∞B#encoder.stages.6.0.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset15581824j
length757248p*Ö
ËB#encoder.stages.6.1.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset18153472j
length1291776p*Ç
B#encoder.stages.6.1.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset3605440j
length139200p*Ñ:
B%encoder.stages.6.1.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset6752896j
length322944p*Ñ
:B%encoder.stages.6.1.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset7075840j
length322944p*y
B#encoder.stages.6.1.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset149056j
length5568p*ÖË
B#encoder.stages.6.1.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset19464192j
length1291776p*Ö
ËB#encoder.stages.6.2.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset20774912j
length1291776p*Ç
B#encoder.stages.6.2.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset3744640j
length139200p*Ñ:
B%encoder.stages.6.2.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset7398784j
length322944p*Ñ
:B%encoder.stages.6.2.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset7721728j
length322944p*y
B#encoder.stages.6.2.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset154624j
length5568p*ÖË
B#encoder.stages.6.2.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset22085632j
length1291776p*Ö
ËB#encoder.stages.6.3.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset23396352j
length1291776p*Ç
B#encoder.stages.6.3.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset3883840j
length139200p*Ñ:
B%encoder.stages.6.3.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset8044672j
length322944p*Ñ
:B%encoder.stages.6.3.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset8367616j
length322944p*y
B#encoder.stages.6.3.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset160192j
length5568p*ÖË
B#encoder.stages.6.3.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset24707072j
length1291776p*Ö
ËB#encoder.stages.6.4.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset26017792j
length1291776p*Ç
B#encoder.stages.6.4.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset4023040j
length139200p*Ñ:
B%encoder.stages.6.4.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset8690560j
length322944p*Ñ
:B%encoder.stages.6.4.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset9013504j
length322944p*y
B#encoder.stages.6.4.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset165760j
length5568p*ÖË
B#encoder.stages.6.4.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset27328512j
length1291776p*Ö
ËB#encoder.stages.6.5.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset28639232j
length1291776p*Ç
B#encoder.stages.6.5.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset4162240j
length139200p*Ñ:
B%encoder.stages.6.5.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset9336448j
length322944p*Ñ
:B%encoder.stages.6.5.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset9659392j
length322944p*y
B#encoder.stages.6.5.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset171328j
length5568p*ÖË
B#encoder.stages.6.5.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset29949952j
length1291776p*Ö
ËB#encoder.stages.7.0.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset31260672j
length1291776p*Ä
B#encoder.stages.7.0.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset837184j
length50112p*Ñ:
B%encoder.stages.7.0.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset9982336j
length322944p*Ö
:B%encoder.stages.7.0.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset10305280j
length322944p*y
B#encoder.stages.7.0.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset176896j
length5568p*ÖÄ
B#encoder.stages.7.0.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset34013184j
length2138112p*ÖÄÄB#encoder.stages.7.1.block.0.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset38535168j
length3538944p*ÅÄB#encoder.stages.7.1.block.1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset2182336j
length82944p*Ö`ÄB%encoder.stages.7.1.block.2.fc1.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset16339072j
length884736p*ÖÄ`B%encoder.stages.7.1.block.2.fc2.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset17223808j
length884736p*yÄB#encoder.stages.7.1.block.2.fc2.biasj)
locationtwinkling-rocket-21.onnx.dataj
offset299968j
length9216p*ÖÄÄB#encoder.stages.7.1.block.3.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset42074112j
length3538944p*ÅÄàBdecoder.blocks.0.conv1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset45613056j
length4792320p*ÅÄÄBdecoder.blocks.0.conv2.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset36175872j
length2359296p*ÅÄ∞Bdecoder.blocks.1.conv1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset32571392j
length1400832p*ÄÄÄBdecoder.blocks.1.conv2.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset14992000j
length589824p*@†Bdecoder.blocks.2.conv1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset10628224j
length368640p*}@@Bdecoder.blocks.2.conv2.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset4301440j
length147456p*} hBdecoder.blocks.3.conv1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset3485632j
length119808p*{  Bdecoder.blocks.3.conv2.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset800320j
length36864p*{ Bdecoder.blocks.4.conv1.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset462400j
length18432p*zBdecoder.blocks.4.conv2.0.weightj)
locationtwinkling-rocket-21.onnx.dataj
offset309184j
length9216p*Bval_67Jˇˇˇˇˇˇˇˇ˛ˇˇˇˇˇˇˇ*«(Bencoder.stages.0.0.weight_biasJ†ÖÚ,@)§?˜
@»@Ã!=@4’@˘(˜¿#ñÜA`œΩ@B‰pATõ?'Öµ?ê]Z?ﬂ…@ÿñe¿s|Ó?ÊñÜøHÃ7¿µ/?¯êZ@Æe¡Ã£*>ˆ_R?d@$l∂¿àiK?Äõ><¸?wß @pæ?( ú?÷¡HK@Lcº•4'@NquAí95@πn„?JWA?0S@*—(B(encoder.stages.1.0.block.0.0.weight_biasJ†#.êΩy@é@†ˆæÛ2˛?C.€?˛ÁÜøOC@N(E¿∂!—?kR¡Rç≤@ë3•?a	M@«@`Dæ®BΩA98@ ú◊Ω8fø\ªùæ´Ä@9ë+@(Ñ∏æƒP≥>E∆@!ø<0Êæ∂ﬁâ@ôÍi@Ïó@µ@@€¿?’˜@ãô@ ôÖæPœ?å~4?Pgﬁ?Ì°@*êB(encoder.stages.1.0.block.2.0.weight_biasJ`∏ø»@sÚ–Ωpvƒ@M‡µ@ËÏ–¡éã%B(->àæ›>Ö®ø2” ¬M≈@ò˙o¿®Î¿‰0¡À·¢@?˛±@Á3	¡âflAEuAT∫k@é˜A≈4”¿Ö
’@Jè\@*êB(encoder.stages.1.1.block.0.0.weight_biasJ`ò†æºµï¿ù(?§òV?¡B¿V–*@ i/ø˜Q&?0Äæ1›Q@÷4∂?u<nø]@ñ`@)È5?…`?±W˝?˙Ä≈?@>q∂¿xõ#¿‚9˜¿Pﬁ8æ¯‹Eø*êB(encoder.stages.1.1.block.2.0.weight_biasJ`±Eç¿›x¯¿+ìÖA|a?"ÛåA$Ì¡ã%Æ@0\?R´øa©AK‡ÆAÄüæQã
¡5∂ö¿<©¡z†¿-V@B{@@I0¡#óÏ¿¡ w¡¿üõ¿Ka¬@zâ¡*{êB(encoder.stages.2.0.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset8352j
length576p*{êB(encoder.stages.2.0.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset8928j
length576p*± B(encoder.stages.2.0.block.3.0.weight_biasJÄßnñ¡âFøÓ':¡—dñ¿SÈ-AÇfAcn¿P¸@„wÚ@¥ÕB¡Dù¿¨wï¿Ç¯¿¥J™? ïË¿ﬂ@ûæÇ˚æé;ó@ıáæ¿<Óå@—oAƒ+G@eÆA1??qµ‘@©ñ>A∫®)A˜åK@µ„¿ ,ï¡h¶¿W	@*|¿B(encoder.stages.2.1.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset11808j
length768p*|¿B(encoder.stages.2.1.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset12576j
length768p*± B(encoder.stages.2.1.block.3.0.weight_biasJÄ™ìlAT6∂@›¶@ØÑÒøG·°¿˛6·?Ï^ÇAz%Ÿøß¢n¿8.@Ó>˘pÖ¿1€?√•˙?o"<@2G∑AÀ í¿ø)Œ¿ò@˘§◊@@¥◊=Í·ª¿"p¿@ø∏ÊÈ¿ ‘c?’	RAÄDΩp‹øúv@K≈ï¿oe¿*|¿B(encoder.stages.2.2.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset13344j
length768p*|¿B(encoder.stages.2.2.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset14112j
length768p*± B(encoder.stages.2.2.block.3.0.weight_biasJÄF6∂¿\Ú˜?/∂¿êF–¿AÊ‘?7Œ¿∞9¯øæ¿zsï?`Q`?jöx@!…ΩØ¥æÆ∏∫æ+à@íöV¡åÜ(¿&à]@Mæ÷?ı†∂@vÂ•øE—¿¿d Aπ}õø‡H*?º zæ:¡Mﬁ≠@nˇ–ø¢†@¿ø7Öî¿*|¿B(encoder.stages.3.0.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset14880j
length768p*|¿B(encoder.stages.3.0.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset15648j
length768p*Ò0B(encoder.stages.3.0.block.3.0.weight_biasJ¿™‚œ¿Íå•¿ ‹AY8ÅA®#Ü¿bÓ¬î›¿Çw∑AHŒˇ¿°M:A—4A¥§oA∫NÛA¢ò£¡∆≠A¿≤d¡D`ÒA.Ù @‡i?l®f¡»Ö@ÿ’∞¡…éÈA‹„…@â}AF;ÏAPf¡*.}¡91„@d™8@dÚ¥¿(è¡ÙHAÇMT@¬â%A?;¡¿ß%WA}õˆ¿Ò`Al\(¡˝U%Bî@ª®Aö¸˛¡=î-¡Á_&¡!É˝¡*}†B(encoder.stages.3.1.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset28352j
length1152p*}†B(encoder.stages.3.1.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset29504j
length1152p*Ò0B(encoder.stages.3.1.block.3.0.weight_biasJ¿(Ü‘ø¿—ΩôF@p´Î@ÙB°æs1ˆ?‹mgø
¡úæ¨≠¸>Ω8åø$øøz-@ÙüMæÉE¢?¨‰b¿‡Ì¿ö+ù?O˚«æª;@\Hr?/≤øØO¡◊Ÿ_@X»ö?øN*¿ê%/¿w!Ω?ˆ5¿Ï'B¿Wı•?sE@µ@Xø<¿Œ≈C@¢¢?@Úeù@¢7øˇ?à›¿∂°@ˆY”?ÃUÊ?yˆ@ÁÔ0?Tˇ ¿äÕ¨ø<‡Å?ÈΩ>@*}†B(encoder.stages.3.2.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset30656j
length1152p*}†B(encoder.stages.3.2.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset31808j
length1152p*Ò0B(encoder.stages.3.2.block.3.0.weight_biasJ¿}#Jæd≤H¿Ë˜/>Ü¥@Æ‘ø4Ñ?…®â>‡bƒ?NàÄ?®Û∂>rnÿøXN‡?˜F˚øﬂj
?5Y¿ûr?C= ?÷:@RøøçC@~Óæ“#¡j©˚?@=ùO¿-Ìiø¸”?$æ“ÁV@~sr?Ï!.?›@XUÄøURï@(böæ0?–-ΩÅ(µø%¿ÿ¿v@FùO?FH@Iˇ8?∆Ú?
ª?/íø)@|¿t…˚?*}†B(encoder.stages.4.0.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset32960j
length1152p*}†B(encoder.stages.4.0.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset34112j
length1152p*y`B(encoder.stages.4.0.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset384j
length384p*}¿B(encoder.stages.4.1.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset56800j
length2304p*}¿B(encoder.stages.4.1.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset59104j
length2304p*y`B(encoder.stages.4.1.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset768j
length384p*}¿B(encoder.stages.4.2.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset61408j
length2304p*}¿B(encoder.stages.4.2.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset63712j
length2304p*z`B(encoder.stages.4.2.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset1152j
length384p*}¿B(encoder.stages.4.3.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset66016j
length2304p*}¿B(encoder.stages.4.3.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset68320j
length2304p*z`B(encoder.stages.4.3.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset1536j
length384p*}¿B(encoder.stages.4.4.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset70624j
length2304p*}¿B(encoder.stages.4.4.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset72928j
length2304p*z`B(encoder.stages.4.4.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset1920j
length384p*}¿B(encoder.stages.5.0.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset75232j
length2304p*}¿B(encoder.stages.5.0.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset77536j
length2304p*{àB(encoder.stages.5.0.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset3328j
length544p*}∞B(encoder.stages.5.1.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset96160j
length3264p*}∞B(encoder.stages.5.1.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset99424j
length3264p*{àB(encoder.stages.5.1.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset3872j
length544p*~∞B(encoder.stages.5.2.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset102688j
length3264p*~∞B(encoder.stages.5.2.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset105952j
length3264p*{àB(encoder.stages.5.2.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset4416j
length544p*~∞B(encoder.stages.5.3.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset109216j
length3264p*~∞B(encoder.stages.5.3.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset112480j
length3264p*{àB(encoder.stages.5.3.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset4960j
length544p*~∞B(encoder.stages.5.4.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset115744j
length3264p*~∞B(encoder.stages.5.4.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset119008j
length3264p*{àB(encoder.stages.5.4.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset5504j
length544p*~∞B(encoder.stages.6.0.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset122272j
length3264p*~∞B(encoder.stages.6.0.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset125536j
length3264p*|ËB(encoder.stages.6.0.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset17280j
length928p*~
B(encoder.stages.6.1.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset182464j
length5568p*~
B(encoder.stages.6.1.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset188032j
length5568p*|ËB(encoder.stages.6.1.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset18208j
length928p*~
B(encoder.stages.6.2.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset193600j
length5568p*~
B(encoder.stages.6.2.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset199168j
length5568p*|ËB(encoder.stages.6.2.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset19136j
length928p*~
B(encoder.stages.6.3.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset204736j
length5568p*~
B(encoder.stages.6.3.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset210304j
length5568p*|ËB(encoder.stages.6.3.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset20064j
length928p*~
B(encoder.stages.6.4.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset215872j
length5568p*~
B(encoder.stages.6.4.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset221440j
length5568p*|ËB(encoder.stages.6.4.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset20992j
length928p*~
B(encoder.stages.6.5.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset227008j
length5568p*~
B(encoder.stages.6.5.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset232576j
length5568p*|ËB(encoder.stages.6.5.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset21920j
length928p*~
B(encoder.stages.7.0.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset238144j
length5568p*~
B(encoder.stages.7.0.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset243712j
length5568p*}ÄB(encoder.stages.7.0.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset36704j
length1536p*~ÄB(encoder.stages.7.1.block.0.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset318400j
length9216p*~ÄB(encoder.stages.7.1.block.1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset327616j
length9216p*}ÄB(encoder.stages.7.1.block.3.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset38240j
length1536p*yÄB$decoder.blocks.0.conv1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset22848j
length1024p*yÄB$decoder.blocks.0.conv2.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset23872j
length1024p*wÄB$decoder.blocks.1.conv1.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset2304j
length512p*wÄB$decoder.blocks.1.conv2.0.weight_biasj)
locationtwinkling-rocket-21.onnx.dataj
offset2816j
length512p*≠@B$decoder.blocks.2.conv1.0.weight_biasJÄ82ÌæÎµ,?î¡=˙LΩ<¡)? è˚>ˆØñ>~π|=9√≤>H\÷=Ü„:>ï:ñø(O≥ΩºænæKR·Ω¥bIæ,%~æw{?>øcRâ?öNö>ïçøsyåæJdøÿ ?¿j√=RMg>˘a(>5Næ ó>-aæ—˙ç>}ñæä‘:>Ä7≈<|NÖæ≤I>K∫=ıÅf?"x)øKÕü>óB⁄>‘z”==>P≠ù=∂7n?y≥¥æp/∫;S>^˚º>bâ	Ω@X/<Ù≤†?=™~Ω}~Ωr‰?€ˆYø¸§??∏z?≥xæi)=>(H¡=ƒ√>‹;ª>*≠@B$decoder.blocks.2.conv2.0.weight_biasJÄ†u>ß–Ω†jZ?,B∆æ>…´Ω˚≈ü?÷”´>E^gæ§ı‡=y–
>ê%"?ºÍ∆øù?ºbaœ>Œ¶æΩ´1?ôED>óyá?[ ü?ÒÕ∏<><>q8µæò\£øøiøé¸>,¿…eÖ?bΩΩZâ>fZ>-C>ø≈Åæ–É>eDºN/√>¥[>|¿∏æ…W°>@ø'f+?8ÙìøÀ{˘>QÆøﬁr∂æcêìΩ[ù?Ó%/ø•wæ≤?∏ÉΩ ˚öª¶Í2=ÊM`=p">d+
æåõq>@‹‘=D æ>RÑ>R
>–ÇVøq–;>ŸETøEÉù?*≠ B$decoder.blocks.3.conv1.0.weight_biasJÄ˘í@—3@õQ¶?Ê”¯>uUæıj@8_W>ı‰∫?ó”>s‘æS‰øõà =cÄ/>eWµ?2<V)?À	?Ô/æJLˆ>ox¨>R∏?ÕÂ>†?N"?|C?C”æè&k?,û6øDkNøni?¢‘?Œc<>*≠ B$decoder.blocks.3.conv2.0.weight_biasJÄá∏>îÖ∂æ∂pØ>Ön>¶£S>AæÌ?@Áô?ÊÅΩì)ú=éà4=“Oc>Œë
?˝}t?E#U?”yj>Âa=>Ùˆ∏>èR? .æ> ·:÷iè=è≈>˛≈«>-ÒÚ>&Ào>)Êª>!xÂ?¬Ñø®x§Ωﬁu7æ©ﬁæ*lB$decoder.blocks.4.conv1.0.weight_biasJ@iïI¿^Å$@†+Óøæ?P@b´Ñ¿‰√x?c:?}j˚>(•>%qñ>(‰˛ΩÿT±=?uw?—Á?·ªp?*lB$decoder.blocks.4.conv2.0.weight_biasJ@_øª}„>JÃøÏC˝øÕÏ¿ø\K¿%%
ø*≥øÙı¿Z^-øfø´◊¿VŒGøÇ±øœ$¿ø1Tø* Bval_1018J  Ä?  Ä?   @   @Z⁄
input+
)%

batch_size

height
width"=
/pkg.torch.export.graph_signature.InputSpec.kind
USER_INPUT"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"&
!pkg.torch.onnx.original_node_namexb”
outputW
UQ

batch_size

32*(((height - 1)//32)) + 32
32*(((width - 1)//32)) + 32"?
0pkg.torch.export.graph_signature.OutputSpec.kindUSER_OUTPUT"/
!pkg.torch.onnx.original_node_name
conv2d_139j=
#encoder.stages.1.0.block.0.0.weight

(


jä
%encoder.stages.1.0.block.1.fc1.weight



(

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_1_0_block_1_fc1_weightj˙
#encoder.stages.1.0.block.1.fc1.bias



"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_1_0_block_1_fc1_biasjä
%encoder.stages.1.0.block.1.fc2.weight

(



"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_1_0_block_1_fc2_weightj˙
#encoder.stages.1.0.block.1.fc2.bias


("<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_1_0_block_1_fc2_biasj=
#encoder.stages.1.0.block.2.0.weight


(

j=
#encoder.stages.1.1.block.0.0.weight




jä
%encoder.stages.1.1.block.1.fc1.weight




"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_1_1_block_1_fc1_weightj˙
#encoder.stages.1.1.block.1.fc1.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_1_1_block_1_fc1_biasjä
%encoder.stages.1.1.block.1.fc2.weight




"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_1_1_block_1_fc2_weightj˙
#encoder.stages.1.1.block.1.fc2.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_1_1_block_1_fc2_biasj=
#encoder.stages.1.1.block.2.0.weight




jã
%encoder.stages.2.0.block.2.fc1.weight


ê

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_2_0_block_2_fc1_weightj˙
#encoder.stages.2.0.block.2.fc1.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_2_0_block_2_fc1_biasjã
%encoder.stages.2.0.block.2.fc2.weight

ê


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_2_0_block_2_fc2_weightj˚
#encoder.stages.2.0.block.2.fc2.bias
	
ê"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_2_0_block_2_fc2_biasj˙
#encoder.stages.2.1.block.2.fc1.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_2_1_block_2_fc1_biasj˚
#encoder.stages.2.1.block.2.fc2.bias
	
¿"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_2_1_block_2_fc2_biasj˙
#encoder.stages.2.2.block.2.fc1.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_2_2_block_2_fc1_biasj˚
#encoder.stages.2.2.block.2.fc2.bias
	
¿"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_2_2_block_2_fc2_biasj˙
#encoder.stages.3.0.block.2.fc1.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_3_0_block_2_fc1_biasj˚
#encoder.stages.3.0.block.2.fc2.bias
	
¿"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_3_0_block_2_fc2_biasj˙
#encoder.stages.3.1.block.2.fc1.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_3_1_block_2_fc1_biasj˚
#encoder.stages.3.1.block.2.fc2.bias
	
†"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_3_1_block_2_fc2_biasj˙
#encoder.stages.3.2.block.2.fc1.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_3_2_block_2_fc1_biasj˚
#encoder.stages.3.2.block.2.fc2.bias
	
†"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_3_2_block_2_fc2_biasj˙
#encoder.stages.4.0.block.2.fc1.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_4_0_block_2_fc1_biasj˚
#encoder.stages.4.0.block.2.fc2.bias
	
†"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_4_0_block_2_fc2_biasj˙
#encoder.stages.4.1.block.2.fc1.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_4_1_block_2_fc1_biasj˚
#encoder.stages.4.1.block.2.fc2.bias
	
¿"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_4_1_block_2_fc2_biasj˙
#encoder.stages.4.2.block.2.fc1.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_4_2_block_2_fc1_biasj˚
#encoder.stages.4.2.block.2.fc2.bias
	
¿"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_4_2_block_2_fc2_biasj˙
#encoder.stages.4.3.block.2.fc1.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_4_3_block_2_fc1_biasj˚
#encoder.stages.4.3.block.2.fc2.bias
	
¿"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_4_3_block_2_fc2_biasj˙
#encoder.stages.4.4.block.2.fc1.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_4_4_block_2_fc1_biasj˚
#encoder.stages.4.4.block.2.fc2.bias
	
¿"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_4_4_block_2_fc2_biasj˙
#encoder.stages.5.0.block.2.fc1.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_5_0_block_2_fc1_biasj˚
#encoder.stages.5.0.block.2.fc2.bias
	
¿"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_5_0_block_2_fc2_biasj˙
#encoder.stages.5.1.block.2.fc1.bias


""<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_5_1_block_2_fc1_biasj˚
#encoder.stages.5.1.block.2.fc2.bias
	
∞"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_5_1_block_2_fc2_biasj˙
#encoder.stages.5.2.block.2.fc1.bias


""<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_5_2_block_2_fc1_biasj˚
#encoder.stages.5.2.block.2.fc2.bias
	
∞"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_5_2_block_2_fc2_biasj˙
#encoder.stages.5.3.block.2.fc1.bias


""<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_5_3_block_2_fc1_biasj˚
#encoder.stages.5.3.block.2.fc2.bias
	
∞"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_5_3_block_2_fc2_biasj˙
#encoder.stages.5.4.block.2.fc1.bias


""<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_5_4_block_2_fc1_biasj˚
#encoder.stages.5.4.block.2.fc2.bias
	
∞"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_5_4_block_2_fc2_biasj˙
#encoder.stages.6.0.block.2.fc1.bias


""<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_6_0_block_2_fc1_biasj˚
#encoder.stages.6.0.block.2.fc2.bias
	
∞"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_6_0_block_2_fc2_biasj˙
#encoder.stages.6.1.block.2.fc1.bias


:"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_6_1_block_2_fc1_biasj˙
#encoder.stages.6.2.block.2.fc1.bias


:"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_6_2_block_2_fc1_biasj˙
#encoder.stages.6.3.block.2.fc1.bias


:"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_6_3_block_2_fc1_biasj˙
#encoder.stages.6.4.block.2.fc1.bias


:"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_6_4_block_2_fc1_biasj˙
#encoder.stages.6.5.block.2.fc1.bias


:"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_6_5_block_2_fc1_biasj˙
#encoder.stages.7.0.block.2.fc1.bias


:"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_7_0_block_2_fc1_biasj˙
#encoder.stages.7.1.block.2.fc1.bias


`"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_7_1_block_2_fc1_biasj
segmentation_head.weight




"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"?
!pkg.torch.onnx.original_node_namep_segmentation_head_weightj‡
segmentation_head.bias


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"=
!pkg.torch.onnx.original_node_namep_segmentation_head_biasj3
encoder.stages.0.0.weight

(


j>
#encoder.stages.2.0.block.0.0.weight

ê


j>
#encoder.stages.2.0.block.1.0.weight

ê


j>
#encoder.stages.2.0.block.3.0.weight

 
ê

j>
#encoder.stages.2.1.block.0.0.weight

¿
 

j>
#encoder.stages.2.1.block.1.0.weight

¿


jã
%encoder.stages.2.1.block.2.fc1.weight


¿

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_2_1_block_2_fc1_weightjã
%encoder.stages.2.1.block.2.fc2.weight

¿


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_2_1_block_2_fc2_weightj>
#encoder.stages.2.1.block.3.0.weight

 
¿

j>
#encoder.stages.2.2.block.0.0.weight

¿
 

j>
#encoder.stages.2.2.block.1.0.weight

¿


jã
%encoder.stages.2.2.block.2.fc1.weight


¿

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_2_2_block_2_fc1_weightjã
%encoder.stages.2.2.block.2.fc2.weight

¿


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_2_2_block_2_fc2_weightj>
#encoder.stages.2.2.block.3.0.weight

 
¿

j>
#encoder.stages.3.0.block.0.0.weight

¿
 

j>
#encoder.stages.3.0.block.1.0.weight

¿


jã
%encoder.stages.3.0.block.2.fc1.weight


¿

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_3_0_block_2_fc1_weightjã
%encoder.stages.3.0.block.2.fc2.weight

¿


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_3_0_block_2_fc2_weightj>
#encoder.stages.3.0.block.3.0.weight

0
¿

j>
#encoder.stages.3.1.block.0.0.weight

†
0

j>
#encoder.stages.3.1.block.1.0.weight

†


jã
%encoder.stages.3.1.block.2.fc1.weight


†

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_3_1_block_2_fc1_weightjã
%encoder.stages.3.1.block.2.fc2.weight

†


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_3_1_block_2_fc2_weightj>
#encoder.stages.3.1.block.3.0.weight

0
†

j>
#encoder.stages.3.2.block.0.0.weight

†
0

j>
#encoder.stages.3.2.block.1.0.weight

†


jã
%encoder.stages.3.2.block.2.fc1.weight


†

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_3_2_block_2_fc1_weightjã
%encoder.stages.3.2.block.2.fc2.weight

†


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_3_2_block_2_fc2_weightj>
#encoder.stages.3.2.block.3.0.weight

0
†

j>
#encoder.stages.4.0.block.0.0.weight

†
0

j>
#encoder.stages.4.0.block.1.0.weight

†


jã
%encoder.stages.4.0.block.2.fc1.weight


†

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_4_0_block_2_fc1_weightjã
%encoder.stages.4.0.block.2.fc2.weight

†


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_4_0_block_2_fc2_weightj>
#encoder.stages.4.0.block.3.0.weight

`
†

j>
#encoder.stages.4.1.block.0.0.weight

¿
`

j>
#encoder.stages.4.1.block.1.0.weight

¿


jã
%encoder.stages.4.1.block.2.fc1.weight


¿

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_4_1_block_2_fc1_weightjã
%encoder.stages.4.1.block.2.fc2.weight

¿


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_4_1_block_2_fc2_weightj>
#encoder.stages.4.1.block.3.0.weight

`
¿

j>
#encoder.stages.4.2.block.0.0.weight

¿
`

j>
#encoder.stages.4.2.block.1.0.weight

¿


jã
%encoder.stages.4.2.block.2.fc1.weight


¿

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_4_2_block_2_fc1_weightjã
%encoder.stages.4.2.block.2.fc2.weight

¿


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_4_2_block_2_fc2_weightj>
#encoder.stages.4.2.block.3.0.weight

`
¿

j>
#encoder.stages.4.3.block.0.0.weight

¿
`

j>
#encoder.stages.4.3.block.1.0.weight

¿


jã
%encoder.stages.4.3.block.2.fc1.weight


¿

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_4_3_block_2_fc1_weightjã
%encoder.stages.4.3.block.2.fc2.weight

¿


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_4_3_block_2_fc2_weightj>
#encoder.stages.4.3.block.3.0.weight

`
¿

j>
#encoder.stages.4.4.block.0.0.weight

¿
`

j>
#encoder.stages.4.4.block.1.0.weight

¿


jã
%encoder.stages.4.4.block.2.fc1.weight


¿

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_4_4_block_2_fc1_weightjã
%encoder.stages.4.4.block.2.fc2.weight

¿


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_4_4_block_2_fc2_weightj>
#encoder.stages.4.4.block.3.0.weight

`
¿

j>
#encoder.stages.5.0.block.0.0.weight

¿
`

j>
#encoder.stages.5.0.block.1.0.weight

¿


jã
%encoder.stages.5.0.block.2.fc1.weight


¿

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_5_0_block_2_fc1_weightjã
%encoder.stages.5.0.block.2.fc2.weight

¿


"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_5_0_block_2_fc2_weightj?
#encoder.stages.5.0.block.3.0.weight

à
¿

j?
#encoder.stages.5.1.block.0.0.weight

∞
à

j>
#encoder.stages.5.1.block.1.0.weight

∞


jã
%encoder.stages.5.1.block.2.fc1.weight

"
∞

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_5_1_block_2_fc1_weightjã
%encoder.stages.5.1.block.2.fc2.weight

∞
"

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_5_1_block_2_fc2_weightj?
#encoder.stages.5.1.block.3.0.weight

à
∞

j?
#encoder.stages.5.2.block.0.0.weight

∞
à

j>
#encoder.stages.5.2.block.1.0.weight

∞


jã
%encoder.stages.5.2.block.2.fc1.weight

"
∞

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_5_2_block_2_fc1_weightjã
%encoder.stages.5.2.block.2.fc2.weight

∞
"

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_5_2_block_2_fc2_weightj?
#encoder.stages.5.2.block.3.0.weight

à
∞

j?
#encoder.stages.5.3.block.0.0.weight

∞
à

j>
#encoder.stages.5.3.block.1.0.weight

∞


jã
%encoder.stages.5.3.block.2.fc1.weight

"
∞

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_5_3_block_2_fc1_weightjã
%encoder.stages.5.3.block.2.fc2.weight

∞
"

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_5_3_block_2_fc2_weightj?
#encoder.stages.5.3.block.3.0.weight

à
∞

j?
#encoder.stages.5.4.block.0.0.weight

∞
à

j>
#encoder.stages.5.4.block.1.0.weight

∞


jã
%encoder.stages.5.4.block.2.fc1.weight

"
∞

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_5_4_block_2_fc1_weightjã
%encoder.stages.5.4.block.2.fc2.weight

∞
"

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_5_4_block_2_fc2_weightj?
#encoder.stages.5.4.block.3.0.weight

à
∞

j?
#encoder.stages.6.0.block.0.0.weight

∞
à

j>
#encoder.stages.6.0.block.1.0.weight

∞


jã
%encoder.stages.6.0.block.2.fc1.weight

"
∞

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_6_0_block_2_fc1_weightjã
%encoder.stages.6.0.block.2.fc2.weight

∞
"

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_6_0_block_2_fc2_weightj?
#encoder.stages.6.0.block.3.0.weight

Ë
∞

j?
#encoder.stages.6.1.block.0.0.weight



Ë

j>
#encoder.stages.6.1.block.1.0.weight





jã
%encoder.stages.6.1.block.2.fc1.weight

:



"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_6_1_block_2_fc1_weightjã
%encoder.stages.6.1.block.2.fc2.weight



:

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_6_1_block_2_fc2_weightj˚
#encoder.stages.6.1.block.2.fc2.bias
	

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_6_1_block_2_fc2_biasj?
#encoder.stages.6.1.block.3.0.weight

Ë



j?
#encoder.stages.6.2.block.0.0.weight



Ë

j>
#encoder.stages.6.2.block.1.0.weight





jã
%encoder.stages.6.2.block.2.fc1.weight

:



"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_6_2_block_2_fc1_weightjã
%encoder.stages.6.2.block.2.fc2.weight



:

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_6_2_block_2_fc2_weightj˚
#encoder.stages.6.2.block.2.fc2.bias
	

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_6_2_block_2_fc2_biasj?
#encoder.stages.6.2.block.3.0.weight

Ë



j?
#encoder.stages.6.3.block.0.0.weight



Ë

j>
#encoder.stages.6.3.block.1.0.weight





jã
%encoder.stages.6.3.block.2.fc1.weight

:



"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_6_3_block_2_fc1_weightjã
%encoder.stages.6.3.block.2.fc2.weight



:

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_6_3_block_2_fc2_weightj˚
#encoder.stages.6.3.block.2.fc2.bias
	

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_6_3_block_2_fc2_biasj?
#encoder.stages.6.3.block.3.0.weight

Ë



j?
#encoder.stages.6.4.block.0.0.weight



Ë

j>
#encoder.stages.6.4.block.1.0.weight





jã
%encoder.stages.6.4.block.2.fc1.weight

:



"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_6_4_block_2_fc1_weightjã
%encoder.stages.6.4.block.2.fc2.weight



:

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_6_4_block_2_fc2_weightj˚
#encoder.stages.6.4.block.2.fc2.bias
	

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_6_4_block_2_fc2_biasj?
#encoder.stages.6.4.block.3.0.weight

Ë



j?
#encoder.stages.6.5.block.0.0.weight



Ë

j>
#encoder.stages.6.5.block.1.0.weight





jã
%encoder.stages.6.5.block.2.fc1.weight

:



"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_6_5_block_2_fc1_weightjã
%encoder.stages.6.5.block.2.fc2.weight



:

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_6_5_block_2_fc2_weightj˚
#encoder.stages.6.5.block.2.fc2.bias
	

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_6_5_block_2_fc2_biasj?
#encoder.stages.6.5.block.3.0.weight

Ë



j?
#encoder.stages.7.0.block.0.0.weight



Ë

j>
#encoder.stages.7.0.block.1.0.weight





jã
%encoder.stages.7.0.block.2.fc1.weight

:



"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_7_0_block_2_fc1_weightjã
%encoder.stages.7.0.block.2.fc2.weight



:

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_7_0_block_2_fc2_weightj˚
#encoder.stages.7.0.block.2.fc2.bias
	

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_7_0_block_2_fc2_biasj?
#encoder.stages.7.0.block.3.0.weight

Ä



j?
#encoder.stages.7.1.block.0.0.weight

Ä
Ä

j>
#encoder.stages.7.1.block.1.0.weight

Ä


jã
%encoder.stages.7.1.block.2.fc1.weight

`
Ä

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_7_1_block_2_fc1_weightjã
%encoder.stages.7.1.block.2.fc2.weight

Ä
`

"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"L
!pkg.torch.onnx.original_node_name'p_encoder_stages_7_1_block_2_fc2_weightj˚
#encoder.stages.7.1.block.2.fc2.bias
	
Ä"<
/pkg.torch.export.graph_signature.InputSpec.kind	PARAMETER"=
5pkg.torch.export.graph_signature.InputSpec.persistentNone"J
!pkg.torch.onnx.original_node_name%p_encoder_stages_7_1_block_2_fc2_biasj?
#encoder.stages.7.1.block.3.0.weight

Ä
Ä

j;
decoder.blocks.0.conv1.0.weight

Ä
à

j;
decoder.blocks.0.conv2.0.weight

Ä
Ä

j;
decoder.blocks.1.conv1.0.weight

Ä
∞

j;
decoder.blocks.1.conv2.0.weight

Ä
Ä

j:
decoder.blocks.2.conv1.0.weight

@
†

j9
decoder.blocks.2.conv2.0.weight

@
@

j9
decoder.blocks.3.conv1.0.weight

 
h

j9
decoder.blocks.3.conv2.0.weight

 
 

j9
decoder.blocks.4.conv1.0.weight


 

j9
decoder.blocks.4.conv2.0.weight




jR
val_67


"<
$pkg.onnxscript.optimizer.folded_from['val_65', 'val_66']j,
encoder.stages.0.0.weight_bias


(j6
(encoder.stages.1.0.block.0.0.weight_bias


(j6
(encoder.stages.1.0.block.2.0.weight_bias


j6
(encoder.stages.1.1.block.0.0.weight_bias


j6
(encoder.stages.1.1.block.2.0.weight_bias


j7
(encoder.stages.2.0.block.0.0.weight_bias
	
êj7
(encoder.stages.2.0.block.1.0.weight_bias
	
êj6
(encoder.stages.2.0.block.3.0.weight_bias


 j7
(encoder.stages.2.1.block.0.0.weight_bias
	
¿j7
(encoder.stages.2.1.block.1.0.weight_bias
	
¿j6
(encoder.stages.2.1.block.3.0.weight_bias


 j7
(encoder.stages.2.2.block.0.0.weight_bias
	
¿j7
(encoder.stages.2.2.block.1.0.weight_bias
	
¿j6
(encoder.stages.2.2.block.3.0.weight_bias


 j7
(encoder.stages.3.0.block.0.0.weight_bias
	
¿j7
(encoder.stages.3.0.block.1.0.weight_bias
	
¿j6
(encoder.stages.3.0.block.3.0.weight_bias


0j7
(encoder.stages.3.1.block.0.0.weight_bias
	
†j7
(encoder.stages.3.1.block.1.0.weight_bias
	
†j6
(encoder.stages.3.1.block.3.0.weight_bias


0j7
(encoder.stages.3.2.block.0.0.weight_bias
	
†j7
(encoder.stages.3.2.block.1.0.weight_bias
	
†j6
(encoder.stages.3.2.block.3.0.weight_bias


0j7
(encoder.stages.4.0.block.0.0.weight_bias
	
†j7
(encoder.stages.4.0.block.1.0.weight_bias
	
†j6
(encoder.stages.4.0.block.3.0.weight_bias


`j7
(encoder.stages.4.1.block.0.0.weight_bias
	
¿j7
(encoder.stages.4.1.block.1.0.weight_bias
	
¿j6
(encoder.stages.4.1.block.3.0.weight_bias


`j7
(encoder.stages.4.2.block.0.0.weight_bias
	
¿j7
(encoder.stages.4.2.block.1.0.weight_bias
	
¿j6
(encoder.stages.4.2.block.3.0.weight_bias


`j7
(encoder.stages.4.3.block.0.0.weight_bias
	
¿j7
(encoder.stages.4.3.block.1.0.weight_bias
	
¿j6
(encoder.stages.4.3.block.3.0.weight_bias


`j7
(encoder.stages.4.4.block.0.0.weight_bias
	
¿j7
(encoder.stages.4.4.block.1.0.weight_bias
	
¿j6
(encoder.stages.4.4.block.3.0.weight_bias


`j7
(encoder.stages.5.0.block.0.0.weight_bias
	
¿j7
(encoder.stages.5.0.block.1.0.weight_bias
	
¿j7
(encoder.stages.5.0.block.3.0.weight_bias
	
àj7
(encoder.stages.5.1.block.0.0.weight_bias
	
∞j7
(encoder.stages.5.1.block.1.0.weight_bias
	
∞j7
(encoder.stages.5.1.block.3.0.weight_bias
	
àj7
(encoder.stages.5.2.block.0.0.weight_bias
	
∞j7
(encoder.stages.5.2.block.1.0.weight_bias
	
∞j7
(encoder.stages.5.2.block.3.0.weight_bias
	
àj7
(encoder.stages.5.3.block.0.0.weight_bias
	
∞j7
(encoder.stages.5.3.block.1.0.weight_bias
	
∞j7
(encoder.stages.5.3.block.3.0.weight_bias
	
àj7
(encoder.stages.5.4.block.0.0.weight_bias
	
∞j7
(encoder.stages.5.4.block.1.0.weight_bias
	
∞j7
(encoder.stages.5.4.block.3.0.weight_bias
	
àj7
(encoder.stages.6.0.block.0.0.weight_bias
	
∞j7
(encoder.stages.6.0.block.1.0.weight_bias
	
∞j7
(encoder.stages.6.0.block.3.0.weight_bias
	
Ëj7
(encoder.stages.6.1.block.0.0.weight_bias
	

j7
(encoder.stages.6.1.block.1.0.weight_bias
	

j7
(encoder.stages.6.1.block.3.0.weight_bias
	
Ëj7
(encoder.stages.6.2.block.0.0.weight_bias
	

j7
(encoder.stages.6.2.block.1.0.weight_bias
	

j7
(encoder.stages.6.2.block.3.0.weight_bias
	
Ëj7
(encoder.stages.6.3.block.0.0.weight_bias
	

j7
(encoder.stages.6.3.block.1.0.weight_bias
	

j7
(encoder.stages.6.3.block.3.0.weight_bias
	
Ëj7
(encoder.stages.6.4.block.0.0.weight_bias
	

j7
(encoder.stages.6.4.block.1.0.weight_bias
	

j7
(encoder.stages.6.4.block.3.0.weight_bias
	
Ëj7
(encoder.stages.6.5.block.0.0.weight_bias
	

j7
(encoder.stages.6.5.block.1.0.weight_bias
	

j7
(encoder.stages.6.5.block.3.0.weight_bias
	
Ëj7
(encoder.stages.7.0.block.0.0.weight_bias
	

j7
(encoder.stages.7.0.block.1.0.weight_bias
	

j7
(encoder.stages.7.0.block.3.0.weight_bias
	
Äj7
(encoder.stages.7.1.block.0.0.weight_bias
	
Äj7
(encoder.stages.7.1.block.1.0.weight_bias
	
Äj7
(encoder.stages.7.1.block.3.0.weight_bias
	
Äj3
$decoder.blocks.0.conv1.0.weight_bias
	
Äj3
$decoder.blocks.0.conv2.0.weight_bias
	
Äj3
$decoder.blocks.1.conv1.0.weight_bias
	
Äj3
$decoder.blocks.1.conv2.0.weight_bias
	
Äj2
$decoder.blocks.2.conv1.0.weight_bias


@j2
$decoder.blocks.2.conv2.0.weight_bias


@j2
$decoder.blocks.3.conv1.0.weight_bias


 j2
$decoder.blocks.3.conv2.0.weight_bias


 j2
$decoder.blocks.4.conv1.0.weight_bias


j2
$decoder.blocks.4.conv2.0.weight_bias


j
val_1018


jX
getitemM
KG

batch_size
(
(((height - 1)//2)) + 1
(((width - 1)//2)) + 1jW
val_52M
KG

batch_size
(
(((height - 1)//2)) + 1
(((width - 1)//2)) + 1jU
siluM
KG

batch_size
(
(((height - 1)//2)) + 1
(((width - 1)//2)) + 1jZ
	getitem_3M
KG

batch_size
(
(((height - 1)//2)) + 1
(((width - 1)//2)) + 1jW
val_64M
KG

batch_size
(
(((height - 1)//2)) + 1
(((width - 1)//2)) + 1jW
silu_1M
KG

batch_size
(
(((height - 1)//2)) + 1
(((width - 1)//2)) + 1j(
mean 


batch_size
(

j,
conv2d_2 


batch_size



j*
val_68 


batch_size



j*
silu_2 


batch_size



j,
conv2d_3 


batch_size
(

j+
sigmoid 


batch_size
(

jX
mul_178M
KG

batch_size
(
(((height - 1)//2)) + 1
(((width - 1)//2)) + 1jZ
	getitem_6M
KG

batch_size

(((height - 1)//2)) + 1
(((width - 1)//2)) + 1jZ
	getitem_9M
KG

batch_size

(((height - 1)//2)) + 1
(((width - 1)//2)) + 1jW
val_91M
KG

batch_size

(((height - 1)//2)) + 1
(((width - 1)//2)) + 1jW
silu_3M
KG

batch_size

(((height - 1)//2)) + 1
(((width - 1)//2)) + 1j*
mean_1 


batch_size


j,
conv2d_6 


batch_size


j*
val_94 


batch_size


j*
silu_4 


batch_size


j,
conv2d_7 


batch_size


j-
	sigmoid_1 


batch_size


jX
mul_255M
KG

batch_size

(((height - 1)//2)) + 1
(((width - 1)//2)) + 1j[

getitem_12M
KG

batch_size

(((height - 1)//2)) + 1
(((width - 1)//2)) + 1jX
add_213M
KG

batch_size

(((height - 1)//2)) + 1
(((width - 1)//2)) + 1j\

getitem_15N
LH

batch_size
ê
(((height - 1)//2)) + 1
(((width - 1)//2)) + 1jY
val_117N
LH

batch_size
ê
(((height - 1)//2)) + 1
(((width - 1)//2)) + 1jX
silu_5N
LH

batch_size
ê
(((height - 1)//2)) + 1
(((width - 1)//2)) + 1j\

getitem_18N
LH

batch_size
ê
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1jY
val_129N
LH

batch_size
ê
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1jX
silu_6N
LH

batch_size
ê
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1j+
mean_2!


batch_size
ê

j-
	conv2d_11 


batch_size


j+
val_132 


batch_size


j*
silu_7 


batch_size


j.
	conv2d_12!


batch_size
ê

j.
	sigmoid_2!


batch_size
ê

jY
mul_384N
LH

batch_size
ê
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1j[

getitem_21M
KG

batch_size
 
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1j\

getitem_24N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1jY
val_155N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1jX
silu_8N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1j\

getitem_27N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1jY
val_167N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1jX
silu_9N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1j+
mean_3!


batch_size
¿

j-
	conv2d_16 


batch_size


j+
val_170 


batch_size


j+
silu_10 


batch_size


j.
	conv2d_17!


batch_size
¿

j.
	sigmoid_3!


batch_size
¿

jY
mul_501N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1j[

getitem_30M
KG

batch_size
 
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1jX
add_405M
KG

batch_size
 
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1j\

getitem_33N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1jY
val_193N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1jY
silu_11N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1j\

getitem_36N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1jY
val_205N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1jY
silu_12N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1j+
mean_4!


batch_size
¿

j-
	conv2d_21 


batch_size


j+
val_208 


batch_size


j+
silu_13 


batch_size


j.
	conv2d_22!


batch_size
¿

j.
	sigmoid_4!


batch_size
¿

jY
mul_630N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1j[

getitem_39M
KG

batch_size
 
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1jX
add_509M
KG

batch_size
 
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1j\

getitem_42N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1jY
val_231N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1jY
silu_14N
LH

batch_size
¿
(((height - 1)//4)) + 1
(((width - 1)//4)) + 1j\

getitem_45N
LH

batch_size
¿
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1jY
val_243N
LH

batch_size
¿
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1jY
silu_15N
LH

batch_size
¿
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1j+
mean_5!


batch_size
¿

j-
	conv2d_26 


batch_size


j+
val_246 


batch_size


j+
silu_16 


batch_size


j.
	conv2d_27!


batch_size
¿

j.
	sigmoid_5!


batch_size
¿

jY
mul_759N
LH

batch_size
¿
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1j[

getitem_48M
KG

batch_size
0
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1j\

getitem_51N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1jY
val_269N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1jY
silu_17N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1j\

getitem_54N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1jY
val_281N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1jY
silu_18N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1j+
mean_6!


batch_size
†

j-
	conv2d_31 


batch_size


j+
val_284 


batch_size


j+
silu_19 


batch_size


j.
	conv2d_32!


batch_size
†

j.
	sigmoid_6!


batch_size
†

jY
mul_876N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1j[

getitem_57M
KG

batch_size
0
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1jX
add_701M
KG

batch_size
0
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1j\

getitem_60N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1jY
val_307N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1jY
silu_20N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1j\

getitem_63N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1jY
val_319N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1jY
silu_21N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1j+
mean_7!


batch_size
†

j-
	conv2d_36 


batch_size


j+
val_322 


batch_size


j+
silu_22 


batch_size


j.
	conv2d_37!


batch_size
†

j.
	sigmoid_7!


batch_size
†

jZ
mul_1005N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1j[

getitem_66M
KG

batch_size
0
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1jX
add_805M
KG

batch_size
0
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1j\

getitem_69N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1jY
val_345N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1jY
silu_23N
LH

batch_size
†
(((height - 1)//8)) + 1
(((width - 1)//8)) + 1j^

getitem_72P
NJ

batch_size
†
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_357P
NJ

batch_size
†
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_24P
NJ

batch_size
†
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j+
mean_8!


batch_size
†

j-
	conv2d_41 


batch_size


j+
val_360 


batch_size


j+
silu_25 


batch_size


j.
	conv2d_42!


batch_size
†

j.
	sigmoid_8!


batch_size
†

j\
mul_1134P
NJ

batch_size
†
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j]

getitem_75O
MI

batch_size
`
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j^

getitem_78P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_383P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_26P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j^

getitem_81P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_395P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_27P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j+
mean_9!


batch_size
¿

j-
	conv2d_46 


batch_size


j+
val_398 


batch_size


j+
silu_28 


batch_size


j.
	conv2d_47!


batch_size
¿

j.
	sigmoid_9!


batch_size
¿

j\
mul_1251P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j]

getitem_84O
MI

batch_size
`
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1jZ
add_997O
MI

batch_size
`
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j^

getitem_87P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_421P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_29P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j^

getitem_90P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_433P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_30P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j,
mean_10!


batch_size
¿

j-
	conv2d_51 


batch_size


j+
val_436 


batch_size


j+
silu_31 


batch_size


j.
	conv2d_52!


batch_size
¿

j/

sigmoid_10!


batch_size
¿

j\
mul_1380P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j]

getitem_93O
MI

batch_size
`
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
add_1101O
MI

batch_size
`
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j^

getitem_96P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_459P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_32P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j^

getitem_99P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_471P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_33P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j,
mean_11!


batch_size
¿

j-
	conv2d_56 


batch_size


j+
val_474 


batch_size


j+
silu_34 


batch_size


j.
	conv2d_57!


batch_size
¿

j/

sigmoid_11!


batch_size
¿

j\
mul_1509P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j^
getitem_102O
MI

batch_size
`
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
add_1205O
MI

batch_size
`
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_105P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_497P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_35P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_108P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_509P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_36P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j,
mean_12!


batch_size
¿

j-
	conv2d_61 


batch_size


j+
val_512 


batch_size


j+
silu_37 


batch_size


j.
	conv2d_62!


batch_size
¿

j/

sigmoid_12!


batch_size
¿

j\
mul_1638P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j^
getitem_111O
MI

batch_size
`
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
add_1309O
MI

batch_size
`
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_114P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_535P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_38P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_117P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_547P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_39P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j,
mean_13!


batch_size
¿

j-
	conv2d_66 


batch_size


j+
val_550 


batch_size


j+
silu_40 


batch_size


j.
	conv2d_67!


batch_size
¿

j/

sigmoid_13!


batch_size
¿

j\
mul_1767P
NJ

batch_size
¿
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_120P
NJ

batch_size
à
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_123P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_573P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_41P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_126P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_585P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_42P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j,
mean_14!


batch_size
∞

j-
	conv2d_71 


batch_size
"

j+
val_588 


batch_size
"

j+
silu_43 


batch_size
"

j.
	conv2d_72!


batch_size
∞

j/

sigmoid_14!


batch_size
∞

j\
mul_1884P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_129P
NJ

batch_size
à
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j\
add_1501P
NJ

batch_size
à
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_132P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_611P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_44P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_135P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_623P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_45P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j,
mean_15!


batch_size
∞

j-
	conv2d_76 


batch_size
"

j+
val_626 


batch_size
"

j+
silu_46 


batch_size
"

j.
	conv2d_77!


batch_size
∞

j/

sigmoid_15!


batch_size
∞

j\
mul_2013P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_138P
NJ

batch_size
à
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j\
add_1605P
NJ

batch_size
à
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_141P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_649P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_47P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_144P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_661P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_48P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j,
mean_16!


batch_size
∞

j-
	conv2d_81 


batch_size
"

j+
val_664 


batch_size
"

j+
silu_49 


batch_size
"

j.
	conv2d_82!


batch_size
∞

j/

sigmoid_16!


batch_size
∞

j\
mul_2142P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_147P
NJ

batch_size
à
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j\
add_1709P
NJ

batch_size
à
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_150P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_687P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_50P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_153P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_699P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_51P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j,
mean_17!


batch_size
∞

j-
	conv2d_86 


batch_size
"

j+
val_702 


batch_size
"

j+
silu_52 


batch_size
"

j.
	conv2d_87!


batch_size
∞

j/

sigmoid_17!


batch_size
∞

j\
mul_2271P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_156P
NJ

batch_size
à
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j\
add_1813P
NJ

batch_size
à
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_159P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
val_725P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j[
silu_53P
NJ

batch_size
∞
(((height - 1)//16)) + 1
(((width - 1)//16)) + 1j_
getitem_162P
NJ

batch_size
∞
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
val_737P
NJ

batch_size
∞
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
silu_54P
NJ

batch_size
∞
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j,
mean_18!


batch_size
∞

j-
	conv2d_91 


batch_size
"

j+
val_740 


batch_size
"

j+
silu_55 


batch_size
"

j.
	conv2d_92!


batch_size
∞

j/

sigmoid_18!


batch_size
∞

j\
mul_2400P
NJ

batch_size
∞
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_165P
NJ

batch_size
Ë
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_168P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
val_763P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
silu_56P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_171P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
val_775P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
silu_57P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j,
mean_19!


batch_size



j-
	conv2d_96 


batch_size
:

j+
val_778 


batch_size
:

j+
silu_58 


batch_size
:

j.
	conv2d_97!


batch_size



j/

sigmoid_19!


batch_size



j\
mul_2517P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_174P
NJ

batch_size
Ë
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j\
add_2005P
NJ

batch_size
Ë
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_177P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
val_801P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
silu_59P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_180P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
val_813P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
silu_60P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j,
mean_20!


batch_size



j.

conv2d_101 


batch_size
:

j+
val_816 


batch_size
:

j+
silu_61 


batch_size
:

j/

conv2d_102!


batch_size



j/

sigmoid_20!


batch_size



j\
mul_2646P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_183P
NJ

batch_size
Ë
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j\
add_2109P
NJ

batch_size
Ë
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_186P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
val_839P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
silu_62P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_189P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
val_851P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
silu_63P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j,
mean_21!


batch_size



j.

conv2d_106 


batch_size
:

j+
val_854 


batch_size
:

j+
silu_64 


batch_size
:

j/

conv2d_107!


batch_size



j/

sigmoid_21!


batch_size



j\
mul_2775P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_192P
NJ

batch_size
Ë
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j\
add_2213P
NJ

batch_size
Ë
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_195P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
val_877P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
silu_65P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_198P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
val_889P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
silu_66P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j,
mean_22!


batch_size



j.

conv2d_111 


batch_size
:

j+
val_892 


batch_size
:

j+
silu_67 


batch_size
:

j/

conv2d_112!


batch_size



j/

sigmoid_22!


batch_size



j\
mul_2904P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_201P
NJ

batch_size
Ë
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j\
add_2317P
NJ

batch_size
Ë
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_204P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
val_915P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
silu_68P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_207P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
val_927P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
silu_69P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j,
mean_23!


batch_size



j.

conv2d_116 


batch_size
:

j+
val_930 


batch_size
:

j+
silu_70 


batch_size
:

j/

conv2d_117!


batch_size



j/

sigmoid_23!


batch_size



j\
mul_3033P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_210P
NJ

batch_size
Ë
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j\
add_2421P
NJ

batch_size
Ë
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_213P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
val_953P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
silu_71P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_216P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
val_965P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
silu_72P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j,
mean_24!


batch_size



j.

conv2d_121 


batch_size
:

j+
val_968 


batch_size
:

j+
silu_73 


batch_size
:

j/

conv2d_122!


batch_size



j/

sigmoid_24!


batch_size



j\
mul_3162P
NJ

batch_size


(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_219P
NJ

batch_size
Ä
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_222P
NJ

batch_size
Ä
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
val_991P
NJ

batch_size
Ä
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
silu_74P
NJ

batch_size
Ä
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_225P
NJ

batch_size
Ä
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j\
val_1003P
NJ

batch_size
Ä
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j[
silu_75P
NJ

batch_size
Ä
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j,
mean_25!


batch_size
Ä

j.

conv2d_126 


batch_size
`

j,
val_1006 


batch_size
`

j+
silu_76 


batch_size
`

j/

conv2d_127!


batch_size
Ä

j/

sigmoid_25!


batch_size
Ä

j\
mul_3279P
NJ

batch_size
Ä
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j_
getitem_228P
NJ

batch_size
Ä
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1j\
add_2613P
NJ

batch_size
Ä
(((height - 1)//32)) + 1
(((width - 1)//32)) + 1jj
upsample_nearest2dT
RN

batch_size
Ä
2*(((height - 1)//32)) + 2
2*(((width - 1)//32)) + 2j[
catT
RN

batch_size
à
2*(((height - 1)//32)) + 2
2*(((width - 1)//32)) + 2jc
getitem_231T
RN

batch_size
Ä
2*(((height - 1)//32)) + 2
2*(((width - 1)//32)) + 2j\
reluT
RN

batch_size
Ä
2*(((height - 1)//32)) + 2
2*(((width - 1)//32)) + 2jc
getitem_234T
RN

batch_size
Ä
2*(((height - 1)//32)) + 2
2*(((width - 1)//32)) + 2j^
relu_1T
RN

batch_size
Ä
2*(((height - 1)//32)) + 2
2*(((width - 1)//32)) + 2jl
upsample_nearest2d_1T
RN

batch_size
Ä
4*(((height - 1)//32)) + 4
4*(((width - 1)//32)) + 4j]
cat_1T
RN

batch_size
∞
4*(((height - 1)//32)) + 4
4*(((width - 1)//32)) + 4jc
getitem_237T
RN

batch_size
Ä
4*(((height - 1)//32)) + 4
4*(((width - 1)//32)) + 4j^
relu_2T
RN

batch_size
Ä
4*(((height - 1)//32)) + 4
4*(((width - 1)//32)) + 4jc
getitem_240T
RN

batch_size
Ä
4*(((height - 1)//32)) + 4
4*(((width - 1)//32)) + 4j^
relu_3T
RN

batch_size
Ä
4*(((height - 1)//32)) + 4
4*(((width - 1)//32)) + 4jl
upsample_nearest2d_2T
RN

batch_size
Ä
8*(((height - 1)//32)) + 8
8*(((width - 1)//32)) + 8j]
cat_2T
RN

batch_size
†
8*(((height - 1)//32)) + 8
8*(((width - 1)//32)) + 8jb
getitem_243S
QM

batch_size
@
8*(((height - 1)//32)) + 8
8*(((width - 1)//32)) + 8j]
relu_4S
QM

batch_size
@
8*(((height - 1)//32)) + 8
8*(((width - 1)//32)) + 8jb
getitem_246S
QM

batch_size
@
8*(((height - 1)//32)) + 8
8*(((width - 1)//32)) + 8j]
relu_5S
QM

batch_size
@
8*(((height - 1)//32)) + 8
8*(((width - 1)//32)) + 8jo
upsample_nearest2d_3W
UQ

batch_size
@
16*(((height - 1)//32)) + 16
16*(((width - 1)//32)) + 16j`
cat_3W
UQ

batch_size
h
16*(((height - 1)//32)) + 16
16*(((width - 1)//32)) + 16jf
getitem_249W
UQ

batch_size
 
16*(((height - 1)//32)) + 16
16*(((width - 1)//32)) + 16ja
relu_6W
UQ

batch_size
 
16*(((height - 1)//32)) + 16
16*(((width - 1)//32)) + 16jf
getitem_252W
UQ

batch_size
 
16*(((height - 1)//32)) + 16
16*(((width - 1)//32)) + 16ja
relu_7W
UQ

batch_size
 
16*(((height - 1)//32)) + 16
16*(((width - 1)//32)) + 16jo
upsample_nearest2d_4W
UQ

batch_size
 
32*(((height - 1)//32)) + 32
32*(((width - 1)//32)) + 32jf
getitem_255W
UQ

batch_size

32*(((height - 1)//32)) + 32
32*(((width - 1)//32)) + 32ja
relu_8W
UQ

batch_size

32*(((height - 1)//32)) + 32
32*(((width - 1)//32)) + 32jf
getitem_258W
UQ

batch_size

32*(((height - 1)//32)) + 32
32*(((width - 1)//32)) + 32ja
relu_9W
UQ

batch_size

32*(((height - 1)//32)) + 32
32*(((width - 1)//32)) + 32ÇÜÉ
0pkg.torch.export.ExportedProgram.graph_signature–Ç
# inputs
p_encoder_stages_0_0_weight: PARAMETER target='encoder.stages.0.0.weight'
p_encoder_stages_0_1_weight: PARAMETER target='encoder.stages.0.1.weight'
p_encoder_stages_0_1_bias: PARAMETER target='encoder.stages.0.1.bias'
p_encoder_stages_1_0_block_0_0_weight: PARAMETER target='encoder.stages.1.0.block.0.0.weight'
p_encoder_stages_1_0_block_0_1_weight: PARAMETER target='encoder.stages.1.0.block.0.1.weight'
p_encoder_stages_1_0_block_0_1_bias: PARAMETER target='encoder.stages.1.0.block.0.1.bias'
p_encoder_stages_1_0_block_1_fc1_weight: PARAMETER target='encoder.stages.1.0.block.1.fc1.weight'
p_encoder_stages_1_0_block_1_fc1_bias: PARAMETER target='encoder.stages.1.0.block.1.fc1.bias'
p_encoder_stages_1_0_block_1_fc2_weight: PARAMETER target='encoder.stages.1.0.block.1.fc2.weight'
p_encoder_stages_1_0_block_1_fc2_bias: PARAMETER target='encoder.stages.1.0.block.1.fc2.bias'
p_encoder_stages_1_0_block_2_0_weight: PARAMETER target='encoder.stages.1.0.block.2.0.weight'
p_encoder_stages_1_0_block_2_1_weight: PARAMETER target='encoder.stages.1.0.block.2.1.weight'
p_encoder_stages_1_0_block_2_1_bias: PARAMETER target='encoder.stages.1.0.block.2.1.bias'
p_encoder_stages_1_1_block_0_0_weight: PARAMETER target='encoder.stages.1.1.block.0.0.weight'
p_encoder_stages_1_1_block_0_1_weight: PARAMETER target='encoder.stages.1.1.block.0.1.weight'
p_encoder_stages_1_1_block_0_1_bias: PARAMETER target='encoder.stages.1.1.block.0.1.bias'
p_encoder_stages_1_1_block_1_fc1_weight: PARAMETER target='encoder.stages.1.1.block.1.fc1.weight'
p_encoder_stages_1_1_block_1_fc1_bias: PARAMETER target='encoder.stages.1.1.block.1.fc1.bias'
p_encoder_stages_1_1_block_1_fc2_weight: PARAMETER target='encoder.stages.1.1.block.1.fc2.weight'
p_encoder_stages_1_1_block_1_fc2_bias: PARAMETER target='encoder.stages.1.1.block.1.fc2.bias'
p_encoder_stages_1_1_block_2_0_weight: PARAMETER target='encoder.stages.1.1.block.2.0.weight'
p_encoder_stages_1_1_block_2_1_weight: PARAMETER target='encoder.stages.1.1.block.2.1.weight'
p_encoder_stages_1_1_block_2_1_bias: PARAMETER target='encoder.stages.1.1.block.2.1.bias'
p_encoder_stages_2_0_block_0_0_weight: PARAMETER target='encoder.stages.2.0.block.0.0.weight'
p_encoder_stages_2_0_block_0_1_weight: PARAMETER target='encoder.stages.2.0.block.0.1.weight'
p_encoder_stages_2_0_block_0_1_bias: PARAMETER target='encoder.stages.2.0.block.0.1.bias'
p_encoder_stages_2_0_block_1_0_weight: PARAMETER target='encoder.stages.2.0.block.1.0.weight'
p_encoder_stages_2_0_block_1_1_weight: PARAMETER target='encoder.stages.2.0.block.1.1.weight'
p_encoder_stages_2_0_block_1_1_bias: PARAMETER target='encoder.stages.2.0.block.1.1.bias'
p_encoder_stages_2_0_block_2_fc1_weight: PARAMETER target='encoder.stages.2.0.block.2.fc1.weight'
p_encoder_stages_2_0_block_2_fc1_bias: PARAMETER target='encoder.stages.2.0.block.2.fc1.bias'
p_encoder_stages_2_0_block_2_fc2_weight: PARAMETER target='encoder.stages.2.0.block.2.fc2.weight'
p_encoder_stages_2_0_block_2_fc2_bias: PARAMETER target='encoder.stages.2.0.block.2.fc2.bias'
p_encoder_stages_2_0_block_3_0_weight: PARAMETER target='encoder.stages.2.0.block.3.0.weight'
p_encoder_stages_2_0_block_3_1_weight: PARAMETER target='encoder.stages.2.0.block.3.1.weight'
p_encoder_stages_2_0_block_3_1_bias: PARAMETER target='encoder.stages.2.0.block.3.1.bias'
p_encoder_stages_2_1_block_0_0_weight: PARAMETER target='encoder.stages.2.1.block.0.0.weight'
p_encoder_stages_2_1_block_0_1_weight: PARAMETER target='encoder.stages.2.1.block.0.1.weight'
p_encoder_stages_2_1_block_0_1_bias: PARAMETER target='encoder.stages.2.1.block.0.1.bias'
p_encoder_stages_2_1_block_1_0_weight: PARAMETER target='encoder.stages.2.1.block.1.0.weight'
p_encoder_stages_2_1_block_1_1_weight: PARAMETER target='encoder.stages.2.1.block.1.1.weight'
p_encoder_stages_2_1_block_1_1_bias: PARAMETER target='encoder.stages.2.1.block.1.1.bias'
p_encoder_stages_2_1_block_2_fc1_weight: PARAMETER target='encoder.stages.2.1.block.2.fc1.weight'
p_encoder_stages_2_1_block_2_fc1_bias: PARAMETER target='encoder.stages.2.1.block.2.fc1.bias'
p_encoder_stages_2_1_block_2_fc2_weight: PARAMETER target='encoder.stages.2.1.block.2.fc2.weight'
p_encoder_stages_2_1_block_2_fc2_bias: PARAMETER target='encoder.stages.2.1.block.2.fc2.bias'
p_encoder_stages_2_1_block_3_0_weight: PARAMETER target='encoder.stages.2.1.block.3.0.weight'
p_encoder_stages_2_1_block_3_1_weight: PARAMETER target='encoder.stages.2.1.block.3.1.weight'
p_encoder_stages_2_1_block_3_1_bias: PARAMETER target='encoder.stages.2.1.block.3.1.bias'
p_encoder_stages_2_2_block_0_0_weight: PARAMETER target='encoder.stages.2.2.block.0.0.weight'
p_encoder_stages_2_2_block_0_1_weight: PARAMETER target='encoder.stages.2.2.block.0.1.weight'
p_encoder_stages_2_2_block_0_1_bias: PARAMETER target='encoder.stages.2.2.block.0.1.bias'
p_encoder_stages_2_2_block_1_0_weight: PARAMETER target='encoder.stages.2.2.block.1.0.weight'
p_encoder_stages_2_2_block_1_1_weight: PARAMETER target='encoder.stages.2.2.block.1.1.weight'
p_encoder_stages_2_2_block_1_1_bias: PARAMETER target='encoder.stages.2.2.block.1.1.bias'
p_encoder_stages_2_2_block_2_fc1_weight: PARAMETER target='encoder.stages.2.2.block.2.fc1.weight'
p_encoder_stages_2_2_block_2_fc1_bias: PARAMETER target='encoder.stages.2.2.block.2.fc1.bias'
p_encoder_stages_2_2_block_2_fc2_weight: PARAMETER target='encoder.stages.2.2.block.2.fc2.weight'
p_encoder_stages_2_2_block_2_fc2_bias: PARAMETER target='encoder.stages.2.2.block.2.fc2.bias'
p_encoder_stages_2_2_block_3_0_weight: PARAMETER target='encoder.stages.2.2.block.3.0.weight'
p_encoder_stages_2_2_block_3_1_weight: PARAMETER target='encoder.stages.2.2.block.3.1.weight'
p_encoder_stages_2_2_block_3_1_bias: PARAMETER target='encoder.stages.2.2.block.3.1.bias'
p_encoder_stages_3_0_block_0_0_weight: PARAMETER target='encoder.stages.3.0.block.0.0.weight'
p_encoder_stages_3_0_block_0_1_weight: PARAMETER target='encoder.stages.3.0.block.0.1.weight'
p_encoder_stages_3_0_block_0_1_bias: PARAMETER target='encoder.stages.3.0.block.0.1.bias'
p_encoder_stages_3_0_block_1_0_weight: PARAMETER target='encoder.stages.3.0.block.1.0.weight'
p_encoder_stages_3_0_block_1_1_weight: PARAMETER target='encoder.stages.3.0.block.1.1.weight'
p_encoder_stages_3_0_block_1_1_bias: PARAMETER target='encoder.stages.3.0.block.1.1.bias'
p_encoder_stages_3_0_block_2_fc1_weight: PARAMETER target='encoder.stages.3.0.block.2.fc1.weight'
p_encoder_stages_3_0_block_2_fc1_bias: PARAMETER target='encoder.stages.3.0.block.2.fc1.bias'
p_encoder_stages_3_0_block_2_fc2_weight: PARAMETER target='encoder.stages.3.0.block.2.fc2.weight'
p_encoder_stages_3_0_block_2_fc2_bias: PARAMETER target='encoder.stages.3.0.block.2.fc2.bias'
p_encoder_stages_3_0_block_3_0_weight: PARAMETER target='encoder.stages.3.0.block.3.0.weight'
p_encoder_stages_3_0_block_3_1_weight: PARAMETER target='encoder.stages.3.0.block.3.1.weight'
p_encoder_stages_3_0_block_3_1_bias: PARAMETER target='encoder.stages.3.0.block.3.1.bias'
p_encoder_stages_3_1_block_0_0_weight: PARAMETER target='encoder.stages.3.1.block.0.0.weight'
p_encoder_stages_3_1_block_0_1_weight: PARAMETER target='encoder.stages.3.1.block.0.1.weight'
p_encoder_stages_3_1_block_0_1_bias: PARAMETER target='encoder.stages.3.1.block.0.1.bias'
p_encoder_stages_3_1_block_1_0_weight: PARAMETER target='encoder.stages.3.1.block.1.0.weight'
p_encoder_stages_3_1_block_1_1_weight: PARAMETER target='encoder.stages.3.1.block.1.1.weight'
p_encoder_stages_3_1_block_1_1_bias: PARAMETER target='encoder.stages.3.1.block.1.1.bias'
p_encoder_stages_3_1_block_2_fc1_weight: PARAMETER target='encoder.stages.3.1.block.2.fc1.weight'
p_encoder_stages_3_1_block_2_fc1_bias: PARAMETER target='encoder.stages.3.1.block.2.fc1.bias'
p_encoder_stages_3_1_block_2_fc2_weight: PARAMETER target='encoder.stages.3.1.block.2.fc2.weight'
p_encoder_stages_3_1_block_2_fc2_bias: PARAMETER target='encoder.stages.3.1.block.2.fc2.bias'
p_encoder_stages_3_1_block_3_0_weight: PARAMETER target='encoder.stages.3.1.block.3.0.weight'
p_encoder_stages_3_1_block_3_1_weight: PARAMETER target='encoder.stages.3.1.block.3.1.weight'
p_encoder_stages_3_1_block_3_1_bias: PARAMETER target='encoder.stages.3.1.block.3.1.bias'
p_encoder_stages_3_2_block_0_0_weight: PARAMETER target='encoder.stages.3.2.block.0.0.weight'
p_encoder_stages_3_2_block_0_1_weight: PARAMETER target='encoder.stages.3.2.block.0.1.weight'
p_encoder_stages_3_2_block_0_1_bias: PARAMETER target='encoder.stages.3.2.block.0.1.bias'
p_encoder_stages_3_2_block_1_0_weight: PARAMETER target='encoder.stages.3.2.block.1.0.weight'
p_encoder_stages_3_2_block_1_1_weight: PARAMETER target='encoder.stages.3.2.block.1.1.weight'
p_encoder_stages_3_2_block_1_1_bias: PARAMETER target='encoder.stages.3.2.block.1.1.bias'
p_encoder_stages_3_2_block_2_fc1_weight: PARAMETER target='encoder.stages.3.2.block.2.fc1.weight'
p_encoder_stages_3_2_block_2_fc1_bias: PARAMETER target='encoder.stages.3.2.block.2.fc1.bias'
p_encoder_stages_3_2_block_2_fc2_weight: PARAMETER target='encoder.stages.3.2.block.2.fc2.weight'
p_encoder_stages_3_2_block_2_fc2_bias: PARAMETER target='encoder.stages.3.2.block.2.fc2.bias'
p_encoder_stages_3_2_block_3_0_weight: PARAMETER target='encoder.stages.3.2.block.3.0.weight'
p_encoder_stages_3_2_block_3_1_weight: PARAMETER target='encoder.stages.3.2.block.3.1.weight'
p_encoder_stages_3_2_block_3_1_bias: PARAMETER target='encoder.stages.3.2.block.3.1.bias'
p_encoder_stages_4_0_block_0_0_weight: PARAMETER target='encoder.stages.4.0.block.0.0.weight'
p_encoder_stages_4_0_block_0_1_weight: PARAMETER target='encoder.stages.4.0.block.0.1.weight'
p_encoder_stages_4_0_block_0_1_bias: PARAMETER target='encoder.stages.4.0.block.0.1.bias'
p_encoder_stages_4_0_block_1_0_weight: PARAMETER target='encoder.stages.4.0.block.1.0.weight'
p_encoder_stages_4_0_block_1_1_weight: PARAMETER target='encoder.stages.4.0.block.1.1.weight'
p_encoder_stages_4_0_block_1_1_bias: PARAMETER target='encoder.stages.4.0.block.1.1.bias'
p_encoder_stages_4_0_block_2_fc1_weight: PARAMETER target='encoder.stages.4.0.block.2.fc1.weight'
p_encoder_stages_4_0_block_2_fc1_bias: PARAMETER target='encoder.stages.4.0.block.2.fc1.bias'
p_encoder_stages_4_0_block_2_fc2_weight: PARAMETER target='encoder.stages.4.0.block.2.fc2.weight'
p_encoder_stages_4_0_block_2_fc2_bias: PARAMETER target='encoder.stages.4.0.block.2.fc2.bias'
p_encoder_stages_4_0_block_3_0_weight: PARAMETER target='encoder.stages.4.0.block.3.0.weight'
p_encoder_stages_4_0_block_3_1_weight: PARAMETER target='encoder.stages.4.0.block.3.1.weight'
p_encoder_stages_4_0_block_3_1_bias: PARAMETER target='encoder.stages.4.0.block.3.1.bias'
p_encoder_stages_4_1_block_0_0_weight: PARAMETER target='encoder.stages.4.1.block.0.0.weight'
p_encoder_stages_4_1_block_0_1_weight: PARAMETER target='encoder.stages.4.1.block.0.1.weight'
p_encoder_stages_4_1_block_0_1_bias: PARAMETER target='encoder.stages.4.1.block.0.1.bias'
p_encoder_stages_4_1_block_1_0_weight: PARAMETER target='encoder.stages.4.1.block.1.0.weight'
p_encoder_stages_4_1_block_1_1_weight: PARAMETER target='encoder.stages.4.1.block.1.1.weight'
p_encoder_stages_4_1_block_1_1_bias: PARAMETER target='encoder.stages.4.1.block.1.1.bias'
p_encoder_stages_4_1_block_2_fc1_weight: PARAMETER target='encoder.stages.4.1.block.2.fc1.weight'
p_encoder_stages_4_1_block_2_fc1_bias: PARAMETER target='encoder.stages.4.1.block.2.fc1.bias'
p_encoder_stages_4_1_block_2_fc2_weight: PARAMETER target='encoder.stages.4.1.block.2.fc2.weight'
p_encoder_stages_4_1_block_2_fc2_bias: PARAMETER target='encoder.stages.4.1.block.2.fc2.bias'
p_encoder_stages_4_1_block_3_0_weight: PARAMETER target='encoder.stages.4.1.block.3.0.weight'
p_encoder_stages_4_1_block_3_1_weight: PARAMETER target='encoder.stages.4.1.block.3.1.weight'
p_encoder_stages_4_1_block_3_1_bias: PARAMETER target='encoder.stages.4.1.block.3.1.bias'
p_encoder_stages_4_2_block_0_0_weight: PARAMETER target='encoder.stages.4.2.block.0.0.weight'
p_encoder_stages_4_2_block_0_1_weight: PARAMETER target='encoder.stages.4.2.block.0.1.weight'
p_encoder_stages_4_2_block_0_1_bias: PARAMETER target='encoder.stages.4.2.block.0.1.bias'
p_encoder_stages_4_2_block_1_0_weight: PARAMETER target='encoder.stages.4.2.block.1.0.weight'
p_encoder_stages_4_2_block_1_1_weight: PARAMETER target='encoder.stages.4.2.block.1.1.weight'
p_encoder_stages_4_2_block_1_1_bias: PARAMETER target='encoder.stages.4.2.block.1.1.bias'
p_encoder_stages_4_2_block_2_fc1_weight: PARAMETER target='encoder.stages.4.2.block.2.fc1.weight'
p_encoder_stages_4_2_block_2_fc1_bias: PARAMETER target='encoder.stages.4.2.block.2.fc1.bias'
p_encoder_stages_4_2_block_2_fc2_weight: PARAMETER target='encoder.stages.4.2.block.2.fc2.weight'
p_encoder_stages_4_2_block_2_fc2_bias: PARAMETER target='encoder.stages.4.2.block.2.fc2.bias'
p_encoder_stages_4_2_block_3_0_weight: PARAMETER target='encoder.stages.4.2.block.3.0.weight'
p_encoder_stages_4_2_block_3_1_weight: PARAMETER target='encoder.stages.4.2.block.3.1.weight'
p_encoder_stages_4_2_block_3_1_bias: PARAMETER target='encoder.stages.4.2.block.3.1.bias'
p_encoder_stages_4_3_block_0_0_weight: PARAMETER target='encoder.stages.4.3.block.0.0.weight'
p_encoder_stages_4_3_block_0_1_weight: PARAMETER target='encoder.stages.4.3.block.0.1.weight'
p_encoder_stages_4_3_block_0_1_bias: PARAMETER target='encoder.stages.4.3.block.0.1.bias'
p_encoder_stages_4_3_block_1_0_weight: PARAMETER target='encoder.stages.4.3.block.1.0.weight'
p_encoder_stages_4_3_block_1_1_weight: PARAMETER target='encoder.stages.4.3.block.1.1.weight'
p_encoder_stages_4_3_block_1_1_bias: PARAMETER target='encoder.stages.4.3.block.1.1.bias'
p_encoder_stages_4_3_block_2_fc1_weight: PARAMETER target='encoder.stages.4.3.block.2.fc1.weight'
p_encoder_stages_4_3_block_2_fc1_bias: PARAMETER target='encoder.stages.4.3.block.2.fc1.bias'
p_encoder_stages_4_3_block_2_fc2_weight: PARAMETER target='encoder.stages.4.3.block.2.fc2.weight'
p_encoder_stages_4_3_block_2_fc2_bias: PARAMETER target='encoder.stages.4.3.block.2.fc2.bias'
p_encoder_stages_4_3_block_3_0_weight: PARAMETER target='encoder.stages.4.3.block.3.0.weight'
p_encoder_stages_4_3_block_3_1_weight: PARAMETER target='encoder.stages.4.3.block.3.1.weight'
p_encoder_stages_4_3_block_3_1_bias: PARAMETER target='encoder.stages.4.3.block.3.1.bias'
p_encoder_stages_4_4_block_0_0_weight: PARAMETER target='encoder.stages.4.4.block.0.0.weight'
p_encoder_stages_4_4_block_0_1_weight: PARAMETER target='encoder.stages.4.4.block.0.1.weight'
p_encoder_stages_4_4_block_0_1_bias: PARAMETER target='encoder.stages.4.4.block.0.1.bias'
p_encoder_stages_4_4_block_1_0_weight: PARAMETER target='encoder.stages.4.4.block.1.0.weight'
p_encoder_stages_4_4_block_1_1_weight: PARAMETER target='encoder.stages.4.4.block.1.1.weight'
p_encoder_stages_4_4_block_1_1_bias: PARAMETER target='encoder.stages.4.4.block.1.1.bias'
p_encoder_stages_4_4_block_2_fc1_weight: PARAMETER target='encoder.stages.4.4.block.2.fc1.weight'
p_encoder_stages_4_4_block_2_fc1_bias: PARAMETER target='encoder.stages.4.4.block.2.fc1.bias'
p_encoder_stages_4_4_block_2_fc2_weight: PARAMETER target='encoder.stages.4.4.block.2.fc2.weight'
p_encoder_stages_4_4_block_2_fc2_bias: PARAMETER target='encoder.stages.4.4.block.2.fc2.bias'
p_encoder_stages_4_4_block_3_0_weight: PARAMETER target='encoder.stages.4.4.block.3.0.weight'
p_encoder_stages_4_4_block_3_1_weight: PARAMETER target='encoder.stages.4.4.block.3.1.weight'
p_encoder_stages_4_4_block_3_1_bias: PARAMETER target='encoder.stages.4.4.block.3.1.bias'
p_encoder_stages_5_0_block_0_0_weight: PARAMETER target='encoder.stages.5.0.block.0.0.weight'
p_encoder_stages_5_0_block_0_1_weight: PARAMETER target='encoder.stages.5.0.block.0.1.weight'
p_encoder_stages_5_0_block_0_1_bias: PARAMETER target='encoder.stages.5.0.block.0.1.bias'
p_encoder_stages_5_0_block_1_0_weight: PARAMETER target='encoder.stages.5.0.block.1.0.weight'
p_encoder_stages_5_0_block_1_1_weight: PARAMETER target='encoder.stages.5.0.block.1.1.weight'
p_encoder_stages_5_0_block_1_1_bias: PARAMETER target='encoder.stages.5.0.block.1.1.bias'
p_encoder_stages_5_0_block_2_fc1_weight: PARAMETER target='encoder.stages.5.0.block.2.fc1.weight'
p_encoder_stages_5_0_block_2_fc1_bias: PARAMETER target='encoder.stages.5.0.block.2.fc1.bias'
p_encoder_stages_5_0_block_2_fc2_weight: PARAMETER target='encoder.stages.5.0.block.2.fc2.weight'
p_encoder_stages_5_0_block_2_fc2_bias: PARAMETER target='encoder.stages.5.0.block.2.fc2.bias'
p_encoder_stages_5_0_block_3_0_weight: PARAMETER target='encoder.stages.5.0.block.3.0.weight'
p_encoder_stages_5_0_block_3_1_weight: PARAMETER target='encoder.stages.5.0.block.3.1.weight'
p_encoder_stages_5_0_block_3_1_bias: PARAMETER target='encoder.stages.5.0.block.3.1.bias'
p_encoder_stages_5_1_block_0_0_weight: PARAMETER target='encoder.stages.5.1.block.0.0.weight'
p_encoder_stages_5_1_block_0_1_weight: PARAMETER target='encoder.stages.5.1.block.0.1.weight'
p_encoder_stages_5_1_block_0_1_bias: PARAMETER target='encoder.stages.5.1.block.0.1.bias'
p_encoder_stages_5_1_block_1_0_weight: PARAMETER target='encoder.stages.5.1.block.1.0.weight'
p_encoder_stages_5_1_block_1_1_weight: PARAMETER target='encoder.stages.5.1.block.1.1.weight'
p_encoder_stages_5_1_block_1_1_bias: PARAMETER target='encoder.stages.5.1.block.1.1.bias'
p_encoder_stages_5_1_block_2_fc1_weight: PARAMETER target='encoder.stages.5.1.block.2.fc1.weight'
p_encoder_stages_5_1_block_2_fc1_bias: PARAMETER target='encoder.stages.5.1.block.2.fc1.bias'
p_encoder_stages_5_1_block_2_fc2_weight: PARAMETER target='encoder.stages.5.1.block.2.fc2.weight'
p_encoder_stages_5_1_block_2_fc2_bias: PARAMETER target='encoder.stages.5.1.block.2.fc2.bias'
p_encoder_stages_5_1_block_3_0_weight: PARAMETER target='encoder.stages.5.1.block.3.0.weight'
p_encoder_stages_5_1_block_3_1_weight: PARAMETER target='encoder.stages.5.1.block.3.1.weight'
p_encoder_stages_5_1_block_3_1_bias: PARAMETER target='encoder.stages.5.1.block.3.1.bias'
p_encoder_stages_5_2_block_0_0_weight: PARAMETER target='encoder.stages.5.2.block.0.0.weight'
p_encoder_stages_5_2_block_0_1_weight: PARAMETER target='encoder.stages.5.2.block.0.1.weight'
p_encoder_stages_5_2_block_0_1_bias: PARAMETER target='encoder.stages.5.2.block.0.1.bias'
p_encoder_stages_5_2_block_1_0_weight: PARAMETER target='encoder.stages.5.2.block.1.0.weight'
p_encoder_stages_5_2_block_1_1_weight: PARAMETER target='encoder.stages.5.2.block.1.1.weight'
p_encoder_stages_5_2_block_1_1_bias: PARAMETER target='encoder.stages.5.2.block.1.1.bias'
p_encoder_stages_5_2_block_2_fc1_weight: PARAMETER target='encoder.stages.5.2.block.2.fc1.weight'
p_encoder_stages_5_2_block_2_fc1_bias: PARAMETER target='encoder.stages.5.2.block.2.fc1.bias'
p_encoder_stages_5_2_block_2_fc2_weight: PARAMETER target='encoder.stages.5.2.block.2.fc2.weight'
p_encoder_stages_5_2_block_2_fc2_bias: PARAMETER target='encoder.stages.5.2.block.2.fc2.bias'
p_encoder_stages_5_2_block_3_0_weight: PARAMETER target='encoder.stages.5.2.block.3.0.weight'
p_encoder_stages_5_2_block_3_1_weight: PARAMETER target='encoder.stages.5.2.block.3.1.weight'
p_encoder_stages_5_2_block_3_1_bias: PARAMETER target='encoder.stages.5.2.block.3.1.bias'
p_encoder_stages_5_3_block_0_0_weight: PARAMETER target='encoder.stages.5.3.block.0.0.weight'
p_encoder_stages_5_3_block_0_1_weight: PARAMETER target='encoder.stages.5.3.block.0.1.weight'
p_encoder_stages_5_3_block_0_1_bias: PARAMETER target='encoder.stages.5.3.block.0.1.bias'
p_encoder_stages_5_3_block_1_0_weight: PARAMETER target='encoder.stages.5.3.block.1.0.weight'
p_encoder_stages_5_3_block_1_1_weight: PARAMETER target='encoder.stages.5.3.block.1.1.weight'
p_encoder_stages_5_3_block_1_1_bias: PARAMETER target='encoder.stages.5.3.block.1.1.bias'
p_encoder_stages_5_3_block_2_fc1_weight: PARAMETER target='encoder.stages.5.3.block.2.fc1.weight'
p_encoder_stages_5_3_block_2_fc1_bias: PARAMETER target='encoder.stages.5.3.block.2.fc1.bias'
p_encoder_stages_5_3_block_2_fc2_weight: PARAMETER target='encoder.stages.5.3.block.2.fc2.weight'
p_encoder_stages_5_3_block_2_fc2_bias: PARAMETER target='encoder.stages.5.3.block.2.fc2.bias'
p_encoder_stages_5_3_block_3_0_weight: PARAMETER target='encoder.stages.5.3.block.3.0.weight'
p_encoder_stages_5_3_block_3_1_weight: PARAMETER target='encoder.stages.5.3.block.3.1.weight'
p_encoder_stages_5_3_block_3_1_bias: PARAMETER target='encoder.stages.5.3.block.3.1.bias'
p_encoder_stages_5_4_block_0_0_weight: PARAMETER target='encoder.stages.5.4.block.0.0.weight'
p_encoder_stages_5_4_block_0_1_weight: PARAMETER target='encoder.stages.5.4.block.0.1.weight'
p_encoder_stages_5_4_block_0_1_bias: PARAMETER target='encoder.stages.5.4.block.0.1.bias'
p_encoder_stages_5_4_block_1_0_weight: PARAMETER target='encoder.stages.5.4.block.1.0.weight'
p_encoder_stages_5_4_block_1_1_weight: PARAMETER target='encoder.stages.5.4.block.1.1.weight'
p_encoder_stages_5_4_block_1_1_bias: PARAMETER target='encoder.stages.5.4.block.1.1.bias'
p_encoder_stages_5_4_block_2_fc1_weight: PARAMETER target='encoder.stages.5.4.block.2.fc1.weight'
p_encoder_stages_5_4_block_2_fc1_bias: PARAMETER target='encoder.stages.5.4.block.2.fc1.bias'
p_encoder_stages_5_4_block_2_fc2_weight: PARAMETER target='encoder.stages.5.4.block.2.fc2.weight'
p_encoder_stages_5_4_block_2_fc2_bias: PARAMETER target='encoder.stages.5.4.block.2.fc2.bias'
p_encoder_stages_5_4_block_3_0_weight: PARAMETER target='encoder.stages.5.4.block.3.0.weight'
p_encoder_stages_5_4_block_3_1_weight: PARAMETER target='encoder.stages.5.4.block.3.1.weight'
p_encoder_stages_5_4_block_3_1_bias: PARAMETER target='encoder.stages.5.4.block.3.1.bias'
p_encoder_stages_6_0_block_0_0_weight: PARAMETER target='encoder.stages.6.0.block.0.0.weight'
p_encoder_stages_6_0_block_0_1_weight: PARAMETER target='encoder.stages.6.0.block.0.1.weight'
p_encoder_stages_6_0_block_0_1_bias: PARAMETER target='encoder.stages.6.0.block.0.1.bias'
p_encoder_stages_6_0_block_1_0_weight: PARAMETER target='encoder.stages.6.0.block.1.0.weight'
p_encoder_stages_6_0_block_1_1_weight: PARAMETER target='encoder.stages.6.0.block.1.1.weight'
p_encoder_stages_6_0_block_1_1_bias: PARAMETER target='encoder.stages.6.0.block.1.1.bias'
p_encoder_stages_6_0_block_2_fc1_weight: PARAMETER target='encoder.stages.6.0.block.2.fc1.weight'
p_encoder_stages_6_0_block_2_fc1_bias: PARAMETER target='encoder.stages.6.0.block.2.fc1.bias'
p_encoder_stages_6_0_block_2_fc2_weight: PARAMETER target='encoder.stages.6.0.block.2.fc2.weight'
p_encoder_stages_6_0_block_2_fc2_bias: PARAMETER target='encoder.stages.6.0.block.2.fc2.bias'
p_encoder_stages_6_0_block_3_0_weight: PARAMETER target='encoder.stages.6.0.block.3.0.weight'
p_encoder_stages_6_0_block_3_1_weight: PARAMETER target='encoder.stages.6.0.block.3.1.weight'
p_encoder_stages_6_0_block_3_1_bias: PARAMETER target='encoder.stages.6.0.block.3.1.bias'
p_encoder_stages_6_1_block_0_0_weight: PARAMETER target='encoder.stages.6.1.block.0.0.weight'
p_encoder_stages_6_1_block_0_1_weight: PARAMETER target='encoder.stages.6.1.block.0.1.weight'
p_encoder_stages_6_1_block_0_1_bias: PARAMETER target='encoder.stages.6.1.block.0.1.bias'
p_encoder_stages_6_1_block_1_0_weight: PARAMETER target='encoder.stages.6.1.block.1.0.weight'
p_encoder_stages_6_1_block_1_1_weight: PARAMETER target='encoder.stages.6.1.block.1.1.weight'
p_encoder_stages_6_1_block_1_1_bias: PARAMETER target='encoder.stages.6.1.block.1.1.bias'
p_encoder_stages_6_1_block_2_fc1_weight: PARAMETER target='encoder.stages.6.1.block.2.fc1.weight'
p_encoder_stages_6_1_block_2_fc1_bias: PARAMETER target='encoder.stages.6.1.block.2.fc1.bias'
p_encoder_stages_6_1_block_2_fc2_weight: PARAMETER target='encoder.stages.6.1.block.2.fc2.weight'
p_encoder_stages_6_1_block_2_fc2_bias: PARAMETER target='encoder.stages.6.1.block.2.fc2.bias'
p_encoder_stages_6_1_block_3_0_weight: PARAMETER target='encoder.stages.6.1.block.3.0.weight'
p_encoder_stages_6_1_block_3_1_weight: PARAMETER target='encoder.stages.6.1.block.3.1.weight'
p_encoder_stages_6_1_block_3_1_bias: PARAMETER target='encoder.stages.6.1.block.3.1.bias'
p_encoder_stages_6_2_block_0_0_weight: PARAMETER target='encoder.stages.6.2.block.0.0.weight'
p_encoder_stages_6_2_block_0_1_weight: PARAMETER target='encoder.stages.6.2.block.0.1.weight'
p_encoder_stages_6_2_block_0_1_bias: PARAMETER target='encoder.stages.6.2.block.0.1.bias'
p_encoder_stages_6_2_block_1_0_weight: PARAMETER target='encoder.stages.6.2.block.1.0.weight'
p_encoder_stages_6_2_block_1_1_weight: PARAMETER target='encoder.stages.6.2.block.1.1.weight'
p_encoder_stages_6_2_block_1_1_bias: PARAMETER target='encoder.stages.6.2.block.1.1.bias'
p_encoder_stages_6_2_block_2_fc1_weight: PARAMETER target='encoder.stages.6.2.block.2.fc1.weight'
p_encoder_stages_6_2_block_2_fc1_bias: PARAMETER target='encoder.stages.6.2.block.2.fc1.bias'
p_encoder_stages_6_2_block_2_fc2_weight: PARAMETER target='encoder.stages.6.2.block.2.fc2.weight'
p_encoder_stages_6_2_block_2_fc2_bias: PARAMETER target='encoder.stages.6.2.block.2.fc2.bias'
p_encoder_stages_6_2_block_3_0_weight: PARAMETER target='encoder.stages.6.2.block.3.0.weight'
p_encoder_stages_6_2_block_3_1_weight: PARAMETER target='encoder.stages.6.2.block.3.1.weight'
p_encoder_stages_6_2_block_3_1_bias: PARAMETER target='encoder.stages.6.2.block.3.1.bias'
p_encoder_stages_6_3_block_0_0_weight: PARAMETER target='encoder.stages.6.3.block.0.0.weight'
p_encoder_stages_6_3_block_0_1_weight: PARAMETER target='encoder.stages.6.3.block.0.1.weight'
p_encoder_stages_6_3_block_0_1_bias: PARAMETER target='encoder.stages.6.3.block.0.1.bias'
p_encoder_stages_6_3_block_1_0_weight: PARAMETER target='encoder.stages.6.3.block.1.0.weight'
p_encoder_stages_6_3_block_1_1_weight: PARAMETER target='encoder.stages.6.3.block.1.1.weight'
p_encoder_stages_6_3_block_1_1_bias: PARAMETER target='encoder.stages.6.3.block.1.1.bias'
p_encoder_stages_6_3_block_2_fc1_weight: PARAMETER target='encoder.stages.6.3.block.2.fc1.weight'
p_encoder_stages_6_3_block_2_fc1_bias: PARAMETER target='encoder.stages.6.3.block.2.fc1.bias'
p_encoder_stages_6_3_block_2_fc2_weight: PARAMETER target='encoder.stages.6.3.block.2.fc2.weight'
p_encoder_stages_6_3_block_2_fc2_bias: PARAMETER target='encoder.stages.6.3.block.2.fc2.bias'
p_encoder_stages_6_3_block_3_0_weight: PARAMETER target='encoder.stages.6.3.block.3.0.weight'
p_encoder_stages_6_3_block_3_1_weight: PARAMETER target='encoder.stages.6.3.block.3.1.weight'
p_encoder_stages_6_3_block_3_1_bias: PARAMETER target='encoder.stages.6.3.block.3.1.bias'
p_encoder_stages_6_4_block_0_0_weight: PARAMETER target='encoder.stages.6.4.block.0.0.weight'
p_encoder_stages_6_4_block_0_1_weight: PARAMETER target='encoder.stages.6.4.block.0.1.weight'
p_encoder_stages_6_4_block_0_1_bias: PARAMETER target='encoder.stages.6.4.block.0.1.bias'
p_encoder_stages_6_4_block_1_0_weight: PARAMETER target='encoder.stages.6.4.block.1.0.weight'
p_encoder_stages_6_4_block_1_1_weight: PARAMETER target='encoder.stages.6.4.block.1.1.weight'
p_encoder_stages_6_4_block_1_1_bias: PARAMETER target='encoder.stages.6.4.block.1.1.bias'
p_encoder_stages_6_4_block_2_fc1_weight: PARAMETER target='encoder.stages.6.4.block.2.fc1.weight'
p_encoder_stages_6_4_block_2_fc1_bias: PARAMETER target='encoder.stages.6.4.block.2.fc1.bias'
p_encoder_stages_6_4_block_2_fc2_weight: PARAMETER target='encoder.stages.6.4.block.2.fc2.weight'
p_encoder_stages_6_4_block_2_fc2_bias: PARAMETER target='encoder.stages.6.4.block.2.fc2.bias'
p_encoder_stages_6_4_block_3_0_weight: PARAMETER target='encoder.stages.6.4.block.3.0.weight'
p_encoder_stages_6_4_block_3_1_weight: PARAMETER target='encoder.stages.6.4.block.3.1.weight'
p_encoder_stages_6_4_block_3_1_bias: PARAMETER target='encoder.stages.6.4.block.3.1.bias'
p_encoder_stages_6_5_block_0_0_weight: PARAMETER target='encoder.stages.6.5.block.0.0.weight'
p_encoder_stages_6_5_block_0_1_weight: PARAMETER target='encoder.stages.6.5.block.0.1.weight'
p_encoder_stages_6_5_block_0_1_bias: PARAMETER target='encoder.stages.6.5.block.0.1.bias'
p_encoder_stages_6_5_block_1_0_weight: PARAMETER target='encoder.stages.6.5.block.1.0.weight'
p_encoder_stages_6_5_block_1_1_weight: PARAMETER target='encoder.stages.6.5.block.1.1.weight'
p_encoder_stages_6_5_block_1_1_bias: PARAMETER target='encoder.stages.6.5.block.1.1.bias'
p_encoder_stages_6_5_block_2_fc1_weight: PARAMETER target='encoder.stages.6.5.block.2.fc1.weight'
p_encoder_stages_6_5_block_2_fc1_bias: PARAMETER target='encoder.stages.6.5.block.2.fc1.bias'
p_encoder_stages_6_5_block_2_fc2_weight: PARAMETER target='encoder.stages.6.5.block.2.fc2.weight'
p_encoder_stages_6_5_block_2_fc2_bias: PARAMETER target='encoder.stages.6.5.block.2.fc2.bias'
p_encoder_stages_6_5_block_3_0_weight: PARAMETER target='encoder.stages.6.5.block.3.0.weight'
p_encoder_stages_6_5_block_3_1_weight: PARAMETER target='encoder.stages.6.5.block.3.1.weight'
p_encoder_stages_6_5_block_3_1_bias: PARAMETER target='encoder.stages.6.5.block.3.1.bias'
p_encoder_stages_7_0_block_0_0_weight: PARAMETER target='encoder.stages.7.0.block.0.0.weight'
p_encoder_stages_7_0_block_0_1_weight: PARAMETER target='encoder.stages.7.0.block.0.1.weight'
p_encoder_stages_7_0_block_0_1_bias: PARAMETER target='encoder.stages.7.0.block.0.1.bias'
p_encoder_stages_7_0_block_1_0_weight: PARAMETER target='encoder.stages.7.0.block.1.0.weight'
p_encoder_stages_7_0_block_1_1_weight: PARAMETER target='encoder.stages.7.0.block.1.1.weight'
p_encoder_stages_7_0_block_1_1_bias: PARAMETER target='encoder.stages.7.0.block.1.1.bias'
p_encoder_stages_7_0_block_2_fc1_weight: PARAMETER target='encoder.stages.7.0.block.2.fc1.weight'
p_encoder_stages_7_0_block_2_fc1_bias: PARAMETER target='encoder.stages.7.0.block.2.fc1.bias'
p_encoder_stages_7_0_block_2_fc2_weight: PARAMETER target='encoder.stages.7.0.block.2.fc2.weight'
p_encoder_stages_7_0_block_2_fc2_bias: PARAMETER target='encoder.stages.7.0.block.2.fc2.bias'
p_encoder_stages_7_0_block_3_0_weight: PARAMETER target='encoder.stages.7.0.block.3.0.weight'
p_encoder_stages_7_0_block_3_1_weight: PARAMETER target='encoder.stages.7.0.block.3.1.weight'
p_encoder_stages_7_0_block_3_1_bias: PARAMETER target='encoder.stages.7.0.block.3.1.bias'
p_encoder_stages_7_1_block_0_0_weight: PARAMETER target='encoder.stages.7.1.block.0.0.weight'
p_encoder_stages_7_1_block_0_1_weight: PARAMETER target='encoder.stages.7.1.block.0.1.weight'
p_encoder_stages_7_1_block_0_1_bias: PARAMETER target='encoder.stages.7.1.block.0.1.bias'
p_encoder_stages_7_1_block_1_0_weight: PARAMETER target='encoder.stages.7.1.block.1.0.weight'
p_encoder_stages_7_1_block_1_1_weight: PARAMETER target='encoder.stages.7.1.block.1.1.weight'
p_encoder_stages_7_1_block_1_1_bias: PARAMETER target='encoder.stages.7.1.block.1.1.bias'
p_encoder_stages_7_1_block_2_fc1_weight: PARAMETER target='encoder.stages.7.1.block.2.fc1.weight'
p_encoder_stages_7_1_block_2_fc1_bias: PARAMETER target='encoder.stages.7.1.block.2.fc1.bias'
p_encoder_stages_7_1_block_2_fc2_weight: PARAMETER target='encoder.stages.7.1.block.2.fc2.weight'
p_encoder_stages_7_1_block_2_fc2_bias: PARAMETER target='encoder.stages.7.1.block.2.fc2.bias'
p_encoder_stages_7_1_block_3_0_weight: PARAMETER target='encoder.stages.7.1.block.3.0.weight'
p_encoder_stages_7_1_block_3_1_weight: PARAMETER target='encoder.stages.7.1.block.3.1.weight'
p_encoder_stages_7_1_block_3_1_bias: PARAMETER target='encoder.stages.7.1.block.3.1.bias'
p_decoder_blocks_0_conv1_0_weight: PARAMETER target='decoder.blocks.0.conv1.0.weight'
p_decoder_blocks_0_conv1_1_weight: PARAMETER target='decoder.blocks.0.conv1.1.weight'
p_decoder_blocks_0_conv1_1_bias: PARAMETER target='decoder.blocks.0.conv1.1.bias'
p_decoder_blocks_0_conv2_0_weight: PARAMETER target='decoder.blocks.0.conv2.0.weight'
p_decoder_blocks_0_conv2_1_weight: PARAMETER target='decoder.blocks.0.conv2.1.weight'
p_decoder_blocks_0_conv2_1_bias: PARAMETER target='decoder.blocks.0.conv2.1.bias'
p_decoder_blocks_1_conv1_0_weight: PARAMETER target='decoder.blocks.1.conv1.0.weight'
p_decoder_blocks_1_conv1_1_weight: PARAMETER target='decoder.blocks.1.conv1.1.weight'
p_decoder_blocks_1_conv1_1_bias: PARAMETER target='decoder.blocks.1.conv1.1.bias'
p_decoder_blocks_1_conv2_0_weight: PARAMETER target='decoder.blocks.1.conv2.0.weight'
p_decoder_blocks_1_conv2_1_weight: PARAMETER target='decoder.blocks.1.conv2.1.weight'
p_decoder_blocks_1_conv2_1_bias: PARAMETER target='decoder.blocks.1.conv2.1.bias'
p_decoder_blocks_2_conv1_0_weight: PARAMETER target='decoder.blocks.2.conv1.0.weight'
p_decoder_blocks_2_conv1_1_weight: PARAMETER target='decoder.blocks.2.conv1.1.weight'
p_decoder_blocks_2_conv1_1_bias: PARAMETER target='decoder.blocks.2.conv1.1.bias'
p_decoder_blocks_2_conv2_0_weight: PARAMETER target='decoder.blocks.2.conv2.0.weight'
p_decoder_blocks_2_conv2_1_weight: PARAMETER target='decoder.blocks.2.conv2.1.weight'
p_decoder_blocks_2_conv2_1_bias: PARAMETER target='decoder.blocks.2.conv2.1.bias'
p_decoder_blocks_3_conv1_0_weight: PARAMETER target='decoder.blocks.3.conv1.0.weight'
p_decoder_blocks_3_conv1_1_weight: PARAMETER target='decoder.blocks.3.conv1.1.weight'
p_decoder_blocks_3_conv1_1_bias: PARAMETER target='decoder.blocks.3.conv1.1.bias'
p_decoder_blocks_3_conv2_0_weight: PARAMETER target='decoder.blocks.3.conv2.0.weight'
p_decoder_blocks_3_conv2_1_weight: PARAMETER target='decoder.blocks.3.conv2.1.weight'
p_decoder_blocks_3_conv2_1_bias: PARAMETER target='decoder.blocks.3.conv2.1.bias'
p_decoder_blocks_4_conv1_0_weight: PARAMETER target='decoder.blocks.4.conv1.0.weight'
p_decoder_blocks_4_conv1_1_weight: PARAMETER target='decoder.blocks.4.conv1.1.weight'
p_decoder_blocks_4_conv1_1_bias: PARAMETER target='decoder.blocks.4.conv1.1.bias'
p_decoder_blocks_4_conv2_0_weight: PARAMETER target='decoder.blocks.4.conv2.0.weight'
p_decoder_blocks_4_conv2_1_weight: PARAMETER target='decoder.blocks.4.conv2.1.weight'
p_decoder_blocks_4_conv2_1_bias: PARAMETER target='decoder.blocks.4.conv2.1.bias'
p_segmentation_head_weight: PARAMETER target='segmentation_head.weight'
p_segmentation_head_bias: PARAMETER target='segmentation_head.bias'
b_encoder_stages_0_1_running_mean: BUFFER target='encoder.stages.0.1.running_mean' persistent=True
b_encoder_stages_0_1_running_var: BUFFER target='encoder.stages.0.1.running_var' persistent=True
b_encoder_stages_0_1_num_batches_tracked: BUFFER target='encoder.stages.0.1.num_batches_tracked' persistent=True
b_encoder_stages_1_0_block_0_1_running_mean: BUFFER target='encoder.stages.1.0.block.0.1.running_mean' persistent=True
b_encoder_stages_1_0_block_0_1_running_var: BUFFER target='encoder.stages.1.0.block.0.1.running_var' persistent=True
b_encoder_stages_1_0_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.1.0.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_1_0_block_2_1_running_mean: BUFFER target='encoder.stages.1.0.block.2.1.running_mean' persistent=True
b_encoder_stages_1_0_block_2_1_running_var: BUFFER target='encoder.stages.1.0.block.2.1.running_var' persistent=True
b_encoder_stages_1_0_block_2_1_num_batches_tracked: BUFFER target='encoder.stages.1.0.block.2.1.num_batches_tracked' persistent=True
b_encoder_stages_1_1_block_0_1_running_mean: BUFFER target='encoder.stages.1.1.block.0.1.running_mean' persistent=True
b_encoder_stages_1_1_block_0_1_running_var: BUFFER target='encoder.stages.1.1.block.0.1.running_var' persistent=True
b_encoder_stages_1_1_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.1.1.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_1_1_block_2_1_running_mean: BUFFER target='encoder.stages.1.1.block.2.1.running_mean' persistent=True
b_encoder_stages_1_1_block_2_1_running_var: BUFFER target='encoder.stages.1.1.block.2.1.running_var' persistent=True
b_encoder_stages_1_1_block_2_1_num_batches_tracked: BUFFER target='encoder.stages.1.1.block.2.1.num_batches_tracked' persistent=True
b_encoder_stages_2_0_block_0_1_running_mean: BUFFER target='encoder.stages.2.0.block.0.1.running_mean' persistent=True
b_encoder_stages_2_0_block_0_1_running_var: BUFFER target='encoder.stages.2.0.block.0.1.running_var' persistent=True
b_encoder_stages_2_0_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.2.0.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_2_0_block_1_1_running_mean: BUFFER target='encoder.stages.2.0.block.1.1.running_mean' persistent=True
b_encoder_stages_2_0_block_1_1_running_var: BUFFER target='encoder.stages.2.0.block.1.1.running_var' persistent=True
b_encoder_stages_2_0_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.2.0.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_2_0_block_3_1_running_mean: BUFFER target='encoder.stages.2.0.block.3.1.running_mean' persistent=True
b_encoder_stages_2_0_block_3_1_running_var: BUFFER target='encoder.stages.2.0.block.3.1.running_var' persistent=True
b_encoder_stages_2_0_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.2.0.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_2_1_block_0_1_running_mean: BUFFER target='encoder.stages.2.1.block.0.1.running_mean' persistent=True
b_encoder_stages_2_1_block_0_1_running_var: BUFFER target='encoder.stages.2.1.block.0.1.running_var' persistent=True
b_encoder_stages_2_1_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.2.1.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_2_1_block_1_1_running_mean: BUFFER target='encoder.stages.2.1.block.1.1.running_mean' persistent=True
b_encoder_stages_2_1_block_1_1_running_var: BUFFER target='encoder.stages.2.1.block.1.1.running_var' persistent=True
b_encoder_stages_2_1_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.2.1.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_2_1_block_3_1_running_mean: BUFFER target='encoder.stages.2.1.block.3.1.running_mean' persistent=True
b_encoder_stages_2_1_block_3_1_running_var: BUFFER target='encoder.stages.2.1.block.3.1.running_var' persistent=True
b_encoder_stages_2_1_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.2.1.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_2_2_block_0_1_running_mean: BUFFER target='encoder.stages.2.2.block.0.1.running_mean' persistent=True
b_encoder_stages_2_2_block_0_1_running_var: BUFFER target='encoder.stages.2.2.block.0.1.running_var' persistent=True
b_encoder_stages_2_2_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.2.2.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_2_2_block_1_1_running_mean: BUFFER target='encoder.stages.2.2.block.1.1.running_mean' persistent=True
b_encoder_stages_2_2_block_1_1_running_var: BUFFER target='encoder.stages.2.2.block.1.1.running_var' persistent=True
b_encoder_stages_2_2_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.2.2.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_2_2_block_3_1_running_mean: BUFFER target='encoder.stages.2.2.block.3.1.running_mean' persistent=True
b_encoder_stages_2_2_block_3_1_running_var: BUFFER target='encoder.stages.2.2.block.3.1.running_var' persistent=True
b_encoder_stages_2_2_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.2.2.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_3_0_block_0_1_running_mean: BUFFER target='encoder.stages.3.0.block.0.1.running_mean' persistent=True
b_encoder_stages_3_0_block_0_1_running_var: BUFFER target='encoder.stages.3.0.block.0.1.running_var' persistent=True
b_encoder_stages_3_0_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.3.0.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_3_0_block_1_1_running_mean: BUFFER target='encoder.stages.3.0.block.1.1.running_mean' persistent=True
b_encoder_stages_3_0_block_1_1_running_var: BUFFER target='encoder.stages.3.0.block.1.1.running_var' persistent=True
b_encoder_stages_3_0_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.3.0.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_3_0_block_3_1_running_mean: BUFFER target='encoder.stages.3.0.block.3.1.running_mean' persistent=True
b_encoder_stages_3_0_block_3_1_running_var: BUFFER target='encoder.stages.3.0.block.3.1.running_var' persistent=True
b_encoder_stages_3_0_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.3.0.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_3_1_block_0_1_running_mean: BUFFER target='encoder.stages.3.1.block.0.1.running_mean' persistent=True
b_encoder_stages_3_1_block_0_1_running_var: BUFFER target='encoder.stages.3.1.block.0.1.running_var' persistent=True
b_encoder_stages_3_1_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.3.1.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_3_1_block_1_1_running_mean: BUFFER target='encoder.stages.3.1.block.1.1.running_mean' persistent=True
b_encoder_stages_3_1_block_1_1_running_var: BUFFER target='encoder.stages.3.1.block.1.1.running_var' persistent=True
b_encoder_stages_3_1_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.3.1.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_3_1_block_3_1_running_mean: BUFFER target='encoder.stages.3.1.block.3.1.running_mean' persistent=True
b_encoder_stages_3_1_block_3_1_running_var: BUFFER target='encoder.stages.3.1.block.3.1.running_var' persistent=True
b_encoder_stages_3_1_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.3.1.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_3_2_block_0_1_running_mean: BUFFER target='encoder.stages.3.2.block.0.1.running_mean' persistent=True
b_encoder_stages_3_2_block_0_1_running_var: BUFFER target='encoder.stages.3.2.block.0.1.running_var' persistent=True
b_encoder_stages_3_2_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.3.2.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_3_2_block_1_1_running_mean: BUFFER target='encoder.stages.3.2.block.1.1.running_mean' persistent=True
b_encoder_stages_3_2_block_1_1_running_var: BUFFER target='encoder.stages.3.2.block.1.1.running_var' persistent=True
b_encoder_stages_3_2_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.3.2.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_3_2_block_3_1_running_mean: BUFFER target='encoder.stages.3.2.block.3.1.running_mean' persistent=True
b_encoder_stages_3_2_block_3_1_running_var: BUFFER target='encoder.stages.3.2.block.3.1.running_var' persistent=True
b_encoder_stages_3_2_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.3.2.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_4_0_block_0_1_running_mean: BUFFER target='encoder.stages.4.0.block.0.1.running_mean' persistent=True
b_encoder_stages_4_0_block_0_1_running_var: BUFFER target='encoder.stages.4.0.block.0.1.running_var' persistent=True
b_encoder_stages_4_0_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.4.0.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_4_0_block_1_1_running_mean: BUFFER target='encoder.stages.4.0.block.1.1.running_mean' persistent=True
b_encoder_stages_4_0_block_1_1_running_var: BUFFER target='encoder.stages.4.0.block.1.1.running_var' persistent=True
b_encoder_stages_4_0_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.4.0.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_4_0_block_3_1_running_mean: BUFFER target='encoder.stages.4.0.block.3.1.running_mean' persistent=True
b_encoder_stages_4_0_block_3_1_running_var: BUFFER target='encoder.stages.4.0.block.3.1.running_var' persistent=True
b_encoder_stages_4_0_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.4.0.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_4_1_block_0_1_running_mean: BUFFER target='encoder.stages.4.1.block.0.1.running_mean' persistent=True
b_encoder_stages_4_1_block_0_1_running_var: BUFFER target='encoder.stages.4.1.block.0.1.running_var' persistent=True
b_encoder_stages_4_1_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.4.1.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_4_1_block_1_1_running_mean: BUFFER target='encoder.stages.4.1.block.1.1.running_mean' persistent=True
b_encoder_stages_4_1_block_1_1_running_var: BUFFER target='encoder.stages.4.1.block.1.1.running_var' persistent=True
b_encoder_stages_4_1_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.4.1.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_4_1_block_3_1_running_mean: BUFFER target='encoder.stages.4.1.block.3.1.running_mean' persistent=True
b_encoder_stages_4_1_block_3_1_running_var: BUFFER target='encoder.stages.4.1.block.3.1.running_var' persistent=True
b_encoder_stages_4_1_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.4.1.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_4_2_block_0_1_running_mean: BUFFER target='encoder.stages.4.2.block.0.1.running_mean' persistent=True
b_encoder_stages_4_2_block_0_1_running_var: BUFFER target='encoder.stages.4.2.block.0.1.running_var' persistent=True
b_encoder_stages_4_2_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.4.2.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_4_2_block_1_1_running_mean: BUFFER target='encoder.stages.4.2.block.1.1.running_mean' persistent=True
b_encoder_stages_4_2_block_1_1_running_var: BUFFER target='encoder.stages.4.2.block.1.1.running_var' persistent=True
b_encoder_stages_4_2_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.4.2.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_4_2_block_3_1_running_mean: BUFFER target='encoder.stages.4.2.block.3.1.running_mean' persistent=True
b_encoder_stages_4_2_block_3_1_running_var: BUFFER target='encoder.stages.4.2.block.3.1.running_var' persistent=True
b_encoder_stages_4_2_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.4.2.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_4_3_block_0_1_running_mean: BUFFER target='encoder.stages.4.3.block.0.1.running_mean' persistent=True
b_encoder_stages_4_3_block_0_1_running_var: BUFFER target='encoder.stages.4.3.block.0.1.running_var' persistent=True
b_encoder_stages_4_3_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.4.3.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_4_3_block_1_1_running_mean: BUFFER target='encoder.stages.4.3.block.1.1.running_mean' persistent=True
b_encoder_stages_4_3_block_1_1_running_var: BUFFER target='encoder.stages.4.3.block.1.1.running_var' persistent=True
b_encoder_stages_4_3_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.4.3.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_4_3_block_3_1_running_mean: BUFFER target='encoder.stages.4.3.block.3.1.running_mean' persistent=True
b_encoder_stages_4_3_block_3_1_running_var: BUFFER target='encoder.stages.4.3.block.3.1.running_var' persistent=True
b_encoder_stages_4_3_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.4.3.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_4_4_block_0_1_running_mean: BUFFER target='encoder.stages.4.4.block.0.1.running_mean' persistent=True
b_encoder_stages_4_4_block_0_1_running_var: BUFFER target='encoder.stages.4.4.block.0.1.running_var' persistent=True
b_encoder_stages_4_4_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.4.4.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_4_4_block_1_1_running_mean: BUFFER target='encoder.stages.4.4.block.1.1.running_mean' persistent=True
b_encoder_stages_4_4_block_1_1_running_var: BUFFER target='encoder.stages.4.4.block.1.1.running_var' persistent=True
b_encoder_stages_4_4_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.4.4.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_4_4_block_3_1_running_mean: BUFFER target='encoder.stages.4.4.block.3.1.running_mean' persistent=True
b_encoder_stages_4_4_block_3_1_running_var: BUFFER target='encoder.stages.4.4.block.3.1.running_var' persistent=True
b_encoder_stages_4_4_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.4.4.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_5_0_block_0_1_running_mean: BUFFER target='encoder.stages.5.0.block.0.1.running_mean' persistent=True
b_encoder_stages_5_0_block_0_1_running_var: BUFFER target='encoder.stages.5.0.block.0.1.running_var' persistent=True
b_encoder_stages_5_0_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.5.0.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_5_0_block_1_1_running_mean: BUFFER target='encoder.stages.5.0.block.1.1.running_mean' persistent=True
b_encoder_stages_5_0_block_1_1_running_var: BUFFER target='encoder.stages.5.0.block.1.1.running_var' persistent=True
b_encoder_stages_5_0_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.5.0.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_5_0_block_3_1_running_mean: BUFFER target='encoder.stages.5.0.block.3.1.running_mean' persistent=True
b_encoder_stages_5_0_block_3_1_running_var: BUFFER target='encoder.stages.5.0.block.3.1.running_var' persistent=True
b_encoder_stages_5_0_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.5.0.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_5_1_block_0_1_running_mean: BUFFER target='encoder.stages.5.1.block.0.1.running_mean' persistent=True
b_encoder_stages_5_1_block_0_1_running_var: BUFFER target='encoder.stages.5.1.block.0.1.running_var' persistent=True
b_encoder_stages_5_1_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.5.1.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_5_1_block_1_1_running_mean: BUFFER target='encoder.stages.5.1.block.1.1.running_mean' persistent=True
b_encoder_stages_5_1_block_1_1_running_var: BUFFER target='encoder.stages.5.1.block.1.1.running_var' persistent=True
b_encoder_stages_5_1_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.5.1.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_5_1_block_3_1_running_mean: BUFFER target='encoder.stages.5.1.block.3.1.running_mean' persistent=True
b_encoder_stages_5_1_block_3_1_running_var: BUFFER target='encoder.stages.5.1.block.3.1.running_var' persistent=True
b_encoder_stages_5_1_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.5.1.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_5_2_block_0_1_running_mean: BUFFER target='encoder.stages.5.2.block.0.1.running_mean' persistent=True
b_encoder_stages_5_2_block_0_1_running_var: BUFFER target='encoder.stages.5.2.block.0.1.running_var' persistent=True
b_encoder_stages_5_2_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.5.2.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_5_2_block_1_1_running_mean: BUFFER target='encoder.stages.5.2.block.1.1.running_mean' persistent=True
b_encoder_stages_5_2_block_1_1_running_var: BUFFER target='encoder.stages.5.2.block.1.1.running_var' persistent=True
b_encoder_stages_5_2_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.5.2.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_5_2_block_3_1_running_mean: BUFFER target='encoder.stages.5.2.block.3.1.running_mean' persistent=True
b_encoder_stages_5_2_block_3_1_running_var: BUFFER target='encoder.stages.5.2.block.3.1.running_var' persistent=True
b_encoder_stages_5_2_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.5.2.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_5_3_block_0_1_running_mean: BUFFER target='encoder.stages.5.3.block.0.1.running_mean' persistent=True
b_encoder_stages_5_3_block_0_1_running_var: BUFFER target='encoder.stages.5.3.block.0.1.running_var' persistent=True
b_encoder_stages_5_3_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.5.3.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_5_3_block_1_1_running_mean: BUFFER target='encoder.stages.5.3.block.1.1.running_mean' persistent=True
b_encoder_stages_5_3_block_1_1_running_var: BUFFER target='encoder.stages.5.3.block.1.1.running_var' persistent=True
b_encoder_stages_5_3_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.5.3.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_5_3_block_3_1_running_mean: BUFFER target='encoder.stages.5.3.block.3.1.running_mean' persistent=True
b_encoder_stages_5_3_block_3_1_running_var: BUFFER target='encoder.stages.5.3.block.3.1.running_var' persistent=True
b_encoder_stages_5_3_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.5.3.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_5_4_block_0_1_running_mean: BUFFER target='encoder.stages.5.4.block.0.1.running_mean' persistent=True
b_encoder_stages_5_4_block_0_1_running_var: BUFFER target='encoder.stages.5.4.block.0.1.running_var' persistent=True
b_encoder_stages_5_4_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.5.4.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_5_4_block_1_1_running_mean: BUFFER target='encoder.stages.5.4.block.1.1.running_mean' persistent=True
b_encoder_stages_5_4_block_1_1_running_var: BUFFER target='encoder.stages.5.4.block.1.1.running_var' persistent=True
b_encoder_stages_5_4_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.5.4.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_5_4_block_3_1_running_mean: BUFFER target='encoder.stages.5.4.block.3.1.running_mean' persistent=True
b_encoder_stages_5_4_block_3_1_running_var: BUFFER target='encoder.stages.5.4.block.3.1.running_var' persistent=True
b_encoder_stages_5_4_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.5.4.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_6_0_block_0_1_running_mean: BUFFER target='encoder.stages.6.0.block.0.1.running_mean' persistent=True
b_encoder_stages_6_0_block_0_1_running_var: BUFFER target='encoder.stages.6.0.block.0.1.running_var' persistent=True
b_encoder_stages_6_0_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.6.0.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_6_0_block_1_1_running_mean: BUFFER target='encoder.stages.6.0.block.1.1.running_mean' persistent=True
b_encoder_stages_6_0_block_1_1_running_var: BUFFER target='encoder.stages.6.0.block.1.1.running_var' persistent=True
b_encoder_stages_6_0_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.6.0.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_6_0_block_3_1_running_mean: BUFFER target='encoder.stages.6.0.block.3.1.running_mean' persistent=True
b_encoder_stages_6_0_block_3_1_running_var: BUFFER target='encoder.stages.6.0.block.3.1.running_var' persistent=True
b_encoder_stages_6_0_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.6.0.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_6_1_block_0_1_running_mean: BUFFER target='encoder.stages.6.1.block.0.1.running_mean' persistent=True
b_encoder_stages_6_1_block_0_1_running_var: BUFFER target='encoder.stages.6.1.block.0.1.running_var' persistent=True
b_encoder_stages_6_1_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.6.1.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_6_1_block_1_1_running_mean: BUFFER target='encoder.stages.6.1.block.1.1.running_mean' persistent=True
b_encoder_stages_6_1_block_1_1_running_var: BUFFER target='encoder.stages.6.1.block.1.1.running_var' persistent=True
b_encoder_stages_6_1_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.6.1.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_6_1_block_3_1_running_mean: BUFFER target='encoder.stages.6.1.block.3.1.running_mean' persistent=True
b_encoder_stages_6_1_block_3_1_running_var: BUFFER target='encoder.stages.6.1.block.3.1.running_var' persistent=True
b_encoder_stages_6_1_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.6.1.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_6_2_block_0_1_running_mean: BUFFER target='encoder.stages.6.2.block.0.1.running_mean' persistent=True
b_encoder_stages_6_2_block_0_1_running_var: BUFFER target='encoder.stages.6.2.block.0.1.running_var' persistent=True
b_encoder_stages_6_2_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.6.2.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_6_2_block_1_1_running_mean: BUFFER target='encoder.stages.6.2.block.1.1.running_mean' persistent=True
b_encoder_stages_6_2_block_1_1_running_var: BUFFER target='encoder.stages.6.2.block.1.1.running_var' persistent=True
b_encoder_stages_6_2_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.6.2.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_6_2_block_3_1_running_mean: BUFFER target='encoder.stages.6.2.block.3.1.running_mean' persistent=True
b_encoder_stages_6_2_block_3_1_running_var: BUFFER target='encoder.stages.6.2.block.3.1.running_var' persistent=True
b_encoder_stages_6_2_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.6.2.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_6_3_block_0_1_running_mean: BUFFER target='encoder.stages.6.3.block.0.1.running_mean' persistent=True
b_encoder_stages_6_3_block_0_1_running_var: BUFFER target='encoder.stages.6.3.block.0.1.running_var' persistent=True
b_encoder_stages_6_3_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.6.3.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_6_3_block_1_1_running_mean: BUFFER target='encoder.stages.6.3.block.1.1.running_mean' persistent=True
b_encoder_stages_6_3_block_1_1_running_var: BUFFER target='encoder.stages.6.3.block.1.1.running_var' persistent=True
b_encoder_stages_6_3_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.6.3.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_6_3_block_3_1_running_mean: BUFFER target='encoder.stages.6.3.block.3.1.running_mean' persistent=True
b_encoder_stages_6_3_block_3_1_running_var: BUFFER target='encoder.stages.6.3.block.3.1.running_var' persistent=True
b_encoder_stages_6_3_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.6.3.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_6_4_block_0_1_running_mean: BUFFER target='encoder.stages.6.4.block.0.1.running_mean' persistent=True
b_encoder_stages_6_4_block_0_1_running_var: BUFFER target='encoder.stages.6.4.block.0.1.running_var' persistent=True
b_encoder_stages_6_4_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.6.4.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_6_4_block_1_1_running_mean: BUFFER target='encoder.stages.6.4.block.1.1.running_mean' persistent=True
b_encoder_stages_6_4_block_1_1_running_var: BUFFER target='encoder.stages.6.4.block.1.1.running_var' persistent=True
b_encoder_stages_6_4_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.6.4.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_6_4_block_3_1_running_mean: BUFFER target='encoder.stages.6.4.block.3.1.running_mean' persistent=True
b_encoder_stages_6_4_block_3_1_running_var: BUFFER target='encoder.stages.6.4.block.3.1.running_var' persistent=True
b_encoder_stages_6_4_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.6.4.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_6_5_block_0_1_running_mean: BUFFER target='encoder.stages.6.5.block.0.1.running_mean' persistent=True
b_encoder_stages_6_5_block_0_1_running_var: BUFFER target='encoder.stages.6.5.block.0.1.running_var' persistent=True
b_encoder_stages_6_5_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.6.5.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_6_5_block_1_1_running_mean: BUFFER target='encoder.stages.6.5.block.1.1.running_mean' persistent=True
b_encoder_stages_6_5_block_1_1_running_var: BUFFER target='encoder.stages.6.5.block.1.1.running_var' persistent=True
b_encoder_stages_6_5_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.6.5.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_6_5_block_3_1_running_mean: BUFFER target='encoder.stages.6.5.block.3.1.running_mean' persistent=True
b_encoder_stages_6_5_block_3_1_running_var: BUFFER target='encoder.stages.6.5.block.3.1.running_var' persistent=True
b_encoder_stages_6_5_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.6.5.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_7_0_block_0_1_running_mean: BUFFER target='encoder.stages.7.0.block.0.1.running_mean' persistent=True
b_encoder_stages_7_0_block_0_1_running_var: BUFFER target='encoder.stages.7.0.block.0.1.running_var' persistent=True
b_encoder_stages_7_0_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.7.0.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_7_0_block_1_1_running_mean: BUFFER target='encoder.stages.7.0.block.1.1.running_mean' persistent=True
b_encoder_stages_7_0_block_1_1_running_var: BUFFER target='encoder.stages.7.0.block.1.1.running_var' persistent=True
b_encoder_stages_7_0_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.7.0.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_7_0_block_3_1_running_mean: BUFFER target='encoder.stages.7.0.block.3.1.running_mean' persistent=True
b_encoder_stages_7_0_block_3_1_running_var: BUFFER target='encoder.stages.7.0.block.3.1.running_var' persistent=True
b_encoder_stages_7_0_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.7.0.block.3.1.num_batches_tracked' persistent=True
b_encoder_stages_7_1_block_0_1_running_mean: BUFFER target='encoder.stages.7.1.block.0.1.running_mean' persistent=True
b_encoder_stages_7_1_block_0_1_running_var: BUFFER target='encoder.stages.7.1.block.0.1.running_var' persistent=True
b_encoder_stages_7_1_block_0_1_num_batches_tracked: BUFFER target='encoder.stages.7.1.block.0.1.num_batches_tracked' persistent=True
b_encoder_stages_7_1_block_1_1_running_mean: BUFFER target='encoder.stages.7.1.block.1.1.running_mean' persistent=True
b_encoder_stages_7_1_block_1_1_running_var: BUFFER target='encoder.stages.7.1.block.1.1.running_var' persistent=True
b_encoder_stages_7_1_block_1_1_num_batches_tracked: BUFFER target='encoder.stages.7.1.block.1.1.num_batches_tracked' persistent=True
b_encoder_stages_7_1_block_3_1_running_mean: BUFFER target='encoder.stages.7.1.block.3.1.running_mean' persistent=True
b_encoder_stages_7_1_block_3_1_running_var: BUFFER target='encoder.stages.7.1.block.3.1.running_var' persistent=True
b_encoder_stages_7_1_block_3_1_num_batches_tracked: BUFFER target='encoder.stages.7.1.block.3.1.num_batches_tracked' persistent=True
b_decoder_blocks_0_conv1_1_running_mean: BUFFER target='decoder.blocks.0.conv1.1.running_mean' persistent=True
b_decoder_blocks_0_conv1_1_running_var: BUFFER target='decoder.blocks.0.conv1.1.running_var' persistent=True
b_decoder_blocks_0_conv1_1_num_batches_tracked: BUFFER target='decoder.blocks.0.conv1.1.num_batches_tracked' persistent=True
b_decoder_blocks_0_conv2_1_running_mean: BUFFER target='decoder.blocks.0.conv2.1.running_mean' persistent=True
b_decoder_blocks_0_conv2_1_running_var: BUFFER target='decoder.blocks.0.conv2.1.running_var' persistent=True
b_decoder_blocks_0_conv2_1_num_batches_tracked: BUFFER target='decoder.blocks.0.conv2.1.num_batches_tracked' persistent=True
b_decoder_blocks_1_conv1_1_running_mean: BUFFER target='decoder.blocks.1.conv1.1.running_mean' persistent=True
b_decoder_blocks_1_conv1_1_running_var: BUFFER target='decoder.blocks.1.conv1.1.running_var' persistent=True
b_decoder_blocks_1_conv1_1_num_batches_tracked: BUFFER target='decoder.blocks.1.conv1.1.num_batches_tracked' persistent=True
b_decoder_blocks_1_conv2_1_running_mean: BUFFER target='decoder.blocks.1.conv2.1.running_mean' persistent=True
b_decoder_blocks_1_conv2_1_running_var: BUFFER target='decoder.blocks.1.conv2.1.running_var' persistent=True
b_decoder_blocks_1_conv2_1_num_batches_tracked: BUFFER target='decoder.blocks.1.conv2.1.num_batches_tracked' persistent=True
b_decoder_blocks_2_conv1_1_running_mean: BUFFER target='decoder.blocks.2.conv1.1.running_mean' persistent=True
b_decoder_blocks_2_conv1_1_running_var: BUFFER target='decoder.blocks.2.conv1.1.running_var' persistent=True
b_decoder_blocks_2_conv1_1_num_batches_tracked: BUFFER target='decoder.blocks.2.conv1.1.num_batches_tracked' persistent=True
b_decoder_blocks_2_conv2_1_running_mean: BUFFER target='decoder.blocks.2.conv2.1.running_mean' persistent=True
b_decoder_blocks_2_conv2_1_running_var: BUFFER target='decoder.blocks.2.conv2.1.running_var' persistent=True
b_decoder_blocks_2_conv2_1_num_batches_tracked: BUFFER target='decoder.blocks.2.conv2.1.num_batches_tracked' persistent=True
b_decoder_blocks_3_conv1_1_running_mean: BUFFER target='decoder.blocks.3.conv1.1.running_mean' persistent=True
b_decoder_blocks_3_conv1_1_running_var: BUFFER target='decoder.blocks.3.conv1.1.running_var' persistent=True
b_decoder_blocks_3_conv1_1_num_batches_tracked: BUFFER target='decoder.blocks.3.conv1.1.num_batches_tracked' persistent=True
b_decoder_blocks_3_conv2_1_running_mean: BUFFER target='decoder.blocks.3.conv2.1.running_mean' persistent=True
b_decoder_blocks_3_conv2_1_running_var: BUFFER target='decoder.blocks.3.conv2.1.running_var' persistent=True
b_decoder_blocks_3_conv2_1_num_batches_tracked: BUFFER target='decoder.blocks.3.conv2.1.num_batches_tracked' persistent=True
b_decoder_blocks_4_conv1_1_running_mean: BUFFER target='decoder.blocks.4.conv1.1.running_mean' persistent=True
b_decoder_blocks_4_conv1_1_running_var: BUFFER target='decoder.blocks.4.conv1.1.running_var' persistent=True
b_decoder_blocks_4_conv1_1_num_batches_tracked: BUFFER target='decoder.blocks.4.conv1.1.num_batches_tracked' persistent=True
b_decoder_blocks_4_conv2_1_running_mean: BUFFER target='decoder.blocks.4.conv2.1.running_mean' persistent=True
b_decoder_blocks_4_conv2_1_running_var: BUFFER target='decoder.blocks.4.conv2.1.running_var' persistent=True
b_decoder_blocks_4_conv2_1_num_batches_tracked: BUFFER target='decoder.blocks.4.conv2.1.num_batches_tracked' persistent=True
x: USER_INPUT

# outputs
conv2d_139: USER_OUTPUT
Çq
2pkg.torch.export.ExportedProgram.range_constraints;{s77: VR[0, int_oo], s53: VR[0, int_oo], s0: VR[0, int_oo]}B
 